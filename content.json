{"meta":{"title":"Hexo","subtitle":null,"description":null,"author":"Kevin","url":"https://chengtong.me"},"pages":[{"title":"Kevin","date":"2020-05-25T08:39:06.640Z","updated":"2020-05-25T08:39:06.640Z","comments":true,"path":"about/index.html","permalink":"https://chengtong.me/about/index.html","excerpt":"","text":"我们之所以觉得悬崖上的花朵美丽那是因为我们会在悬崖停下脚步而不是像那些毫不畏惧的花朵般能向天空踏出一步 支付宝红包码"}],"posts":[{"title":"Spring Boot 2.5.0 正式发布","slug":"Spring Boot 2.5.0 正式发布","date":"2021-06-06T12:16:09.000Z","updated":"2021-06-08T02:19:32.849Z","comments":true,"path":"posts/277a750e.html","link":"","permalink":"https://chengtong.me/posts/277a750e.html","excerpt":"","text":"Spring Boot 2.5.0 正式发布 123456&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.5.0&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt;&lt;/parent&gt; 主要更新内容 支持 Java 16 支持 Gradle 7 支持 Jetty 10 增强 Docker 镜像的构建 更新了Datasource的初始化机制 除了框架功能更新之后，该版本在文档方面也顺应时代潮流，增加了暗黑模式的支持！ 文档地址：https://docs.spring.io/spring-boot/docs/current/reference/html/ 外观新颖，字体更清晰。 上下方向箭头展开/折叠示例代码以显示导入和详细信息。 代码片段剪贴板按钮 文档支持暗黑模式 重要更新 数据源相关变更 spring.datasource.* 已被 spring.sql.init.* 属性替代。 Flyway 和 Liquibase 需要指定单独的 username / password,不再从 datasource 继承。 不再维护 spring data solr , 从此版本开始 已经开始从源码中移除。 断点 /info 不再通过 web 暴露，如果类中包含 spring security，需要安全验证。 EL 语法实现由 tomcat-embed-el 替代为 jakrta-el。 Error View 异常页面中不会包含 具体的错误信息，如果需要则可以通过 server.error.include-message开启。 通过 logging.register-shutdown-hook 属性可以在 jvm 退出时释放日志资源。 基于Spring Boot 2.4的变动 Sql脚本初始化数据源 在Spring Boot 2.5中已经重新设计了用于支持和编写脚本的基础方法。数据源初始化相关的配置已经过时，会被系列配置所代替，而且新的配置对R2DBC也适用。需要注意的是目前不支持分离许可证（），目的是降低复杂度并同Flyway和Liquibase保持一致性兼容。当然你可以通过自行实现 来扩展。 环境变量前缀 现在可以为系统环境变量指定前缀，以便您可以在同一环境中运行多个不同的Spring Boot应用程序时使用 例如： 当你需要针对特定的应用改变系统变量时，如,就可以声明为、或者。 注意不是中的配置。 HTTP/2支持 现在Spring Boot内置的四种Web容器已经在不需要任何自定义的情况下，支持HTTP/2 over TCP。设置为 ，为即可生效。 Docker镜像 War分层镜像 现在Spring Boot也能打成war包装进Docker镜像了，而且支持分层构建。 buildpacks 度量指标 现在Spring Boot支持OpenMetrics for Prometheus、Spring Data Repositories、WebFlux、MongoDB、Quartz的度量指标监控。 其他更新management.endpoints.web.cors.allowed-origin-patterns配置可以用来控制是否允许Actuator端点跨域访问 HttpSessionIdListener现在开始自动注册到Servlet上下文 Couchbase现在默认使用自动化配置的ObjectMapper Elasticsearch的Sniffer会根据classpath下是否存在elasticsearch-rest-client-sniffer模块来自动配置 spring.data.cassandra.controlconnection.timeout现在可以用来配置Cassandra的连接超时控制 spring.kafka.listener.only-log-record-metadata现在可以用来配置重试时记录的元数据 支持Apache Phoenix，自动检测jdbc:phoenix这样的JDBC链接配置 /actuator的发现页现在可以通过management.endpoints.web.discovery.enabled配置来禁用 /actuator/configprops和actuator/env端点现在可以用additional-keys-to-sanitize来配置不展示的key 如果要自定义JMX的Actuator端点，可以使用EndpointObjectNameFactory 当classpath下有Spring Security的时候，会自动配置并绑定RSAPublicKey和RSAPrivateKey RabbitMQ的ConnectionFactory现在可以通过ConnectionFactoryCustomizer来实现自定义 CloudPlatform现在可以自动侦测Azure App Service server.tomcat.keep-alive-timeout可以用来配置Tomcat在关闭keep-alive连接之前等待另一个请求的时间。 server.tomcat.max-keep-alive-requests可以用来控制在keep-alive状态的连接关闭之前可以保持的最大请求数。 spring.webflux.session.cookie.same-site用来配置WebFlux的SameSite cookie策略，默认为lax Apache HttpCient 5现在是默认的自动化配置使用WebClient 依赖组件版本在Spring Boot 2.5 中更新了各项依赖组件的版本，具体清单如下： Spring Data 2021.0 Spring HATEOAS 1.3 Spring Integration 5.5 Spring Kafka 2.7 Spring Retry 1.3 Spring Security 5.5 Spring Session 2021.0 下面是第三方依赖组件的版本清单： Kotlin 1.5 Groovy 3.0 Flyway 7.7 Liquibase 4.2 Jackson 2.12 Kafka 2.7 Cassandra Driver 4.10 Embedded Mongo 3.0 Hibernate Validator 6.2 Jersey 2.33 Mockito 3.7 MongoDB 4.2 JUnit Jupiter 5.7 Elasticsearch 7.12 弃用内容以下是Spring Boot 2.5中被弃用的内容，大家升级的时候有所涉及的要做好调整哦！ 原位于org.springframework.boot.actuate.endpoint.http包下的ActuatorMediaType和ApiVersion被整合并移动到了org.springframework.boot.actuate.endpoint包下。 原用于实现jOOQ的一些Provider的回调接口以及配置从这个版本开始弃用。后面要使用org.springframework.boot.autoconfigure.jooq.DefaultConfigurationCustomizer来替代。 原位于org.springframework.boot.autoconfigure.data.jpa包下的EntityManagerFactoryDependsOnPostProcessor移动到org.springframework.boot.autoconfigure.orm.jpa包下 过期依赖移除 Spring Boot 2.5已删除了Spring Boot 2.3中不推荐使用的代码。Spring Boot 2.4不推荐使用的代码目前保留，并计划在Spring Boot 2.6中将其删除。 不推荐使用的代码即标记的API。 文档优化 Spring Boot文档史诗级优化，界面更新颖漂亮，字体更加清晰，暗黑主题，代码折叠，代码剪切板都有了！","categories":[{"name":"JAVA","slug":"JAVA","permalink":"https://chengtong.me/categories/JAVA/"}],"tags":[{"name":"Spring Boot","slug":"Spring-Boot","permalink":"https://chengtong.me/tags/Spring-Boot/"}]},{"title":"ios的app后缀是ipa，安卓是apk，那兼容安卓app的鸿蒙呢？","slug":"ios的app后缀是ipa，安卓是apk，那兼容安卓app的鸿蒙呢？","date":"2021-06-04T12:55:04.000Z","updated":"2021-06-08T02:27:07.416Z","comments":true,"path":"posts/cf57e2b0.html","link":"","permalink":"https://chengtong.me/posts/cf57e2b0.html","excerpt":"","text":"大家都知道ios的app后缀名是“ipa”，安卓app后缀是“apk”，后缀代表着兼容格式，那么鸿蒙OS的app后缀是啥？答案是“.hap”，这是一个全新的app后缀，当前已经有京东，优酷，新浪新闻等等应用APP推出了鸿蒙版应用版，最近硬件神器AIDA64也表示正在开发鸿蒙OS的app，截至目前，适配鸿蒙OS的app，已经累计数量超200款应用了。 那有网友会问了，鸿蒙系统为什么可以使用apk呢？原因是鸿蒙和安卓都是基于Linux开发的，而Linux是多国成员共同开发的免费开源的，华为之所以在鸿蒙发布之前先上了一个方舟编译器，应该就是为apk程序准备的转换器，用来过渡，当鸿蒙取得一定的体量之后，会停止对apk的安卓应用的支持，只是时间问题了。 安卓是做了十几年才有今天的样子，华为这么短时间就能做到完成度这么高，如果是真的从底层做起，那是真厉害，不过有这么多人怀疑也是正常的，就看华为怎么正名了。鸿蒙就在那华为一直公开透明，你们不去了解不去看就怪华为不证明，黑华为嘲笑鸿蒙或者普通消费者理解的证明要看到表面中的表面安卓做不到鸿蒙这样。安卓能同时连接五个设备，长时间不掉线，而且五个设备硬件通用，延时低，安卓能做到吗？做不到吧 一个系统，开发开发底层，码代码并不难，难的是生态，系统能否活下去，就是靠生态，生态起不来，再好的系统也是白搭。安卓发展了这么多年，吸收了全球很多优秀的开发者，一起填充安卓这个高楼，虽然鸿蒙有很多和安卓相似的地方，但也是因为借鉴了AOSP社区里的一些代码。","categories":[],"tags":[]},{"title":"这个牛逼哄哄的数据库开源了,300万行核心代码","slug":"这个牛逼哄哄的数据库开源了,300万行核心代码","date":"2021-06-01T13:50:09.000Z","updated":"2021-06-08T02:24:21.639Z","comments":true,"path":"posts/fbb24e80.html","link":"","permalink":"https://chengtong.me/posts/fbb24e80.html","excerpt":"","text":"6月1日，在数据库OceanBase3.0峰会上，蚂蚁集团自主研发的分布式数据库OceanBase首次从技术、商业和生态三个维度对未来发展战略进行了系统性阐述。同时，OceanBase宣布正式开源，并成立OceanBase开源社区，社区官网同步上线，300万行核心代码向社区开放。 未来三年专注核心分布式改造 CEO杨冰表示，OceanBase将持续坚持自研开放之路，在未来3年内，专注企业核心分布式改造。同时，宣布释放科技红利，7月启动全新价格体系，公共云版本将推出价格更低的存算分离版本。 此次推出的最新3.0版本产品，让OceanBase同时具备了在事务处理和数据分析两类任务的高性能能力，升级为一款支持 HTAP 混合负载的企业级分布式数据库。和过去相比，事务处理性能提升50%，数据分析性能提升10倍。未来，用户业务无论是事务型还是分析型，只要一套系统就可以应对数字化转型过程中“海量、实时、在线”的业务需求。 Gartner认为，HTAP（混合事务/分析处理）数据库将成为数据库领域的重要发展趋势，一个集成的数据平台将会加速数字化转型。 在各个领域深化数字化转型过程中， 核心系统的分布式改造是非常关键的一环。过去一年的合作案例显示，随着自主研发分布式技术的逐步成熟，不断应用、优化和完善，OceanBase帮助客户进行核心系统数字化改造时，在可靠性、可扩展性等方面的优势越来越明显。 杨冰透露，“在当前规模和技术红利基础上，我们希望以更低的价格与门槛，给予客户更强的数据库能力进行核心系统的分布式改造。核心系统改造不仅能让企业实现整体系统完全自主掌控。更能在业务稳定性、连续性不降低的前提下，支撑业务敏捷，最后达到每单笔交易/每个账户成本下降的目标。” 开源300万行核心代码 大会现场，CEO杨冰还宣布自研数据库OceanBase正式开源，并成立OceanBase开源社区，社区官网同步上线。 据了解，开源已经上升为OceanBase重要的技术战略。OceanBase数据库创始人阳振坤表示，蚂蚁自研数据库OceanBase致力于打造企业级开源数据库，同时与合作伙伴一起紧密合作，快速发行商业版本，满足行业客户对数据库高性能、高可靠、融合处理的业务诉求。 据介绍，开发者在开源社区能够完整使用OceanBase数据库内核。此次开源采用业界通用Open Core模式。开源范围包含数据库内核、分布式组件和接口驱动，并提供完整的SQL引擎、事务引擎和存储引擎，支持多副本、分布式事务、高性能、扩展能力、故障恢复、优化器、多活容灾、语法兼容等核心技术，开源300万行核心代码。 OceanBase采用木兰公共协议 MulanPubL-2.0 版，协议允许所有社区参与者对代码进行自由修改、使用和引用。OceanBase社区同时成立了技术委员会，欢迎所有开发者贡献代码和文档。 “越来越多优秀的产品加入到开源社区，有利于我国开源生态的建设以及开源人才的培养。”北大计算机系教授、木兰开源许可证主要发起人周明辉表示，中国从开源社区中受益良多。目前我们有更多的能力，那我们就可以承担多一点的责任，让开源界、让世界更好。 阳振坤透露，“希望更多贡献者加入，共同构建一个能够融合多元化技术架构的企业级开源数据库社区。OceanBase开源版将与商业版共同演进，愿和全球开发者、伙伴共同演化出丰富的数据处理产品，促进社区的繁荣。” 据悉，OceanBase是蚂蚁自主研发的分布式数据库，经历过阿里超大规模业务场景、支付宝金融级场景以及双11等战役的历练，并于2017年开始对外输出。目前该产品已在多家机构落地应用，包括中国工商银行、山东移动、福建移动、数字江西、中国石化、中华财险、人保健康、浙商证券、天津银行、西安银行、常熟农商行、东莞银行等。 11年发展，OceanBase已经成为世界领先的数据库产品。2019年和2020年连续刷新事务处理任务（TPC-C）基准测试世界纪录。 OceanBase 是由蚂蚁金服、阿里巴巴完全自主研发的金融级分布式关系数据库，始创于2010年。OceanBase具有数据强一致、高可用、高性能、在线扩展、高度兼容SQL标准和主流关系数据库、低成本等特点。 2015 年，淘宝顶级科学家阳振坤微博号@阿里正祥 ，发布过一则消息“从上周五开始，淘宝/天猫/聚划算在支付宝上的交易，100% 都在 OceanBase 上了。你可能没有什么感觉。” OceanBase 也凭借强劲的性能成为过去多年「双11」支付宝交易处理系统的守护神。数亿人能够随时随地网购、移动支付，背后靠的都是 OceanBase 数据库的力量。 也正是「双11」带来的极限压力测试，逼迫阿里巴巴放弃原有数据库架构，开发出了 OceanBase。使得该数据库具有数据强度一致、高可用、高性能、在线扩展、高度兼容 SQL 标准和主流关系数据库、低成本等优点。 2019 年 10 月 2 号，OceanBase 在数据库 TPC-C 基准测试中拿了第一名，打破了 Oracle 保持9年的纪录，造就了新的世界纪录。 TPC-C是全球主流计算机硬件厂商、数据库厂商公认的评价标准，被誉为“数据库领域的世界杯”。 OceanBase 能够取得这样的成绩，是中国技术人的技术沉淀。在实战中摸爬滚打，业务催生技术不断突破，效率倒逼技术迭代更新。 就在刚刚，OceanBase 开源了！ 数据库开发人员及相关从业者将可以通过 OceanBase 官网、GitHub 等渠道下载体验 OceanBase 源码。这是 OceanBase 由闭源软件售卖走向开源商业模式关键一步。 但是：如何平衡商业和开源，开源的是不是阉割版？后面还会不会闭源？ 这些问题一切都是未知数，毕竟早在 2013 年， OceanBase 就已经开源了，不过后面又闭源了。 地址：https://open.oceanbase.com/ 开源：https://github.com/oceanbase/oceanbase","categories":[],"tags":[]},{"title":"录屏软件推荐","slug":"录屏软件推荐","date":"2021-05-26T11:15:01.000Z","updated":"2021-05-26T09:45:34.657Z","comments":true,"path":"posts/247db835.html","link":"","permalink":"https://chengtong.me/posts/247db835.html","excerpt":"","text":"总结推荐使用Apowersoft免费在线录屏、EV 录屏、OBS、Captura、Screen To Gif；有预算的话，Bandicam，Camtasia也不错。 一、Win10自带录屏现在电脑录屏软件越来越多，功能越来越复杂反而有点眼花缭乱，下载了还得花时间去学，实在是得不偿失！ 如果是简单的录屏需求，我极力推荐你使用Win10自带的录屏工具就够了。什么？还有人不知道Win10有自带的录屏工具？那你可Out了，赶快认真看一看。 使用方法： 1、按下键盘快捷键「Win + G」，弹出一个对话框，勾选「是的，这是一个游戏」。（因为Win10这个功能就是为了游戏录制设计的，所以有此弹窗） 2、点击工具栏中的红色按钮，即可开始录制电脑屏幕，如果需要录制麦克风，记得勾选底下按钮。 3、开始录屏后，工具栏会缩小在屏幕上，结束录制时，点击工具栏的白色小框即可。 4、录屏结束后，打开「我的电脑」，点击「视频」，里面有一个「捕获」文件夹，刚录制的视频就在里面。 这就是Win10自带的录屏方法，除了可设置选项有点少之外没有其他的缺点，简单的录屏需求绝对可以满足了。 二、PPT自带录屏如果你按「Win + G」没有任何反应，说明你的系统不是Win10或者版本太低，这时候我们也可以尝试下PPT自带的录屏。 使用方法： 1、打开PPT2016，点击「插入」，找到最右边的「屏幕录制」按钮。 2、点击屏幕录制之后，先设置是否开启音频、记录指针，然后选择录制区域。 3、选择完录制区域后，点击左侧「录制」按钮或者按快捷键「Win + Shift + R」，倒计时3秒后即可开始录制。 4、录制完成后，按「Win + Shift + Q」停止录制，已录制视频就会出现在PPT上了，可以对着视频右击，选择「将媒体另存为」，再选择保存位置即可将录制的视频导出。 三、Apowersoft免费在线录屏官网：https://www.apowersoft.cn/free-online-screen-recorder 如果你懒得下载软件，你就可以使用Apowersoft在线录屏，支持Windows和MacOS ，是一款轻量且免费的页面应用，无需安装Java程序，第一次使用时需要安装一个启动程序，就直接在线录制屏幕，可以根据自己的需求对某一区域的活动进行录制，也可以录制整个电脑屏幕及网络摄像头。 装好启动器之后，直接点击网页上的【开始录制】，允许调用，无水印录制，实时编辑视频功能、但这需要注册一个账号，支持WMV、AVI、MP4等多种导出格式，满足不同平台对视频格式的要求。 录制时长没有限制，可以录制完整的电视节目、在线课程等，以便可以稍后观看。录制的过程中任意添加多种颜色、线框、文本、箭头图标等等为视频做标记，不用等视频录制结束后再进行编辑了，录制视频完成后，您可以在给定的选项中，将视频保存到本地或上传到录咖云端存储，上传完毕后，就可以与同事、朋友在社交网络中分享了。 四、EV 录屏官网：https://www.ieway.cn/evcapture.html EV 录屏，一个简单易用的免费录屏软件，录屏之前无需过多的设置就可以开始录制视频。 至于操作就不多介绍了，录屏软件在使用上都差不多，但EV的优点是录屏效果且内存小，真的很香。 五、Screen To Gif官网：https://www.screentogif.com 一个体积很小的录屏软件，免费好用，简单易上手！ 这个录屏软件是我最常用的一个，平时录动图都是用它！它的强大之处在于，能够对录制的视频进行多方面编辑，功能非常全面。 六、Ocam官网：https://ohsoft.net/eng/ 下载地址：https://ocam.en.softonic.com/ 一款免费、操作简单，功能齐全的录屏软件。 每次启动后，需要先选择图像保存路径，录制范围可以随意调整，支持全屏录制，但界面有广告。 七、Captura官网：https://mathewsachin.github.io/Captura/ 一个免费开源的录屏软件，软件体积轻巧，而且没有广告，非常良心。 页面设计简洁，支持摄像头、全屏、窗口、区域录制，声音录制的话支持系统声音和麦克风声音的录制。 还支持光标、鼠标点击、按键、录屏时长的录制，在设置中的视频选项中，可以打开或者关闭这些设置。 在下面可以设置视频帧率，还可以设置录制倒计时时间和录制持续时间，比如录制持续时间设为60秒，那录制1分钟之后就会自动停止录制。 在右边可以选择视频编码器和视频格式，编码器建议选择FFmpeg，录屏格式支持MP4和Avi两种格式，视频质量也可以自己调整。 Captura怎么设置中文操作步骤如下： 1、进入到主界面后，点击左边栏目中的设置，找到“Language”选项，软件默认为English，如下图所示： 2、在上一步点击Language，选择其中的“Chinese”中文选项，如下图所示： 3、成功设置完成后，可以看到软件的界面已经成功变为中文了，如下图所示： 八、Open Broadcaster Softwarehttps://obsproject.com/ Open Broadcaster Software，简称 OBS，是一个开源的视频推流软件，可用于直播和录屏，支持 Windows、macOS 和 Linux 系统。 当你要进行录制时，需要先创建录制窗口，点击来源面板左下角的加号，选择显示器捕获/采集，点击两次确定，就完成了录制窗口的创建。 创建录制窗口后，需要对录制的窗口大小进行调整，如下图，软件内的红色边框即为录制窗口的边缘，完成窗口大小的调整后，点击右边的开始录制，即可开始录制视频。 打开软件设置，切换到「输出」选项卡，你可以设置录像的质量和格式，录制质量即视频码率，默认为 2500 Kbps，格式默认为 mkv。 在「视频」选项卡中，你可以设置录屏得到的视频分辨率和帧速率，默认的输出分辨率为 1280*720，如果你想获得更好的画质，可以将输出分辨率设置为基础分辨率一样的大小。 九、Bandicam 班迪录屏官网：https://www.bandicam.cn/ 价格：¥249元一次付款，授权终身有效(购买 Bandicam 正式版，不受10分钟录制时间限制，并去除水印“www.BANDICAM.com”。并且购买的注册码保存好好可以永久使用产品。) Bandicam作为录屏行业领先代表，它可以解决配置低的电脑容易出现的视频录制不同步问题。Bandicam可录制分辨率可高达2560×1600高画质视频，支持自主添加LOGO和水印，非常简单好上手！ 十、Camtasiahttps://www.techsmith.com/video-editor.html Camtasia，是一个收费的视频录制软件，支持 Windows 和 macOS 系统，相比前面介绍的录屏软件，Camtasia 增加了视频剪辑的功能。 费用：$ 249.99","categories":[{"name":"录屏软件","slug":"录屏软件","permalink":"https://chengtong.me/categories/录屏软件/"}],"tags":[{"name":"Windows10","slug":"Windows10","permalink":"https://chengtong.me/tags/Windows10/"},{"name":"macOS","slug":"macOS","permalink":"https://chengtong.me/tags/macOS/"}]},{"title":"Hexo打包，内存溢出","slug":"Hexo打包，内存溢出","date":"2020-12-15T10:50:09.000Z","updated":"2021-06-02T10:17:36.114Z","comments":true,"path":"posts/538c8c9a.html","link":"","permalink":"https://chengtong.me/posts/538c8c9a.html","excerpt":"","text":"Hexo打包，内存溢出错误描述CALL_AND_RETRY_LAST Allocation failed - JavaScript heap out of memory（内存溢出） 原因分析报错中有句关键的话，CALL_AND_RETRY_LAST Allocation failed - JavaScript heap out of memory JavaScript堆内存不足，这里说的 JavaScript 其实就是 Node，我们都知道 Node 是基于V8引擎，在一般的后端开发语言中，在基本的内存使用上没有什么限制，但是在 Node 中通过 JavaScript 使用内存时只能使用部分内存（64位系统下约为1.4 GB，32位系统下约为0.7 GB），这就是我们编译项目时为什么会出现内存泄露了 解决方案方案1在node_modules中的hexo.cmd中添加max-old-space-sizewindows环境在项目中可以找到以下路径 1./node_modules/.bin/hexo.cmd 添加 –max-old-space-size=4096 1234567@IF EXIST \"%~dp0\\node.exe\" ( \"%~dp0\\node.exe\" \"%~dp0\\..\\hexo\\bin\\hexo\" %*) ELSE ( @SETLOCAL @SET PATHEXT=%PATHEXT:;.JS;=;% node --max-old-space-size=4096 \"%~dp0\\..\\hexo\\bin\\hexo\" %*) 方案2全局安装 increase-memory-limit 1、全局安装 increase-memory-limit 1npm install -g increase-memory-limit 2、进入工程目录，执行： 1increase-memory-limit 3、重启项目即可","categories":[],"tags":[]},{"title":"CentOS7升级新版OpenSSL","slug":"CentOS7升级新版OpenSSL","date":"2020-12-14T14:09:49.000Z","updated":"2021-02-19T09:10:19.705Z","comments":true,"path":"posts/19e8a435.html","link":"","permalink":"https://chengtong.me/posts/19e8a435.html","excerpt":"","text":"一、主机基本信息 操作系统：CentOS Linux release 7.8.2003 (Core) 内核版本：3.10.0-1127.13.1.el7.x86_64 温馨提示：升级OpenSSL前务必先做好快照备份，以免操作失误导致系统崩溃 受影响的版本： OpenSSL 1.1.1 ～ 1.1.1h OpenSSL 1.0.2 ～ 1.0.2w 安全版本： OpenSSL 1.1.1i OpenSSL 1.0.2x 二、下载OpenSSL源码包（当前最新版本为1.1.1i）腾讯云OpenSSL软件源：https://mirrors.cloud.tencent.com/openssl/source/ 1234# 下载源码包wget https://mirrors.cloud.tencent.com/openssl/source/openssl-1.1.1i.tar.gz -O /usr/local/src/openssl-1.1.1i.tar.gz# 源码编译依赖gcc和perl（5.0版本以上）yum -y install gcc perl 三、源码编译安装123456789# 压缩包解压cd /usr/local/srctar xf openssl-1.1.1i.tar.gz# 切换到源码目录cd openssl-1.1.1i# 执行编译./config --prefix=/usr/local/openssl./config -tmake &amp;&amp; make install 四、使用新版OpenSSL123456789101112# 查询旧版OpenSSLrpm -qa | grep openssl# 卸载旧版OpenSSL（--nodeps参数表示忽略依赖关系）rpm -e openssl --nodeps# 使用新版OpenSSLln -s /usr/local/openssl/bin/openssl /usr/bin/openssl# 添加函数库echo \"/usr/local/openssl/lib\" &gt;&gt; /etc/ld.so.conf# 更新函数库ldconfig -v# 检查新版OpenSSLopenssl version -a 五、注意事项 系统旧版openssl软件包可以卸载，openssl其他附属软件包不建议卸载 系统默认安装的openssl-libs不能卸载，否则系统可能会崩溃","categories":[{"name":"Linux","slug":"Linux","permalink":"https://chengtong.me/categories/Linux/"}],"tags":[{"name":"CentOS","slug":"CentOS","permalink":"https://chengtong.me/tags/CentOS/"}]},{"title":"Spring Boot 2.4 新特性","slug":"Spring Boot 2.4 新特性","date":"2020-11-22T14:05:52.000Z","updated":"2020-12-16T07:19:09.284Z","comments":true,"path":"posts/f3154141.html","link":"","permalink":"https://chengtong.me/posts/f3154141.html","excerpt":"","text":"Spring Boot 官网看了下，果然 2.4.0 了，我顿时傻眼了，又得写文章了，看来我消息还是稍微有点滞后了… Spring Boot 2.4.0 这么快就发布了，Spring Boot 更新也太快了，很多同学表示学不来了，学不动了。学不动也要学啊，不然就要被淘汰了，Java技术栈所有 Spring Boot 教程和示例源码都上传到 Github 了，欢迎 Star： https://github.com/javastacks/spring-boot-best-practice 带大家来解读下 Spring Boot 2.4.0 到底更新了什么鬼？ 一、支持 Java 15Spring Boot 2.4.0 支持 Java 15 了，同时向下兼容 Java 11 和 Java 8。 二、依赖升级Spring Boot 2.4.0 升级了一些主要的 Spring 项目： Spring AMQP 2.3 Spring Batch 4.3 Spring Data 2020.0 Spring Framework 5.3 Spring HATEOAS 1.2 Spring Integration 5.4 Spring Kafka 2.6 Spring Retry 1.3 Spring Security 5.4 Spring Session 2020.0 另外，还尽可能升级了一些第三方库到最新稳定版本： Artemis 2.13 AssertJ 3.18 Cassandra Driver 4.7 Elasticsearch 7.9 Flyway 7 Jersey 2.31 JUnit 5.7 Liquibase 3.10 Lettuce 6.0 Micrometer 1.6 Mockito 3.4 MongoDB 4.1 Oracle Database 19.7 Reactor 2020.0 RSocket 1.1 Undertow 2.2 …… 三、配置改进1、改进配置文件的处理方式Spring Boot 2.4 改进了处理 application.properties 和 application.yml 配置文件的方式。更新后的逻辑旨在简化和合理化外部配置的加载方式，但有些参数的组合形式却得到了限制，升级请谨慎。 如果你的应用工程只有一个简单的 application.properties 或 application.yml 文件，则可以进行无缝升级到 Spring Boot 2.4.0。 但是，如果你的配置较为复杂，比如说有指定 profile 的参数，或者有基于 profile 激活的参数，要使用新功能就需要进行一些更改。 更多细节可参考： https://github.com/spring-projects/spring-boot/wiki/Spring-Boot-Config-Data-Migration-Guide 如果你想继续使用 Spring Boot 2.3 的配置逻辑，也可以通过在 application.properties 或者 application.yml 配置文件中添加以下参数： spring.config.use-legacy-processing = true 2、导入配置参数改进通过配置参数 spring.config.location 和 spring.config.import 来指定或者导入配置文件时，如果配置文件不存在，现在不是只能默默地失败了，可以通过添加 optional: 前缀来标识它是可选的。 比如我们从 /etc/config/application.properties 指定配置文件，如果这个文件不存在，系统就会跳过它。 spring.config.location=optional:/etc/config/application.properties 如果你想将所有指定的配置文件都默认为可选的，可以通过 SpringApplication.setDefaultProperties(…) 来设置 spring.config.on-location-not-found=ignore 这个参数，或者将它设置在系统环境变量中。 3、支持导入配置树新版本的 spring.config.import 属性还可以用于导入配置树，通过与 Kubernetes 一起使用，配置树是提供键/值对的另一种方法，每一个键值/对都在其自己的文件中声明，文件名是键，文件内容就是值。 另外，从配置树导入的参数默认会带一个换行符。 详细的参考： https://docs.spring.io/spring-boot/docs/2.4.0/reference/html/spring-boot-features.html#boot-features-external-config-files-configtree 具体的配置上的细节暂时没有时间详细研究了，后面有机会再详细介绍一篇，关注公众号Java技术栈第一时间推送。 四、新增启动端点Spring Boot 2.4.0 添加了一个新的启动端点，用来显示应用启动有关的详细信息，比如可以帮助我们来诊断启动时间比预期更长的 Spring Beans。 这个功能建立在 Spring Framwork 5.3 最近添加的应用程序启动跟踪特性的基础上，感兴趣的可以在 Spring 框架文档中阅读有关该功能的更多信息。 https://docs.spring.io/spring-framework/docs/5.3.x/reference/html/core.html#context-functionality-startup 五、新增起源链（Origin Chains）Origin 接口更新了，使用了全新的 getParent() 方法，这样就可以提供完整的参数起源链，以准确显示某一项参数的来源。 比如你在 application.properties 配置文件中使用 spring.config.import 来导入第二个配置文件的参数，从第二个配置文件加载的参数的 Origin 将具有一个指向原始导入声明的父级。 说白了就是可以看到参数从哪里导进来的，可以通过 actuator/env 或者 actuator/configprops 端点来查看与之相关的输出信息，这里暂不详细研究了，后面有机会再详细介绍一篇，关注公众号Java技术栈第一时间推送。 六、Docker 支持升级1、镜像发布Spring Boot Maven 插件的 spring-boot:build-image 指令和 Gradle 插件的 bootBuildImage 任务现在可以直接发布 Docker 镜像到 Docker 注册中心了。 2、授权机制当使用 Spring Boot 构建时，可以为构建器或者运行镜像使用私有授权的 Docker 私有注册中心，支持用户名/密码认证以及基于 Token 机制认证。 更多详细的配置可以参考对应的插件文档： Maven： https://docs.spring.io/spring-boot/docs/2.4.0/maven-plugin/reference/htmlsingle/#build-image-example-publish Gradle： https://docs.spring.io/spring-boot/docs/2.4.0/gradle-plugin/reference/htmlsingle/#build-image-example-publish 七、移除了 JUnit 5’s Vintage 引擎Spring Boot 2.4.0 从 spring-boot-starter-test 中移除了 JUnit 5 Vintage 引擎，JUnit 5 可以通过 vintage 引擎来运行 JUnit 4 编写的测试用例，说白了就是兼容 JUnit 4 呗。 如果你不想迁移测试用例到 JUnit 5 而继续使用 JUnit 4，添加以下 Maven 依赖即可： 1234567891011&lt;dependency&gt; &lt;groupId&gt;org.junit.vintage&lt;/groupId&gt; &lt;artifactId&gt;junit-vintage-engine&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.hamcrest&lt;/groupId&gt; &lt;artifactId&gt;hamcrest-core&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt; 以下为对应的 Gradle 配置： 123testImplementation(&quot;org.junit.vintage:junit-vintage-engine&quot;) &#123; exclude group: &quot;org.hamcrest&quot;, module: &quot;hamcrest-core&quot;&#125; 八、通用宏简化Cron表达式(全新的Cron表达式处理机制)说起 cron 表达式大家一定不陌生，我们常用来作为定时任务执行策略规则。 在 Spring Boot 框架中 cron 表达式主要配合 @Scheduled 注解在应用程序中使用。 在 Spring Boot 2.4 （既 Spring 5.3）以后,引入了 CronExpression表达式处理器来替代原有的 CronSequenceGenerator。 为什么要替代原有的 CronSequenceGenerator ? 此处理器是基于 java.util.Calendar局限性比较大，无法完成last day of month 语义。 例如利用CronExpression 计算表达式下次执行时间 123456789101112LocalDateTime now = LocalDateTime.now();System.out.println(\"当前运行时间: \" + now);// 每小时执行一次CronExpression expression1 = CronExpression.parse(\"0 0 0/1 * * *\");LocalDateTime nextTime = expression1.next(now);System.out.println(\"每小时执行一次 -&gt; 下次执行时间: \" + nextTime); // 每小时第十分执行一次CronExpression expression2 = CronExpression.parse(\"0 10 0/1 * * *\");LocalDateTime nextTime2 = expression2.next(now);System.out.println(\"每小时第十分执行 -&gt; 下次执行时间: \" + nextTime2); 执行结果 123当前运行时间: 2020-11-14T23:04:46.302739每小时执行一次 -&gt; 下次执行时间: 2020-11-15T00:00每小时第十分执行 -&gt; 下次执行时间: 2020-11-14T23:10 新增常用表达式通用宏 对于非开发人员来说 cron 表达式并不容易理解，所以很难在出现错误的时候进行修复。比如笔者会把 cron 表达式 在在线网站 模拟运行一下，确认执行过程方便排查问题。 为了提高可读性，Spring Boot 现在支持以下代表常用表达式的宏。可以使用这些宏而不是六位的表达式，因此： 1@Scheduled(cron = &quot;@hourly&quot;)。 相当于 1@Scheduled(cron = &quot;0 0 * * * *&quot;) 其他常用宏命令 宏 cron 表达式 含义 @yearly 0 0 0 1 1 * 每年执行一次 @monthly 0 0 0 1 每月执行一次 @weekly 0 0 0 0 每周执行一次 @daily 或@annually 0 0 0 * 每天执行一次 @hourly 0 0 每小时执行一次 增强原有表达式 最后几天 1234567 每周的第几天 | ∨* * * * * * ^ | 每月的第几天 如上其中的 每月的第几天、每周的第几天 支持 最后几天 （L） 的语义例如： 12345670 0 0 L * * 每月最后一天的零时0 0 0 L-3 * * 每月最后第三天的零时 (L-d 格式)0 0 0 * * 5L 每月最后的星期五零时 （dL 格式）0 0 0 * * FRIL 每月最后的星期五零时 （ (星期一星期天的英文缩写)L 格式） 增强原有表达式 工作日 1234* * * * * * ^ | 每月的第几天 如上其中的 每月的第几天 支持 工作日 （W）的语义例如: 120 0 0 1W * * 每月的第一个工作日零时0 0 0 LW * * 每月的最后一个工作日零时 增强原有表达式 几周的星期几 1234 每周的第几天 | ∨* * * * * * 如上其中的 每周的第几天 支持 每月第几周的第几天语义例如 1230 0 0 ? * 5#2 每月第二周的星期五零时0 0 0 ? * MON#1 每月周一的星期一零时 九、jar自动瘦身自动分析瘦身 Spring Boot 项目最终构建处理 JAR 包大小一直是个诟病，需要把所有依赖包内置最终输出可运行的 jar。 当然可以使用其他的插件扩展 实现依赖 JAR 和 可运行 jar 分离可以参考 slot-maven-plugin, 但此种方法治标不治本并不能减少原有依赖的 JAR 的大小。 Spring Boot 2.4 提供对构建输出 JAR 分析自动瘦身的功能，自动在构建输出可运行 JAR 时删除 empty starter dependencies 效果展示 先来分别基于 Spring Boot 2.4.0 和 Spring Boot 2.3.6 来构建一个可运行的 jar ，再来聊什么是 empty starter 使用 start.spring.io 创建一个空的 Spring Boot 项目，注意不需要引入任何依赖 mvn clean install 构建出来相关可运行 jar 分别解压两个 jar 到两个不同的目录 123tar -zxvf demo-2.3.6.jar -C demo-2.3.6/tar -zxvf demo-2.4.0.jar -C demo-2.4.0/12 统计依赖 jar 个数, 2.3.6 共计 19 个 依赖 jar 而 2.4.0 只有 18 个依赖 jar ,缺少了 spring-boot-starter.jar 12345cd demo-2.3.6/BOOT-INF/lib &amp;&amp; ll -h | wc -l19cd demo-2.4.0/BOOT-INF/lib &amp;&amp; ll -h | wc -l181234 什么是 empty starter 如上文所述，我们在基于 start.spring.io 创建项目的时候 已经默认引入了, 但在 Spring Boot 2.4 中会自动删除此类 empty starter dependencies jar 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt;&lt;/dependency&gt;123 我们来看一下 spring-boot-stater 有什么特殊性？ ① 空 jar 不包含任何代码 ② 有引用其他 jar,只为批量导入其他 jar 所以此类型 jar 在构建成可运行 jar 时并未实际意义，因为批量导入的依赖 jar 都可以被引入。目前 spring boot 提供的 redis、amqp等大部分 starter 均是此类 jar,所以在构建后会自动删除。 自定义 jar 实现自动瘦身 创建 MANIFEST.MF jar 包元信息，添加一行 Spring-Boot-Jar-Type: dependencies-starter 即可 1234resources ├── META-INF └── MANIFEST.MF123 十、其他更新Spring Boot 2.4.0 发布更新说明中还包括了许多其他的更新和改进，比如说在 Spring Boot 2.4.0 中标识了在下个版本中计划废弃的不推荐使用的类和方法等。 以上就是 Spring Boot 2.4.0 的主要变更内容，当然还有许多发布细节，感兴趣的可以研究下这个更新说明： https://github.com/spring-projects/spring-boot/wiki/Spring-Boot-2.4-Release-Notes","categories":[{"name":"JAVA","slug":"JAVA","permalink":"https://chengtong.me/categories/JAVA/"}],"tags":[{"name":"Spring Boot","slug":"Spring-Boot","permalink":"https://chengtong.me/tags/Spring-Boot/"}]},{"title":"Dockerfile MAINTAINER和LABEL指令 语法解析","slug":"Dockerfile MAINTAINER和LABEL指令 语法解析","date":"2020-11-06T12:15:01.000Z","updated":"2021-06-02T02:48:23.661Z","comments":true,"path":"posts/cd0d1ec5.html","link":"","permalink":"https://chengtong.me/posts/cd0d1ec5.html","excerpt":"","text":"任何文件系统中的数据分为数据和元数据。数据是指普通文件中的实际数据，而元数据指用来描述一个文件的特征的系统数据，诸如访问权限、文件拥有者等等。Docker提供了MAINTAINER和LABEL用于处理镜像的元数据。 MAINTAINER 指令MAINTAINER 语法1MAINTAINER &lt;name&gt; MAINTAINER 语义 指定镜像作者信息，即镜像的Author属性。LABEL是一个更灵活的版本，可以替代MAINTAINER，LABEL可以设置任何需要设置的元数据，并且可以轻松查看，例如docker inspect。使用LABEL设置MAINTAINER可以使用如下命令： 1LABEL CHENGTONG=\"IM.CHENGTONG@GMAIL.COM\" MAINTAINER 示例MAINTAINER 指令示例 创建Dockerfile文件。 123FROM nginx:alpineMAINTAINER CHENGTONG \"IM.CHENGTONG@GMAIL.COM\"CMD /bin/bash 执行如下的构建命令，基于Dockerfile构建镜像。 1docker build -t nginx:1.0 . 通过docker inspect命令查看镜像Author的值。 1docker inspect -f &#123;&#123;\".Author\"&#125;&#125; eb5ad0af61d7 · LABEL 指令示例 进入/securitit/dockerfile/目录（根据个人选择，这是本文使用的目录），编辑dockerfile文件。 123FROM nginx:alpineLABEL CHENGTONG=\"IM.CHENGTONG@GMAIL.COM\"CMD /bin/bash 执行如下的构建命令，基于dockerfile构建镜像。 1docker build -t nginx:1.1 . 通过docker inspect命令查看镜像Config.Labels.maintainer的值。 1docker inspect -f &#123;&#123;\".Config.Labels.CHENGTONG\"&#125;&#125; f5b71b3f6510 MAINTAINER 注意 按照官方文档描述，可以使用LABEL maintainer=”xxx”代替MAINTAINER xxx，但还是需要注意两者设置的值，在镜像的描述文件中所处位置是不一样的。 · MAINTAINER xxx位于顶层Author属性中。 · LABEL maintainer=”xxx”位于Config.Labels.maintainer属性中。 LABEL 指令LABEL 语法1LABEL &lt;key&gt;=&lt;value&gt; &lt;key&gt;=&lt;value&gt; &lt;key&gt;=&lt;value&gt; ... LABEL 语义 · LABEL为镜像增加元数据，一个LABEL是键值对，多个键值对之间使用空格分开，命令换行时是使用反斜杠\\。 12345LABEL \"email\"=\"Securitit@13.com\"LABEL email-host=\"www.host.com\"LABEL email-version=\"1.0\"LABEL email-description=\"This is my \\ persional email.\" · 一个镜像可以有很多LABEL，可以在一行中指定多个元数据。方法有以下两种： 1LABEL multi.label-1=&quot;value-1&quot; multi.label-2=&quot;value-2&quot; multi.label-3=&quot;value-3&quot; 123LABEL multi.label-1=&quot;value-1&quot; \\ multi.label-2=&quot;value-2&quot; \\ multi.label-3=&quot;value-3&quot; · 基础镜像或父镜像中包含的元数据由当前镜像继承。如果元数据已经存在，但具有不同的值，则最近应用的值将覆盖以前设置的任何值。 LABEL 示例 · 单指令设置多个元数据 创建Dockerfile文件。 123456FROM nginx:alpineLABEL email=\"Securitit@163.com\" \\ email-host=\"www.host.com\" \\ email-description=\"This is my \\persional email.\"CMD /bin/bash 执行如下的构建命令，基于Dockerfile构建镜像。 1docker build -t nginx:1.2 . 通过docker inspect命令查看镜像Config.Labels.maintainer的值。 1docker inspect -f &#123;&#123;&quot;.Config.Labels&quot;&#125;&#125; 7a02315aaeee · 继承元数据示例 编辑dockerfile文件，只修改email的内容，其他内容期望从nginx:1.2继承。 123FROM nginx:1.2LABEL email=\"Securitit@126.com\"CMD /bin/bash 执行如下的构建命令，基于dockerfile构建镜像。 1docker build -t nginx:1.3 . 通过docker inspect命令查看镜像Config.Labels.maintainer的值。 1docker inspect -f &#123;&#123;&quot;.Config.Labels&quot;&#125;&#125; f360ed26570d 可以看到除了email外，email-host和email-description均是从基础镜像中继承得来的。 总结 MAINTAINER已经过时，在新版本已不推荐使用，推荐使用LABEL完成元数据设置。","categories":[{"name":"容器","slug":"容器","permalink":"https://chengtong.me/categories/容器/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://chengtong.me/tags/Docker/"},{"name":"Dockerfile","slug":"Dockerfile","permalink":"https://chengtong.me/tags/Dockerfile/"}]},{"title":"Lombok注解实现final属性的构造注入","slug":"Lombok注解实现final属性的构造注入","date":"2020-10-30T14:54:00.000Z","updated":"2020-12-09T08:01:54.413Z","comments":true,"path":"posts/3dfd485f.html","link":"","permalink":"https://chengtong.me/posts/3dfd485f.html","excerpt":"","text":"Lombok可以消除 Java 的冗长，减少代码的长度，让关注点转移到该专注的地方。 下面介绍几个常用的 lombok 注解： @Data ：注解在类上；提供类所有属性的 getting 和 setting 方法，此外还提供了equals、canEqual、hashCode、toString 方法 @Setter：注解在属性上；为属性提供 setting 方法 @Getter：注解在属性上；为属性提供 getting 方法 @Log4j ：注解在类上；为类提供一个 属性名为log 的 log4j 日志对象 @NoArgsConstructor：注解在类上；为类提供一个无参的构造方法 @AllArgsConstructor：注解在类上；为类提供一个全参的构造方法 SpringBoot把Lombok放到了它的依赖中，Java14甚至也借鉴了这种思想，推出了record语法，就是类似于下面这种： 1record Point(int x, int y) &#123; &#125; Spring提供了两种注入模式，这也是非常初级的程序员经常被问到的三种DI写法。 一种是属性注入(Filed injection)，一种是通过setter方法，一种是构造器注入。 三种方式的区别小结 1.基于constructor的注入，会固定依赖注入的顺序；该方式不允许我们创建bean对象之间的循环依赖关系，这种限制其实是一种利用构造器来注入的益处 - 当你甚至没有注意到使用setter注入的时候，Spring能解决循环依赖的问题； 2.基于setter的注入，只有当对象是需要被注入的时候它才会帮助我们注入依赖，而不是在初始化的时候就注入；另一方面如果你使用基于constructor注入，CGLIB不能创建一个代理，迫使你使用基于接口的代理或虚拟的无参数构造函数。 3.相信很多同学都选择使用直接在成员变量上写上注解来注入，正如我们所见，这种方式看起来非常好，精短，可读性高，不需要多余的代码，也方便维护； 缺点 1.当我们利用constructor来注入的时候，比较明显的一个缺点就是：假如我们需要注入的对象特别多的时候，我们的构造器就会显得非常的冗余、不好看，非常影响美观和可读性，维护起来也较为困难； 2.当我们选择setter方法来注入的时候，我们不能将对象设为final的； 3.当我们在field变量上来实现注入的时候 a.这样不符合JavaBean的规范，而且很有可能引起空指针； b.同时也不能将对象标为final的； c.类与DI容器高度耦合，我们不能在外部使用它； d.类不通过反射不能被实例化（例如单元测试中），你需要用DI容器去实例化它，这更像集成测试； 本篇文章，不打算讨论什么类似于@Data注解之类的。我们讨论一个比较偏门的，但是又让你感觉相见恨晚的一个注解：RequiredArgsConstructor。 属性注入经常被问的是byName和byType。不过，这年头，我们用的更多的是@Autowired或@Resource注解。 代码写起来一般是这样的。 12345678910111213@Servicepublic class GoodsServiceImpl implements GoodsSrv &#123; @Autowired private GoodsRepo goodsRepo; @Autowired private TagRepo tagRepo; @Autowired private TagRefRepo tagRefRepo; @Autowired private BrandRepo brandRepo; @Autowired private UnitRepo unitRepo;&#125; 这一般没什么问题，因为注入的字段是有限的。但如果你没见过一些项目代码，你会被这种程序界完美的表象给蒙骗了。 业务代码，不加注释，单文件长度超过2000行的比比皆是。注入的属性能达到十几个之多。这部分注入代码真是脏乱差。 不仅如此，这些字段，还会在IDE里变成灰色，告诉你未被初始化。 相信大部分人项目只要用了spring框架，肯定到处都是@Autowired。 来自Spring官方文档的建议 在Spring 3.x 中，Spring团队建议我们使用setter来注入 大致是说大量的构造器参数会显得非常笨重，尤其是当属性是可选的时候。setter方法可以使类的对象在后来重新配置或者重新注入。提供所有的依赖意味着对象总是返回一个完全初始化状态的client客户端(调用)。缺点是对象变得不那么适合重新配置和重新注入。 而在Spring 4.x 中，Spring团队不再建议我们使用setter来注入，改为了constructor： Spring团队通常建议使用构造器来注入，因为它允许一个应用程序组件实现为不可变对象，并确保所需的依赖项不是空。此外构造器注入组件总是返回一个完全初始化状态的client客户端(调用)。附注，大量的构造函数参数是一个糟糕的代码习惯，看起来也很坏，这意味着类可能有太多的责任，应该被重构，以更好地解决适当的关注点分离。 setter方法只应该主要的用在可以在类中指定合理的默认值的可选的依赖关系。否则，用到依赖的所有地方都应该进行非空检查。setter注入的一个好处是，setter方法使类的对象可以在之后重新配置或者重新注入。 从Spring4.3以后， 就 不 推 荐 使 用 属 性 注 入 模 式 了 ，原因是它可以让我们忽略掉一些代码可能变坏的隐患，全部更新内容: 地址；其中跟新内容如下 既然Spring推荐使用显示的Setter和构造器方式，那我们就切换一下实现方案。 Setter方法基本上用的人比较少，因为它更加臭更加长。要是给每一个属性写一个set方法，我估计你即使用代码生成器也玩吐了。 setter注入提供setting方法 12345678910@Controllerpublic class TestController &#123; private TestService testService; @Autowired public void setMyService(TestService testService) &#123; this.testService = testService; &#125; &#125; 使用 Lombok 进行setter注入 1234567@Service@Setter(onMethod_ = &#123;@Autowired&#125;)public class TestServiceImpl implements TestService &#123; private TestDao testDao; &#125; 编译后的内容如下： 1234567891011@Servicepublic class TestServiceImpl implements TestService &#123; private TestDao testDao; @Autowired public void setTestDao(final TestDao testDao) &#123; this.testDao= testDao; &#125; &#125; 构造器注入接下来插播一条Spring 4.3 的新特征： 在Spring 4.3 以后，如果我们的类中只有单个构造函数，那么Spring就会实现一个隐式的自动注入，那么构造器的方法就成了我们的首选。 示例代码1如下： 之前 12345678910@Servicepublic class FooService &#123; private final FooRepository repository; @Autowired public FooService(FooRepository repository) &#123; this.repository = repository &#125;&#125; 在Spring 4.3 之后： 123456789@Servicepublic class FooService &#123; private final FooRepository repository; public FooService(FooRepository repository) &#123; this.repository = repository &#125;&#125; 如我们所见，我去掉了构造器上的@Autowired注解，经测试后发现，程序能正常运行，repository的依赖也被成功注入了，当时感觉就很amazing 示例代码2如下： 12345678910111213141516171819202122public class GoodsServiceImpl implements GoodsSrv &#123; private GoodsRepo goodsRepo; private TagRepo tagRepo; private TagRefRepo tagRefRepo; private BrandRepo brandRepo; private UnitRepo unitRepo; public GoodsServiceImpl( GoodsRepo goodsRepo, TagRepo tagRepo, TagRefRepo tagRefRepo, BrandRepo brandRepo, UnitRepo unitRepo) &#123; this.goodsRepo = goodsRepo; this.tagRefRepo = tagRefRepo; this.tagRefRepo = tagRefRepo; this.brandRepo = brandRepo; this.unitRepo = unitRepo; this.tagRepo = tagRepo; &#125;&#125; Spring不需要加入其他注解，就可以使用构造器完成注入。问题是，我们依然要写很多代码。 这个时候，你可能想到了Lombok的AllArgsConstructor注解。 123456789@Service@AllArgsConstructor(onConstructor_ = &#123;@Autowired&#125;)public class GoodsServiceImpl implements GoodsSrv &#123; private GoodsRepo goodsRepo; private TagRepo tagRepo; private TagRefRepo tagRefRepo; private BrandRepo brandRepo; private UnitRepo unitRepo;&#125; 但它是针对于全部的属性的，如果类中有一些非Bean的属性，Spring就会晕菜。这个时候，就可以使用RequiredArgsConstructor了。 代码如下。 123456789@Service@RequiredArgsConstructorpublic class GoodsServiceImpl implements GoodsSrv &#123; final GoodsRepo goodsRepo; final TagRepo tagRepo; final TagRefRepo tagRefRepo; final BrandRepo brandRepo; final UnitRepo unitRepo;&#125; 我们把需要注入的属性，修改成final类型的（或者使用@NotNull注解，不推荐），这些属性将构成默认的构造器。Java要求final类型的属性必须要初始化，如果没有构造方法代码就会变红。 我们可以看到修改之后的IDE，恼人的灰色提示也消失了。 这样的代码，是非常简洁的。 这是执行此操作的真正好方法。您的代码保持非常干净。使用 Spring时，通常需要多个自动装配属性。当您需要添加另一个 bean 时，只需声明一个 final 属性。如果您重构并且不再需要 Spring 托管的依赖项，则只需删除 final 属性。你不再需要维护设置器或构造函数代码。Project Lombok 减轻了您的日常工作。我在日常编码中一直使用这种技术。绝对是节省时间。并导致更干净的代码。未使用的属性和未使用的构造函数参数已一去不复返了。重构现在不那么痛苦了！ 更高级一点RequiredArgsConstructor注解，你还可以像下面这样写。即使是把@__换成@_，或者换成@___，也是能正常的运行。 1@RequiredArgsConstructor(onConstructor = @__(@Autowired)) 它的意思是，给使用Lombok生成的构造器方法，加入一个@Autowired注解。这是彻头彻尾的Lombok语法，不过现在的Spring已经不需要加入这样的注解就能运行了。 示例代码如下： 123456@RequiredArgsConstructor(onConstructor = @__(@Autowired))public class OrderService &#123; //这里必须是final,若不使用final,用@NotNull注解也是可以的 private final UserService userService; &#125; 其他@Data@AllArgsConstructor@RequiredArgsConstructor都会针对final成员变量生成构造函数，所以，可以省略@Autowired、@Inject、@Resource等依赖注入注解。 @NoArgsConstructorConstructor先于@Autowired注解生效。","categories":[{"name":"JAVA","slug":"JAVA","permalink":"https://chengtong.me/categories/JAVA/"}],"tags":[{"name":"Lombok","slug":"Lombok","permalink":"https://chengtong.me/tags/Lombok/"}]},{"title":"CentOS8安装Docker出现package docker-ce-319.03.13-3.el7.x86_64 requires containerd.io = 1.2.2-3","slug":"CentOS8安装Docker出现package docker-ce-319.03.13-3.el7.x86_64 requires containerd.io = 1.2.2-3","date":"2020-10-02T15:15:56.000Z","updated":"2021-06-02T02:42:53.260Z","comments":true,"path":"posts/1e7ccb7b.html","link":"","permalink":"https://chengtong.me/posts/1e7ccb7b.html","excerpt":"","text":"CentOS8安装Docker出现package docker-ce-319.03.13-3.el7.x86_64 requires containerd.io = 1.2.2-3, but none of the providers can be installed 背景简介最近在阿里云上重置系统后，使用了CentOS8，正好尝尝鲜，尝试安装Docker时出现了错误，故及时记录一下，方面其他同学。 错误提示123456789101112Error:Problem: package docker-ce-3:19.03.13-3.el7.x86_64 requires containerd.io &gt;= 1.2.2-3, but none of the providers can be installed - cannot install the best candidate for the job - package containerd.io-1.2.10-3.2.el7.x86_64 is filtered out by modular filtering - package containerd.io-1.2.13-3.1.el7.x86_64 is filtered out by modular filtering - package containerd.io-1.2.13-3.2.el7.x86_64 is filtered out by modular filtering - package containerd.io-1.2.2-3.3.el7.x86_64 is filtered out by modular filtering - package containerd.io-1.2.2-3.el7.x86_64 is filtered out by modular filtering - package containerd.io-1.2.4-3.1.el7.x86_64 is filtered out by modular filtering - package containerd.io-1.2.5-3.1.el7.x86_64 is filtered out by modular filtering - package containerd.io-1.2.6-3.3.el7.x86_64 is filtered out by modular filtering - package containerd.io-1.3.7-3.1.el7.x86_64 is filtered out by modular filtering 安装步骤： 问题分析centos8默认使用podman代替docker，所以需要containerd.io，那我们就安装一下就好了 解决方法安装containerd.io即可 1yum install -y https://download.docker.com/linux/fedora/30/x86_64/stable/Packages/containerd.io-1.2.6-3.3.fc30.x86_64.rpm 然后继续安装Docker 1234567yum install -y yum-utils device-mapper-persistent-data lvm2yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo或yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repoyum install -y docker-ce systemctl start dockersystemctl enable docker","categories":[{"name":"Linux","slug":"Linux","permalink":"https://chengtong.me/categories/Linux/"}],"tags":[{"name":"CentOS","slug":"CentOS","permalink":"https://chengtong.me/tags/CentOS/"},{"name":"Docker","slug":"Docker","permalink":"https://chengtong.me/tags/Docker/"}]},{"title":"java.lang.NoClassDefFoundError","slug":"java.lang.NoClassDefFoundError","date":"2020-09-02T15:30:11.000Z","updated":"2020-09-03T06:08:12.038Z","comments":true,"path":"posts/91a9aa13.html","link":"","permalink":"https://chengtong.me/posts/91a9aa13.html","excerpt":"","text":"今天使用jdk11，出现了这个错误，错误如下： java.lang.NoClassDefFoundError: javax/activation/DataSource 故障原因： 123JAXB API是java EE 的API，因此在java SE 9.0 中不再包含这个 Jar 包。java 9 中引入了模块的概念，默认情况下，Java SE中将不再包含java EE 的Jar包而在 java 6/7 / 8 时关于这个API 都是捆绑在一起的 解决方案一降低JDK 版本到 JDK 8 解决方案二（亲测可行）手动加入这些依赖Jar包 1234567891011121314151617181920&lt;dependency&gt; &lt;groupId&gt;javax.xml.bind&lt;/groupId&gt; &lt;artifactId&gt;jaxb-api&lt;/artifactId&gt; &lt;version&gt;2.3.0&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.sun.xml.bind&lt;/groupId&gt; &lt;artifactId&gt;jaxb-impl&lt;/artifactId&gt; &lt;version&gt;2.3.0&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.sun.xml.bind&lt;/groupId&gt; &lt;artifactId&gt;jaxb-core&lt;/artifactId&gt; &lt;version&gt;2.3.0&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;javax.activation&lt;/groupId&gt; &lt;artifactId&gt;activation&lt;/artifactId&gt; &lt;version&gt;1.1.1&lt;/version&gt;&lt;/dependency&gt;","categories":[],"tags":[]},{"title":"【转】第三方直播SDK对比","slug":"【转】第三方直播SDK对比","date":"2020-07-28T12:14:00.000Z","updated":"2020-08-20T07:46:36.429Z","comments":true,"path":"posts/6532b32c.html","link":"","permalink":"https://chengtong.me/posts/6532b32c.html","excerpt":"","text":"看下哪个平台的更好一些。将相关官网的资料整理，做了一点对比，方便看到各平台优点。 首先看过各个平台直播SDK后大致知道平台SDK分为有2种： 直播：传统方式，1个主播，多个观众 互动直播：与普通的单向直播相比，赋予了观众露脸发声的权利，因此对实时性、抗回声的要求更高；主打“连麦”、“多画面特效”等能力。 以下内容是基于拥有连麦技术做的对比 主要功能对比 功能点 腾讯云 阿里云 网易云信 七牛云 金山云 声网 即构科技 文档更新时间 2019-05-15 2019-04-03 2018-11-20 2018-05-30 2018-12-18 2019-04-01 2019-05-15 案例 龙珠直播、now直播、小程序,斗鱼 全民直播，好未来，淘宝网 网易云课堂 熊猫直播、全民直播、龙珠直播 今日头条、龙珠直播 陌陌，花椒直播，狼人杀，斗鱼直播，B站 花椒直播，映客直播 直播推流 RTMP，录屏推流 RTMP RTMP RTMP RTMP 直播播放 RTMP、FLV 及 HLS RTMP、FLV及HLS RTMP、FLV及HLS RTMP-FLV、HTTP-FLV、HLS、HTTPS、mp4、mp4v RTMP/HTTP-FLV/HLS/HTTPS 直播连麦 1对1、1对多、多对多 N/A 支持4人同时语音、视频连麦互动并直播出去 1对1、1对多、 支持1对1连麦，1对多连麦处于开发中 1对1、1对多、多对多 业内首创 AI美颜特效 支持 支持 支持 支持 支持 支持 支持 H5页面及小程序播放 支持 支持 支持 支持 支持 支持 支持 支持android最低版本 Android 4.1 Android 4.3 Android 4.3 Android 4.0.3 Android 4.0.4 Android 4.1 Android 4.0.3 支持IOS最低版本 iOS 9.0 iOS 8.0 iOS 7.0 iOS 8.0 iOS7.0 iOS 8.0 iOS 7.0 多主播互动 10人 N/A 4人（需接入网易云信IM账号体系） 没有看到说明，翻api看到默认3人 从2017年6月起，金山云自研连麦不再开放给普通用户使用 17人 32人 最多观众人数 100万 100万 总的来说，腾讯云直播，七牛云，金山云更偏向于娱乐性的直播，网易云信是基于他的IM系统，而阿里云偏向服务器CDN，声网更擅长多对多音视频聊天，即构科技连麦技术最强大。 推流SDK其他功能比较由于金山云有个功能列表，所以列表是按金山云来列的（以下仅供参考，实际以官方文档为准） 功能点 腾讯云 阿里云 网易云信 七牛云 金山云 声网 即构科技 推流地址自定义 支持 N/A 支持 N/A 支持 支持 支持 视频软编码 支持 N/A 支持 支持 支持 支持 支持 视频硬编码 支持 支持 支持 支持 支持 支持 支持 美颜 支持 支持 支持 支持 支持 支持 支持 第三方美颜接口 N/A N/A N/A 支持 支持 N/A 支持 水印 支持 支持 支持 支持 支持 支持 支持 截图 支持 支持 支持 支持 支持 支持 支持 多视频分辨率支持 支持 支持 支持 支持 支持 支持 支持 横竖屏推流 支持 支持 支持 支持 支持 支持 动态横竖屏切换 支持 N/A 支持 支持 支持 支持 连麦 支持 N/A 支持 支持 支持 支持 支持 画中画 支持 N/A 支持 支持 支持 支持 支持 对焦/变焦 支持 支持 支持 支持 支持 支持 支持 镜像 支持 支持 支持 支持 支持 支持 支持 闪光灯 支持 支持 支持 支持 支持 支持 支持 耳返 支持 支持 支持 支持 支持 支持 蓝牙耳机 支持 N/A 支持 支持 支持 支持 混音 支持 支持 支持 IOS支持，android测试中 支持 支持 支持 混响 支持 N/A 支持 N/A 支持 支持 支持 纯音频推流 支持 支持 支持 支持 支持 支持 支持 后台音频推流 支持 支持 支持 支持 支持 支持 录屏 支持 支持 支持 支持 支持 支持 支持 短视频录制 支持 支持 支持 支持 支持 支持 支持 场景编码 支持 N/A 支持 支持 支持 支持 支持 动态帧率 支持 支持 支持 支持 支持 支持 支持 变声 支持 N/A 支持 支持 支持 支持 升降调 支持 N/A 支持 支持 支持 支持 立体声推流 支持 支持 支持 支持 支持 支持 支持 悬浮窗 支持 N/A 支持 降噪 N/A 支持 支持 支持 拉流SDK其他功能比较拉流详情我没有细看比较，基本都是播放之类的，常见播放器功能都有。 价格对比腾讯云官网地址：https://cloud.tencent.com/ 1.预付模式 流量/带宽的单位进制为1000，即：1TB = 1000GB。 直播流量资源包 价格（元） 连麦资源包（分钟数） 价格（元） 100GB 25 50000 2688（文档&amp;工单） 500GB 118 250000 9688（技术人员邀您加入技术群） 1TB 236 1000000 28988（技术人员邀您加入技术群） 5TB 1086 3000000 73888（单独拉群专人支持） 10TB 2172 赠SDK(1年) 50TB 8972 赠SDK(1年) 200TB 30198 赠SDK(1年) 1PB 149589 赠SDK(1年) 2.后付费模式 流量阶梯 价格(元/GB/天) 0 - 500GB 0.26 500GB（含）- 2TB 0.25 2TB（含）- 50TB 0.23 50TB（含）- 100TB 0.19 ≥ 100TB 0.16 带宽阶梯 价格(元/Mbps/天) 0 - 500Mbps 0.64 500Mbps（含）- 5Gbps 0.62 5Gbps（含）- 20Gbps 0.59 ≥ 20Gbps 0.58 阿里云官网地址：https://helpcdn.aliyun.com/ 1.按峰值带宽计费：是以当日直播观看区域所在节点直播加速服务分别产生的带宽最高值（单位Mbps）为结算标准。 使用直播95峰值带宽计费，需提交工单申请阿里云 带宽阶梯(元/Mbps/天) 价格 0~500Mbps（含） 0.66 500Mbps-5Gbps（含） 0.638 5Gbps-20Gbps（含） 0.616 大于20Gbps 0.594 2.流量阶梯价格计费：流量累积到自然月底，下月自动清零重新累积。 流量阶梯 价格 0-10TB（含） ¥0.264 10TB-50TB（含） ¥0.253 50TB-100TB（含） ¥0.231 100TB-1PB（含） ¥0.198 大于1PB ¥0.165 还有其他转码，截图，鉴黄识别，广告识别等等收费内容 网易云信官网地址：https://netease.im/ 1.“按流量”计费 = 流量费 + 增值服务费； 计费标准: 1元/GB 计费规则: 按视频直播服务消耗的上下行流量之和计费 计费周期: 按日计费 收费示例: 假设当日视频直播服务消耗的上下行流量之和为1000GB，则对应的日流量费为 (1000*1）元，即 1000元 2. “按日峰值带宽”计费 = 日峰值带宽费 + 增值服务费； 计费标准: 0.6元/Mbps/日 计费规则: 当日使用直播服务产生的上下行带宽之和峰值计费（单位Mbps） 计费周期: 按日计费 收费示例: 假设当日的峰值带宽为900Mbps，则对应的日带宽计费为 (900*0.6) 元，即 540元 增值服务费： 截图标准: 0.1元/千次 实时转码标准: 0.1元 / 分钟 七牛云官网地址：https://www.qiniu.com/ 官网没有看到介绍 金山云官网地址：https://www.ksyun.com/ 采用阶梯累进计费方式，价格阶梯如下： 流量阶梯 价格（单位：元/GB) 0-10TB（含） ¥0.22 10TB-50TB（含） ¥0.2 50TB-100TB（含） ¥0.18 100TB-1PB（含） ¥0.15 大于1PB ¥0.13 峰值带宽阶梯 价格（单位：元/Mbps/日） 0-500Mbps（含） ¥0.6 500Mbps-5Gbps（含） ¥0.56 大于5Gbps ¥0.52 声网 官网地址：https://docs.agora.io/ 每月免费使用10000分钟，不超过完全免费；超过部分单独计算： 分辨率720P 及以下28 元 / 1000分钟， 分辨率720P 以上105 元 / 1000分钟。 即构科技官网地址：https://www.zego.im/ 官网没有看到介绍 以按流量计费做的一个横向对比（720分辨率）注意声网是按分钟收费，不是流量，写在这里只是做个参照 阶梯 腾讯云（G） 阿里云（G） 网易云信（G） 七牛云 金山云（G） 声网（分钟） 即构科技 0 - 500GB 0.26 0.264 1 没有找到 0.22 10000分钟以内免费 没有找到 500GB（含）- 2TB 0.25 0.264 1 0.22 0.28 2-10TB（含） 0.23 0.264 1 0.22 0.28 10TB-50TB（含） 0.23 0.253 1 0.2 0.28 50TB-100TB（含） 0.19 0.231 1 0.18 0.28 100TB-1PB（含） 0.16 0.198 1 0.15 0.28 大于1PB 0.16 0.165 1 0.13 0.28 PS：直播，实时音视频，互动直播，旁路直播的概念：1.直播：（一对多，RTMP/HLS/HTTP-FLV，CDN）直播是一种非常典型的流媒体系统，通常会分为推流端（Pusher）、拉流端（或者叫播放端，Player）以及直播流媒体中心（直播源站），通常会使用CDN进行直播的分发，因此大部分情况下使用的是通用标准的协议，如RTMP，而经过CDN分发后，播放时一般可以选择RTMP、HTTP-FLV或HLS（H5支持）等方式。直播的特点是只有一个推流端，以及多个的观看端。 2.实时音视频：（双人/多人通话，UDP私有协议，低延时）实时音视频（Real-Time Communication, RTC）主要应用场景是音视频通话，技术关注点是低延时通信，因而使用基于UDP的私有协议，其延迟可低于100ms，适用于双人通话或是多人群组群话，典型的场景就是QQ电话、微信电话。 腾讯云实时音视频（TRTC）覆盖各平台，除了iOS/Android/Windows之后，还支持小程序以及 WebRTC 互通，并且支持通过云端混流的方式将画面旁路直播出去。当业务对延迟敏感，通话场景要求比较高，或是需要小程序或者 H5 场景下的双人或多人音视频通话可以选择实时音视频 TRTC。 3.互动直播：（连麦，二对多/多对多，私有协议+标准协议，DC/OC+CDN） 互动直播是在实时音视频的基础上，将实时音视频某个房间中的画面经云端混流后，通过旁路直播的方式直播出来。因此，互动直播主播与连麦者之间延迟与实时音视频一致，而主播/连麦者与普通观众之间的延时则与普通直播相同。 4.旁路直播（关键词：云端混流，转推，CDN）将主/副播实时音视频通话时的整个房间的画面复制一份到云端进行云端混流，并将混流后的画面推流给腾讯云直播系统的工作方式。 因为混流后的视频数据流和主/副播通话房间实际上并不是同一路流，而是在另外平行的一路，因而称为旁路，即不在主路。云端录制时，录制的流也是通过旁路的方式从流媒体中心引出，存到COS中。","categories":[{"name":"直播","slug":"直播","permalink":"https://chengtong.me/categories/直播/"}],"tags":[]},{"title":"视频直播技术","slug":"视频直播技术","date":"2020-07-24T15:40:01.000Z","updated":"2020-07-28T09:21:27.738Z","comments":true,"path":"posts/3d419aac.html","link":"","permalink":"https://chengtong.me/posts/3d419aac.html","excerpt":"","text":"我们将从整体介绍直播中的各个环节。 1.采集 采集是播放环节中的第一环，iOS 系统因为软硬件种类不多，硬件适配性较好，所以比较简单。Android 则不同，市面上硬件机型非常多，难以做到一个库适配所有硬件。PC 端的采集也跟各种摄像头驱动有关，推荐使用目前市面上最好用的 PC 端开源免费软件 OBS。 2.处理 「80% 的主播没有美颜根本没法看。」不光是美颜，很多其它的视频处理如模糊效果、水印等也都是在这个环节做。目前 iOS 端比较知名的是 GPUImage 这个库，提供了丰富的预处理效果，还可以基于这个库自己写算法实现更丰富的效果。Android 也有 GPUImage 这个库的移植，叫做 android-gpuimage。同时，Google 官方开源了一个伟大的库，覆盖了 Android 上面很多多媒体和图形图像相关的处理。 3.编码 编码主要难点有两个：1. 处理硬件兼容性问题。2. 在高 fps、低 bitrate 和音质画质之间找到平衡。iOS 端硬件兼容性较好，可以直接采用硬编。而 Android 的硬编的支持则难得多，需要支持各种硬件机型，推荐使用软编。 4.推流和传输 传输涉及到很多端：从主播端到服务端，从收流服务端到边缘节点，以及再从边缘节点到观众端。 推流端和分发端理论上需要支持的并发用户数应该都是亿级的，不过毕竟产生内容的推流端在少数，和消费内容的播放端不是一个量级，但是他们对推流稳定性和速度的要求比播放端高很多，这涉及到所有播放端能否看到直播，以及直播端质量如何。 很多人吐槽现在的 CDN 不靠谱，我也承认传统的 CDN 在新时代显得心有余力不足。你能够借助 CDN 快速实现大规模的流分发，但是稳定高速的推流上传可能还需要自己做很多工作。因此，我们七牛打造了一个直播专属的实时流网络，接下来我们会重点介绍这个网络和传统 CDN 的差别。 5.转码 为了让主播推上来的流适配各个平台端各种不同协议，需要在服务端做一些流处理工作，比如转码成不同格式支持不同协议如 RTMP、HLS 和 FLV，一路转多路流来适配各种不同的网络状况和不同分辨率的终端设备。 同时，为了配合一些运营需求，比如一些监管部门的要求，我们在服务端也提供了内容识别如鉴黄的功能。 6.解码和渲染 解码和渲染，也即音视频的播放，目前 iOS 端的播放兼容性较好，在延迟可接受的情况下使用 HLS 协议是最好的选择，我们也提供了能够播放 RTMP 和 HLS 的播放器 SDK。Android 的硬件解码和编码一样也存在兼容性问题，目前比较好的开源播放器是基于 ffplay 的 ijkplayer，我们也基于此实现了一个更好的 Android SDK。 除了 SDK 的介绍之外，我们将重点介绍播放器的原理，以及现代视频播放器的基本架构。 7.直播场景化解决方案 除了整个直播流程的介绍之外，我们将围绕当下最火的直播场景如社交直播和游戏直播，介绍它背后的技术方案。这些技术方案不仅涉及到七牛这样的直播基础服务，还可能涉及到和场景相关的其它技术，如社交直播下的聊天、点赞和弹幕的支持。","categories":[{"name":"直播","slug":"直播","permalink":"https://chengtong.me/categories/直播/"}],"tags":[]},{"title":"细数直播平台的六大分类","slug":"细数直播平台的六大分类","date":"2020-07-24T14:44:56.000Z","updated":"2020-07-28T09:21:27.735Z","comments":true,"path":"posts/18811265.html","link":"","permalink":"https://chengtong.me/posts/18811265.html","excerpt":"","text":"本质上说来，网络视频直播只是一种技术手段，利用这种技术手段所实现的产品都可以算是广义上的视频直播产品。按照服务对象的不同，网络视频直播大概可分为to-B 和to-C 两种。但这些不同的视频直播类型，只是在服务对象和产品形式上有区别，在实现的技术手段上没有本质区别。 to-B 是指将直播服务提供给企业的形式，比如各种企业常见的视频会议。视频会议的视频部分从本质上也可算是视频直播的一种。 to-C 是指将视频直播服务提供给普通用户的形式。这种形式在网络生活中很常见，又可以分为一对一和一对多： 一对一 是指视频源从一个人传输到另一个人，常见于视频通话和聊天，比如FaceTime、Skype的视频通话、微信及QQ的视频通话功能，近两年也被用作证券公司网上开户的视频验证。 一对多 是指视频源从一个人传输到多个用户，这种形式即我们常说的“网络视频直播”。根据目前市场上各个直播平台的主打内容（或噱头），又可以分为以下六个种类： 一、 秀场直播(娱乐) 秀场直播是国内最早的直播形式，主要内容是各路美女表演唱歌跳舞等才艺。最早期（之一）是韩国的视频聊天社区“十人房”，后被国内的傅政军发现，于是便在国内做了一个类似的视频聊天社区9158，这也是国内最早的秀场直播平台。后来呱呱、YY语音、六间房也涉足这个领域，这三家就是国内第二批视频直播平台。 在2012年底至2014年YY和天鸽互动（9158母公司）分别上市后，中国的互联网公司和投资人突然发现，原来视频直播这么来钱，于是从2014年起国内掀起了秀场直播平台的热潮，到目前为止，已有无数家大小公司涉足这个领域，这个市场也成为了一片红海。 目前涉足秀场直播的公司和产品主要有：优酷的来疯、网易的BoBo、酷狗的酷狗繁星、乐视的甜心宝贝、爱奇艺的奇秀、人人网的我秀、腾讯的QT星主播、杭州米络的KK唱响、以及无数的二三四五六线中小秀场。 从内容上看，几乎完全一样。 二、电子竞技（游戏）直播 电子竞技直播（即通常所说的游戏直播），最早的产品是美国的Justin.TV在2011年推出的新品牌Twitch，用来进行游戏视频的直播，但这种直播形式被国内公司和投资人注意到则是三年后的2014年前后，先是传出Google要收购Twitch，而后8月份Twitch正式被亚马逊公司以9.7亿美元收购。 自此，国内又掀起了大搞游戏直播平台的热潮。反应最快的是斗鱼TV和战旗TV、2014年初便成立；第二批的是YY的虎牙TV、腾讯游戏竞技平台TGA搞的TGA直播（后又和PLU游戏娱乐传媒合作更名为龙珠直播）、搜狐的17173游戏直播、新浪的看游戏、网易的CC、杭州米络的KK直播；再往后就是更多后知后觉的中小公司杀入这个领域，又一次搞出了一个红海。 另外值得一提的是，网易CC和杭州米络的产品最为失败，估计是因为游戏直播没人看，他们便又在这个游戏直播平台上加上了秀场内容的美女直播，这样不仅搞乱了品牌分类，又和自家的网易BoBo及KK唱响形成了竞争关系，不得不说，姿势水平实在太低。 由于游戏直播在带宽上的特殊要求，以及用户群体和心态的差别，至今无一国内平台实现盈利。在我个人看来，考虑到国内的带宽价格以及用户付费习惯的差异，国内这些人只因为亚马逊的高额收购就盲目地抄袭这一产品，只会画虎不成反类犬。 三、移动直播 视频直播第三个阶段是只有智能手机端、而无电脑及网页端的移动全民直播。 这种直播形式最早是2015年2月份美国一家创业公司上线的Meerkat，上线后几周内便拿到了1200万美元的风投。同年3月份，Twitter以近1亿美元的价格收购了涉及同样领域但还未上线的Periscope、并于3月底上线运营，同时禁止了Meerkat对Twitter用户的抓取。紧随其后Facebook也宣布将要涉及这一领域。2016年三月初，也就是Meerkat上线的一年后，Meerkat的首席执行官宣布，由于面临着Twitter和Facebook等科技巨头的强大竞争压力，Meerkat决定放弃直播视频社交网络业务。 国内第一批拷贝这个产品的是北京蜜莱坞和花椒团队，他们先后于2015年下半年上线了类似产品。北京蜜莱坞最早期同时上线了两款功能相似的产品：蜜live和映客，初期的想法是蜜live面向国外留学生、映客面向国内，但现已集中推广映客。花椒团队是几个在美国留学的90后，其中有人认识360的人，因此产品一做出来就被360收购了。 再往后就是更多的移动直播产品被做出来。这类产品的特点是没有开播门槛，比如秀场类直播必须要签约公会、游戏直播必须要上传身份证明，而移动直播则只要注册一个账号、人人都可以进行直播。另外，移动直播产品和前两个直播还有一些不同，就是它又被细分成了几个不同的使用场景。具体如下： 1、移动全民直播 这个子类型的产品起源就是Meerkat，代表就是映客和花椒。最初也是模仿Meerkat的模式，以视频社交作为产品方向（即继文字社交、图片社交、小视频社交后的第四个社交模式），但估计是秀场类直播的现金流诱惑在国内的互联网公司深入人心、以及这种直播模式一直难以实现用户付费、再加上国外的抄袭对象也没有出现像Twitch那种的巨额收购，所以这些公司纷纷把内容又引向了美女直播，形成了一个产品形式接近Meerkat，而运营逻辑、内容偏好和商业模式偏向秀场的“中国特色”移动直播产品。 2、社交软件直播 这个子类型最初的产品思路应该是来自Twitter的Periscope，即社交化的视频直播，利用社交平台的流量优势来做直播产品。主要的代表是陌陌内嵌的直播功能以及Blued（一款男同性恋社交软件）内嵌的直播功能，最近，微博也开始大力推广自己的直播产品“一直播”，依托微博自身巨大的流量优势，我估计很多做移动直播的小创业公司要哭死了。 虽然这个细分类型名义上是“社交化视频直播”，但遗憾的是，大概是出于3.1中的那几个原因，这类直播同样很快地滑向了秀场直播的窠臼。 这个细类产品的玩法，其实跟优酷在自家网站上推来疯直播是一模一样、只是一种对流量的利用手段，只不过是从网站换成了手机，“社交直播”只是个名存实亡的噱头罢了。 3、电商(购物)直播 这是一个最近发展出来的产品方向。主要是用直播的形式来推荐各种商品。其实这个方向的本质就是“自媒体营销号”，在斗鱼等平台上早就有商家在做，各种卖电脑、卖食品、卖服务的商家；后来一些电商平台看到了用网红直播做营销的好处，便利用自身平台的产品和流量优势也加入进来。这些平台做的直播基本都是赤裸裸的广告了，跟直播产品最初的内涵已经大不相同，盈利模式也从刷礼物变成了卖东西。 目前淘宝、聚美优品等电商纷纷开始做了直播功能，也有一些小创业公司也在做单纯的商品营销、购物指南、买手直播之类的直播产品，目前还不成气候。 4、手游直播 这个子类型产品本质上还是游戏直播，只是只选择了游戏中的移动端手游，这样的好处是避免了电脑游戏直播那高昂的带宽费用（手机画面要求的带宽低），除此之外，（在我个人看来）基本全都是坏处。如果说名存实亡的移动直播还能靠美女直播赚点小钱，这类手游直播估计只能靠手游分发赚点钱勉强糊口了。更不用说斗鱼TV之类的平台也都纷纷上线了手游直播的版块（即便不考虑游戏直播平台的移动端上也是有手游分发功能的）。 代表产品是触手TV，以及其他各种小团队做的产品。 四、体育直播 这类产品初期主要直播各种体育比赛，后来又加上了各种棋牌游戏。形式上跟斗鱼TV之类的游戏直播最为接近，因此没必要多说了。 主要代表是章鱼TV。这类直播的产品目前是最少的，已有平台上的用户也是最少的。 五、活动直播 这类直播主要播放各种现场活动，在美国基本都是YouTube之类的视频大站在做，国内做这种产品的公司也很少。估计有三个原因：一是国外没有这类产品的上市或被收购案例，关注的人少；二是直播现场活动要求团队有着相当的人脉资源，三是直播这类活动需要的牌照最多。二三两条就形成了很高的进入壁垒。 另外，这类直播跟前四种已经有了本质的不同，因为它已经不是前面那些以主播为中心、以围观用户付费虚拟礼物为主的商业模式了，而是一种无主播、不和用户产生交流、更接近传统电视直播的一种模式，它有着完全不同的商业模式。 比如微吼：为企业提供直播的场地、技术及播出渠道，并向企业收费，这种模式其实已经不能算是我们常说的那种“视频直播”了，而是更接近传统的广告服务商，这种模式下的直播界面就好比是公交、地铁、商场、超市、小区里的广告位、广告牌。 这类直播目前主要有三种形式： 对各种讲座、峰会以及商业活动进行直播，主要代表是微吼直播。 是对各种演唱会的直播，优酷、乐视等大型视频网站都有这类直播，此外腾讯的龙珠音乐也涉足这一领域。 是各大视频站自办的直播活动，如优酷直播的罗永浩大战王自如。 对于想做视频直播平台的普通创业者来说，基本上可以不用考虑这个类型了。 六、摄像头直播 这个类型最早起源于美国的DropCam，是基于无线网络的摄像头，具备网络直播、网络存储、双向通话等功能，用户可以通过桌面浏览器、iPhone或者Android客户端查看DropCam所拍到的画面，自2009年起便开始销售这类产品，在美国主要被用作婴儿监控摄像头。2014年6月，谷歌旗下的Nest公司宣布，以5.55亿美元的现金价格收购Dropcam。 国内的公司再一次开始了这类产品的抄袭之路，时间嘛，不用我说你也肯定能猜到了，2014-2015年，就是这么没悬念。主要公司有联想、360、小米、百度、网易等，其中把直播画面放上网的有360小水滴直播、网易青果直播、百度云直播，内容主要是旅游景点、中小学教室、车间厂房、餐厅厨房、广播电台、街道路况等。 这类直播最初只是作为私人监控，只是在隐私不那么受尊重的中国才被这些互联网公司放上网做宣传自己的产品用，严格来说，360们已经涉嫌违法了；再考虑到这种直播和活动直播一样“不以主播为中心和缺乏互动”的特性，对于想做视频直播平台的创业者，这个类型也基本不用考虑了。 以上，目前国内直播行业的发展历程、现有种类及格局大概就是这样。 国内的直播产品最大的成本有三块：1、带宽，2、主播底薪，3、宣传推广。 昂贵的带宽费用是国内绕不掉的，而正因为这块的高额成本，导致了国内的直播产品大部分都要签约专业的主播、网红或者主播经济公司，借助她们的本领来给平台带来现金流水、借此来覆盖带宽费用，因此主播底薪这个开支自然也无法避免，因此各家平台到最后拼的都是宣传推广的成本和运营的能力（国内的直播平台绝大部分都没有创意、只有跟风抄作业，所以也就不存在拼创意），这时候谁能活到最后基本就能看出来端倪了。 而美国的带宽成本几乎可以忽略不计，没有了带宽成本的压力，自然也就没有了「直播产品纷纷秀场化」的必然结果，这时就只剩下营销推广、运营能力以及创意的比拼了。如此看来，美国的直播产品是在拼「谁活得更好」，而国内的产品目前还只是在拼「谁活得更久」。 即便如此，看到Facebook和Twitter这两个巨头都玩起了直播（Facebook Live和Periscope），最早做移动直播的Meerkat反而宣布放弃直播业务了； 反观国内，存量市场就那么大，又没谁能搞出创新的模式来开辟出增量市场，带宽费用又比美国高出那么多，却依然疯狂地扎堆玩直播平台，只能说国内的金主和创业者们太缺乏创意、抄作业已经演化为生存本能了。 我看国内直播产品未来的发展路径很可能跟当初的视频网站一样，大批起来、而后又大批死掉，最后只剩几个巨头存活，毕竟现在国内大大小小的直播产品已经有300～500个了，即便中国的潜在市场很大，这个数量也依然太多了。","categories":[{"name":"直播","slug":"直播","permalink":"https://chengtong.me/categories/直播/"}],"tags":[]},{"title":"Docker-Compose安装Wordpress博客","slug":"Docker-Compose安装Wordpress博客","date":"2020-05-01T14:20:00.000Z","updated":"2021-06-02T02:41:09.925Z","comments":true,"path":"posts/f2a408f6.html","link":"","permalink":"https://chengtong.me/posts/f2a408f6.html","excerpt":"","text":"博客搭建1.前提 linux 环境 安装 Docker，Docker-compose 2.linux 安装 dockera.安装 docker 12345uname -r #查看你当前的内核版本yum update #更新yumyum -y install docker #安装 dockersystemctl start docker.service #启动 docker 服务docker version #查看 docker版本 b.安装 docker-compose 12yum install -y docker-compose #安装 docker-composedocker-compose version #查看版本 3.安装 Wordpress创建 docker-compose.yml或docker-compose.wordpress.yml 12345678910111213141516171819202122232425262728version: '3.3'services: db: image: mysql:5.7 volumes: - db_data:/var/lib/mysql restart: always ports: - 4306:3306 environment: MYSQL_ROOT_PASSWORD: somewordpress MYSQL_DATABASE: wordpress MYSQL_USER: wordpress MYSQL_PASSWORD: wordpress wordpress: depends_on: - db image: wordpress:latest ports: - \"9000:80\" restart: always environment: WORDPRESS_DB_HOST: db:3306 WORDPRESS_DB_USER: wordpress WORDPRESS_DB_PASSWORD: wordpress WORDPRESS_DB_NAME: wordpressvolumes: db_data: &#123;&#125; 执行命令： 12docker-compose -f docker-compose.wordpress.yml up -d #后台运行docker-compose -f docker-compose.wordpress.yml down #停止并删除服务 前台访问地址：IP:9000 后台访问地址：IP:9000/wp-admin 注：如果无法访问，阿里云/腾讯云，记得开启9000端口。","categories":[{"name":"容器","slug":"容器","permalink":"https://chengtong.me/categories/容器/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://chengtong.me/tags/Docker/"},{"name":"Docker Compose","slug":"Docker-Compose","permalink":"https://chengtong.me/tags/Docker-Compose/"},{"name":"Wordpress","slug":"Wordpress","permalink":"https://chengtong.me/tags/Wordpress/"}]},{"title":"vue与html5关系","slug":"vue与html5关系","date":"2020-04-29T01:54:00.000Z","updated":"2020-12-07T05:57:32.104Z","comments":true,"path":"posts/76355b4a.html","link":"","permalink":"https://chengtong.me/posts/76355b4a.html","excerpt":"","text":"介绍 要想了解vue与HTML5的关系，首先我们得清楚什么是vue，什么是HTML5，只有通过对它们有个大致的概念，才会对它们之间的联系有一个清楚的认识和理解。下面就从vue和HTML5的基本概念入手分析一下它们之间的基本关系。 1.什么是vue？ Vue 是一套用于构建用户界面的渐进式 JavaScript 框架 ；同时它是一个典型的 MVVM 模型的框架（即：视图层-视图模型层-模型层）。 2. MVVM模型又是什么？ MVVM 是View-ViewModel-Model的缩写（即：视图层-视图模型层-模型层）。 View被称为视图层，可以把它理解为HTML页面；Model 被称为模型层，它是负责处理业务逻辑以及和服务器端进行交互的；ViewModel 被称为视图模型层，vue框架就在这里发挥作用了，主要是作为 View 层和 Model 层之间的通信桥梁。 3. 什么是HTML5？ HTML5是HTML的新标准，是一种超文本标记语言，是用来创建网页的标准标记语言，通过一系列的标识，来规范网络上的文档格式。 4.vue与HTML5的区别 区别： ​ 1.vue是一个渐进式 JavaScript 框架，而HTML5是一种超文本标记语言； ​ 2.在开发中vue框架通过mvvm的模式，解耦了视图层与模型层，而HTML5原生开中数据与标签紧耦合； 联系: ​ 1.vue是一个前端框架，但还是建立在HTML ，CSS ，JavaScript的基础之上的，通过编译之后依然是HTML+CSS+JavaScript组成。","categories":[],"tags":[{"name":"VUE","slug":"VUE","permalink":"https://chengtong.me/tags/VUE/"},{"name":"HTML5","slug":"HTML5","permalink":"https://chengtong.me/tags/HTML5/"}]},{"title":"【转】Moodle、Sakai、Blackboard对比","slug":"【转】Moodle、Sakai、Blackboard对比","date":"2020-04-12T13:21:53.000Z","updated":"2020-10-02T15:22:47.250Z","comments":true,"path":"posts/b84480a5.html","link":"","permalink":"https://chengtong.me/posts/b84480a5.html","excerpt":"","text":"Moodle、Sakai、Blackboard对比 英文名称 Moodle Sakai Blackboard Learning System CE 6.1 Enterprise License 中文名称 Moodle（魔灯） Sakai 毕博 开发单位/开发者 Martin Dougiamas Sakai WebCT 国家 澳大利亚 美国 美国 版权类型 GPL 教育社区许可证(Educational Communtity License) 商品软件 版本更新时间 2008年3月3日，Moodle 1.9 2008年3月27日，Sakai 2.5 2006年10月26日，Blackboard Learning System CE 6.1 交流工具 讨论区 1.能够选择是否讨论的帖子发到学生电子邮箱中。2.学生能够通过电子邮件来浏览帖子，电子邮件呈现的内容包括以主题的每日摘要或帖子的全部内容两种方式。3.学生能够订阅讨论区的RSS种子。4.提供对学生和教师发表帖子内容的拼写检查。 1.能够选择是否讨论的帖子发到学生电子邮箱中。2.学生能够通过电子邮件来浏览帖子，电子邮件呈现的内容包括以主题的每日摘要或帖子的全部内容两种方式。3.提供对学生和教师发表帖子内容的拼写检查。 1.提供对学生和教师发表帖子内容的拼写检查。 讨论区管理 1.帖子能够被其他同学查看。2.教师能够查看有关参与者发表帖子的统计数据，这些统计数据能够帮助教师对参与者进行评价。 教师在所有的帖子经过筛选过之后能够建立适当的讨论。 1.帖子能够被其他同学查看。2.教师能够查看有关参与者发表帖子的统计数据，这些统计数据能够帮助教师对参与者进行评价。 文件交换 学生能够提交作业。 学生能够提交作业。 1.学生能够提交作业。2.管理者能够定义每名用户的磁盘空间大小。 电子邮件 1.学生能够使用内嵌的电子邮件功能给个人或小组成员发邮件。2.教师能通过电子邮件地址或学习者别名对全班成员或个人发邮件。 1.学生能够使用内嵌的电子邮件功能给个人或小组成员发邮件。2.学生能够使用地址搜索栏。3.教师能通过电子邮件地址或学习者别名对全班成员或个人发邮件。4.学生能够转发自己的邮件。 在线日志/在线笔记 1.学生能够在任意页上添加笔记。2.学生能够合并他们的课程笔记，并可打印。 实时聊天室 1.支持实时的小组讨论。2.教师能控制聊天并控制聊天者的参与。3.系统为所有聊天室进行日志存档。 1.支持实时的小组讨论。2.系统为所有聊天室进行日志存档。 1.支持实时的小组讨论。2.教师能控制聊天并控制聊天者的参与。3.聊天工具支持学生提问，教师回答的方式。4.系统为所有聊天室进行日志存档。 白板 1.支持图片和ppt的上载。2.支持数学符号。3.通过软件能够记录会议内容，方便日后浏览。 工具 书签 1.学习者能够分享自己的书签。2.学习者能够在自己的文件夹中建立书签。3.学生能够对课程中的任何内容材料建立书签。 日历/事件提醒 1.教师能够在课程通知界面中发布通知。2.学生在完成了作业后能浏览自己的成绩，并与班上的其他同学对比。 1. 教师和学习者都能在课程日历上添加事件。2.教师能够在课程通知界面中发布通知。3.学生有自己的个人主页，这个主页中列出了所有学生能够选择的课程清单、新的电子邮件、所有课程，在个人日历上还列出了系统事件。 1. 教师和学习者都能在课程日历上添加事件。2. 教师能够在课程通知界面中发布通知。3.学生有自己的个人主页，这个主页中列出了所有学生能够选择的课程清单、新的电子邮件、所有课程，在个人日历上还列出了系统事件。4.学生在完成了作业后能浏览自己的成绩，并与班上的其他同学对比。 课程搜索 学习者能够搜索所有讨论线程。 1.学习者能够搜索所有课程内容。2.学习者能够搜索所有讨论线程。3.学习者能够搜索聊天室或虚拟教室的会议记录。 1.学习者能够搜索所有课程内容。2.学习者能够搜索所有讨论线程。 离线学习/同步学习 1.学习者能够完成和下载整堂课的内容，这些课程内容都以能够存储在本机上或打印的格式保留下来。2.教师能够通过CD发布课程内容，这样便于学习者的离线学习。 导航条/帮助 1.学习者能够及时的得到任何工具的使用帮助。 1. 学习者能够及时的得到任何工具的使用帮助。2.系统有帮助学习者如何使用系统的在线教程。 1. 学习者能够及时的得到任何工具的使用帮助。2.系统有帮助学习者如何使用系统的在线教程。 学生互动工具 小组合作 1.教师能够为学习者分组。2.每个小组能够有自己的讨论区。3.每个小组能够有自己的聊天室或互动白板。4.每个小组能够有小组特有的活动或作业。 1.教师能够为学习者分组。2.每个小组能够有小组特有的活动或作业。3.小组能够自我管理或接受教师的监管。 1.教师能够为学习者分组。2.系统能够根据特定的大小和规模随机分组。3.学习者能够自己分组。4.每个小组能够有自己的讨论区。5.每个小组能够有自己的聊天室或互动白板。6.每个小组能够有小组特有的活动或作业。7.小组能够自我管理或接受教师的监管。 社会网络 学习者能够根据兴趣建立自己的在线俱乐部，能够在系统里的小组学习。 学习档案袋 开源电子档案袋是Sakai的备选工具。1、学习者可以收集、整理、反思自己在学习过程中完成的作业和作品。2、学习者可以设计、编排他们的作品，继而放到网上供老师、同学、家长浏览。3、教学者可以利用档案袋整理自己的教学资源。4、教学者可以回顾、反思自己的教学经历。5、教学者能够利用档案袋让学习者、家长和学校更好地了解自己的教学理念和教学状况。 1.学习者能够为每门课程建立自己的主页。2.学习者能够使用他们自己的个人主页来选择性的显示自己的课程学习。3.学习者能够输出个人主页中的内容。 管理 验证 1.管理者能够允许访客进入所有课程。2.系统能够验证外部的LDAP服务器。 1.管理者能够允许访客进入所有课程。2.系统能够验证外部的LDAP服务器。3.系统能够通过Kerberos协议进行验证。4.系统支持Shibboleth。5.系统支持CAS。 1.系统能够验证外部的LDAP服务器。2.系统能够通过Kerberos协议进行验证。3.系统支持Shibboleth。4.系统支持CAS。5.系统能够验证IMAP，POP3或安全NNTP。6.管理者能够建立对二级课程建立登录失败清单。7.系统能够支持多组织单元和符合服务期设置虚拟服务器。 开设课程授权 1.系统支持基于角色的开课授权，角色能定制服务提供者。2.教师和学习者在不同的课程中可以被赋予不同的角色。3. 可以设置不同类型的角色参与教学活动。 1.系统支持基于角色的开课授权，角色能定制服务提供者。2.管理者能够建立一个不限用户组织单元数，以及为用户定义能够进入课程内容和工具的特定浏览权限。3.管理者能通过许可，为角色定义多重制度以及在课程中的角色。4.教师和学习者在不同的课程中可以被赋予不同的角色。 1.系统支持基于角色的开课授权，角色能定制服务提供者。2.管理者能够建立一个不限用户组织单元数，以及为用户定义能够进入课程内容和工具的特定浏览权限。3.管理者能通过许可，为角色定义多重制度以及在课程中的角色。4.教师和学习者在不同的课程中可以被赋予不同的角色。 注册 1.教师能够为自己的课程增加学生，也允许学生自己提出申请。2.管理者能够通过一定的文本格式批量添加学生信息。3.管理者能够在系统和SIS之间转存学生信息。 1.教师能够为自己的课程增加学生，也允许学生自己提出申请。2.管理者能够通过一定的文本格式批量添加学生信息。 1.教师能够为自己的课程增加学生，也允许学生自己提出申请。2.管理者能够在系统和SIS之间转存学生信息。3.软件通过API事件驱动支持学生信息系统数据交换。4.软件支持SCT Banner，SCT Luminis，Datatel，PeopleSoft8或其他SIS或portal系统之间的整合。5.通过软件使用IMS企业版的学生数据。 本机服务器 从商业分支机构中得到主机和支持服务。 提供主机解决方法。 课程工具 测试类型 1.多项选择2.多选答案题3.匹配题4.计算题5.数字题6.填空题7.完形填空8.描述9.问答题10.答案可以包含其他媒体元素(图片，视频，音频) 1.多项选择2.多选答案题3.匹配题4.计算题5.填空题6.完形填空7.调查问卷题8.描述9.答案可以包含其他媒体元素(图片，视频，音频) 1.多项选择2.多选答案题3.匹配题4.句子排序题5.计算题6.填空题7.完形填空题8.问卷调查题9.描述10.答案可以包含其他媒体元素(图片，视频，音频) 自动测试管理 1.系统能随机选择题目顺序和答案顺序。2.教师能建立自评。3.教师能限制测试时间。4.教师能允许学生重试。5.系统支持测试代理。 1.系统能随机选择题目顺序和答案顺序。2.教师能建立自评。3.教师能限制测试时间。4.教师能允许学生重试。5.学生可以浏览已回答的问题。6.教师能设定对正确的答案给与特定的反馈信息。7.系统支持测试代理。 1.系统能随机选择题目顺序和答案顺序。2.教师能建立自评。3.教师能限制测试时间。4.教师能允许学生重试。5.学生可以浏览已回答的问题。6.教师能设定对正确的答案给与特定的反馈信息。7.系统支持测试代理。 自动测试支持 1.教师能够建立个人测试题库。2.支持导入和导出试题库。 1.教师能够建立个人测试题库。2.教师能够建立系统测试题库。3.能够导入测试，测试类型需符合QTI。4.系统提供测试分析数据。 1.教师能够建立个人测试题库。2.能够导入测试，测试类型需符合QTI。3.系统提供测试分析数据。 在线划线工具 1.教师能够选择特定的学习者或者问题进行标记。2.教师能够使学习者对其他学习者进行评级、评论。 1.教师能够选择特定的学习者或者问题进行标记。2.教师能够使学习者对其他学习者进行评级、评论。 1.教师能够选择特定的学习者或者问题进行标记。2.教师能够匿名对学习者的回家进行评价。3.教师能够使学习者对其他学习者进行评级、评论。 在线成绩簿 1.当教师在课程中布置一次作业后，软件把其自动添加到成绩簿中。2.教师能对离线作业评分。3.教师能够以表格形式把成绩簿中的分数输出。4.教师能够建立课程评分维度，可以是百分比，等级制或是否通过。 1.当教师在课程中布置一次作业后，软件把其自动添加到成绩簿中。2.教师能对离线作业评分。3.教师能够以表格形式把成绩簿中的分数输出。4.教师能够建立课程评分维度，可以是百分比，等级制或是否通过。 1.当教师在课程中布置一次作业后，软件把其自动添加到成绩簿中。2.教师能对离线作业评分。3.教师能在特定的栏目中添加细节内容。4.教师能够以表格形式把成绩簿中的分数输出。5.教师能够建立课程评分维度，可以是百分比，等级制或是否通过。 课程管理 1.教师能够旋转性的发放作业、评价和课程的开始、结束时间。2.教师能基于小组成员的以个人身份进入课程内容。 1.教师能够旋转性的发放作业、评价和课程的开始、结束时间。2.教师能基于小组成员的以个人身份进入课程内容。 1.教师能够有选择性的发放作业、评价和基于特定的事件发布消息。2.教师能基于单独的内容(日期、等级等)发放材料，教师能够使用布尔数值来选择发放内容。3.教师能够建立课程内容，设定课程开始时间，以及学习者必须学习的完成的内容。4.教师能够把讨论区与日期和事件联系起来。5.教师能基于小组成员的以个人身份进入课程内容。6.教师能基于课程活动的以个人身份进入课程内容。7.教师基于学生成果以个人身份进入课程内容。 学习追踪 1.教师能够追踪到学习者进入课程学习的频率和持续时间。2.教师能以小组合计的方式显示时间、日期和频率信息。3.教师能对进入课程、讨论区、课程测试和作业的学习者的分别就进入次数，进入时间，日期，频率和IP地址进行记录，显示。 1.教师能够追踪到学习者进入课程学习的频率和持续时间。2.教师能以小组合计的方式显示时间、日期和频率信息。3.教师能对进入课程、讨论区、课程测试和作业的学习者的分别就进入次数，进入时间，日期，频率和IP地址进行记录，显示。4.教师能浏览每个学生的导航记录。5.使用数据能根据课程整合，也可根据教学整合。 内容开发工具 存储 1.提供自我报告，软件需符合美国复原技术508部分。2.提供自我报告，软件需符合WAI WCAG1.0A级标准。 1.提供自我报告，软件需符合美国复原技术508部分。2.提供自我报告，软件需符合WAI WCAG1.0A级标准。 1.提供自我报告，软件需符合美国复原技术508部分。2.提供自我报告，软件需符合WAI WCAG1.0A级标准。 内容分享/重用 支持SCORM标准 支持SCORM标准 支持SCORM标准 课程模板 1.在课程建立的时候，软件提供模板支持。2.系统允许管理者把现有课程或预定义的课程模板作为新课程的默认模板。 1.在课程建立的时候，软件提供模板支持。2.课程内容可以通过WebDAV上载。3.系统允许管理者把现有课程或预定义的课程模板作为新课程的默认模板。 1.在课程建立的时候，软件提供模板支持。2.课程内容可以通过WebDAV上载。3.课程模板可能包括可选择性的使用标准和用户成绩薄栏目，这些内容可以在每个新的课程中出现。3.系统允许管理者把现有课程或预定义的课程模板作为新课程的默认模板。 用户界面 1.系统提供课程缺省界面。2.教师能够为每门课程改变导航图标和主题颜色。3.教师能够改变每门课程菜单项的名称和顺序。4.教师能够建立自己的界面模板，并使用在整个系统中，包括自己的教学图标，页眉和页脚。5.系统能够支持教学，部门，学校或其他组织单元同时装载在一个系统下，每个单元能够应用自己的界面和模板，包括图片，页眉和页脚。 1.系统提供课程缺省界面。2.教师能够为每门课程改变导航图标和主题颜色。3.教师能够建立自己的界面模板，并使用在整个系统中，包括自己的教学图标，页眉和页脚。 1.系统提供课程缺省界面。2.教师能够为每门课程改变导航图标和主题颜色。3.教师能够改变每门课程菜单项的名称和顺序。4.教师能够建立自己的界面模板，并使用在整个系统中，包括自己的教学图标，页眉和页脚。 教学设计工具 教师能够把课程作为模板重用在以后的课中。 1.教师能够组织学习对象，课程工具和内容在教学过程中，这些东西是能够重用的。2.教师能够建立线性的学习过程组织，这种组织方式可以是课程，课和主题。3.教师能够把课程作为模板重用在以后的课中。 1.教师能够组织学习对象，课程工具和内容在教学过程中，这些东西是能够重用的。2.教师能够建立线性的学习过程组织，这种组织方式可以是课程，课和主题。3.教师能够把课程作为模板重用在以后的课中。 教学标准兼容性 1.SCORM1.22.SCORM1.33.SCORM2004 1.IMS内容包1.1.32.IMS QTI1.2.13.SCORM1.2 1.IMS内容包1.1.32.IMS QTI1.2.13.微软LRN4.SCORM1.2 硬件/软件环境 数据库 系统支持MySQL。 1.系统支持Oracle。2.系统支持MySQL。3.应用仅仅需要一个数据库，并能与其他应用中的表格并存。 1.系统支持Oracle。2.系统支持MySQL。 UNIX服务器 可用UNIX系统 可用UNIX系统 可用UNIX系统 Windows服务器 可用Windows系统 可用Windows系统 可用Windows系统","categories":[],"tags":[]},{"title":"【转】网易IM、腾讯IM、环信IM、融云IM、leancloud IM介绍","slug":"【转】网易IM、腾讯IM、环信IM、融云IM、leancloud IM介绍","date":"2020-03-08T15:30:11.000Z","updated":"2020-08-20T07:46:54.349Z","comments":true,"path":"posts/8afb5d6e.html","link":"","permalink":"https://chengtong.me/posts/8afb5d6e.html","excerpt":"","text":"功能对比 功能 网易云信 环信 融云 leancloud 云通信 基础聊天 支持 支持 支持 支持 支持 群组聊天 最多2000人 最多2000人 最多3000人 最多500人 最多10000 聊天室 支持 最多5000人 支持 建议最多5000人 支持 图片消息 支持 支持 支持 支持 支持 视频消息 支持 支持 不支持 支持 支持微视频 音频消息 支持 支持 支持 支持 支持 位置消息 经纬度和描述 经纬度和描述 经纬度和描述 经纬度和描述 经纬度和描述 Web链接 实时音频 可多人 一对一 可多人 不支持 不支持 实时视频 可多人 一对一 可多人，多清晰度 不支持 不支持 离线消息 支持 支持 支持 需手动启用 支持 文件传输 支持 支持 支持 支持 28M以下 自定义消息 支持 支持 支持 支持 支持 扩展服务功能对比 功能 网易云信 环信 融云 leancloud 云通信 已读回执 支持 支持 支持 不支持 支持 消息撤回 支持 不支持 支持 不支持 不支持 敏感词过滤 不支持 不支持 不支持 不支持 支持 服务端消息记录 基础版1年 7天，单会话500条 手动开启，最多6个月 需开通存储服务 保存7天 消息记录同步Api 支持 支持 支持 支持 支持 用户关系管理 支持 支持 不支持 不支持 支持 教学白板 支持 不支持 不支持 不支持 不支持 消息加密 支持 不支持 不支持 平台支持 iOS、android、PC、Web iOS、android、Web、Linux iOS、android、Web iOS、android iOS、android、PC、Web 群组核心功能对比 功能 网易云信 环信 融云 leancloud 云通信 群资料 头像、名称、介绍、公告、类型 名称、描述、人数、类型 名称 名称 名称、头像、简介、公告、当前人数等 群形态 普通群、高级群 私有群、公开群 自己维护 自己维护 私有群、公开群 加入方式 邀请、申请 邀请、申请 自己维护 自己维护 邀请、申请 成员管理 群昵称修改，禁言，踢出，设置或移除管理员 移除，黑名单 自己维护 自己维护 群昵称修改，禁言，踢出，设置或移除管理员 群管理 修改群资料，解散或转让群，设置管理员，群禁言 修改群资料，解散群，屏蔽群消息 自己维护 自己维护 修改群资料，解散，设置管理员，群禁言 网易云信报价3800/月，其中聊天室2000/月 群容量：200人； 单人建群200个； 开通聊天室； 历史消息记录存储1年； 消息漫游和离线消息； 10T存储空间； 10000日活； 实时音视频需另外付费； 环信报价免费 基础通信功能； 群无限制； 聊天室； 实时音频和视频（特有）； 单用户离线消息保存7天； 单群内离线消息保存500条； 日活30万以下； 融云报价2000/月 基础通信功能； 群无限制； 聊天室； 聊天消息云端存储； 日活10000； 实时音视频需另外付费； learncloud报价447.24/月 文件存储1T（消息存储另外收费）； 文件下载流量每月15G免费； 群无限制； 聊天室； 基础通信功能； 日活10000； 无实时音视频服务； 腾讯云通信报价免费 基础通信功能； 群无限制； 聊天室； 消息漫游，仅保存7天； 日活低于10万； 无实时音视频服务； 注： 网易云信有专业运维团队24小时技术服务，有论坛； 腾讯云通信可提工单，但没有论坛； 环信有社区论坛，无在线技术客服； 融云有工单服务支持，无技术论坛社区； learncloud有技术社区，工单服务需付费开通； 网易云通信IM 网易sdk价格.png 网易云信im官方文档http://dev.netease.im/docs/product/IM%E5%8D%B3%E6%97%B6%E9%80%9A%E8%AE%AF/SDK%E5%BC%80%E5%8F%91%E9%9B%86%E6%88%90 拥有私聊、群聊、聊天室等通讯能力 客户端 IM 组件、客户端 IM 基础库、全平台 SDK 以及服务端 API 等 网易im架构 实现功能 单聊消息点对点聊天，支持的消息类型包括文字、图片、语音、视频、地理位置、文件、通知、提示、智能对话机器人、自定义消息。同时提供离线消息、漫游消息、多端同步、云端历史记录、消息推送能力。(可以满足医生在线问诊业务场景) 群聊提供了普通群 (Normal) 以及高级群 (Advanced) 两种形式的群聊功能。高级群拥有更多的权限操作，两种群聊形式在共有操作上保持了接口一致。(可以满足医生病理讨论等业务场景) 聊天室聊天室是一种比群组组织更加松散的形态，用户可以随意进出聊天室 用户资料托管网易云通信提供了用户资料托管，用户资料包括帐号、昵称、性别、头像、签名、手机、邮箱、生日以及扩展字段等。用户资料托管属于非必选项，开发者可以自行实现。 用户关系托管用户关系托管主要用于维护用户与用户之间的好友关系，包括添加好友、删除好友、好友列表、黑名单等 消息推送服务消息推送是一种在移动端保障 IM 消息送达率的重要途径。网易云通信 IM SDK 从3.2.0 起引进第三方消息推送来增加消息送达率，目前已支持的第三方推送有小米推送、华为推送。在网易云通信 IM SDK 基础上，开发者可快速接入第三方推送，在支持的设备上，网易云通信 SDK 进程与服务器连接断开之后，联系人发来的消息将通过第三方推送平台推送给用户，从而提高消息达到率。 消息抄送服务 事件订阅服务 网易实时音视频 网易实时音视频官方文档http://dev.netease.im/docs/product/%E9%9F%B3%E8%A7%86%E9%A2%91%E9%80%9A%E8%AF%9D/SDK%E5%BC%80%E5%8F%91%E9%9B%86%E6%88%90/iOS%E5%BC%80%E5%8F%91%E9%9B%86%E6%88%90/%E6%A6%82%E8%A6%81%E4%BB%8B%E7%BB%8D 基于网络的一对一、多对多实时语音功能，视频通话功能实现功能 点对点通话建立 通话过程 多人房间相关3.1 创建一个多人房间创建一个多人音视频房间，可以指定房间名、房间类型3.2 加入一个多人房间加入一个多人音视频房间，可以指定自己的角色：互动者或是观众，若为互动者，可以指定视频清晰度、帧率、音频采样率等3.3 用户加入房间的通知3.4 离开一个多人房间3.5 用户离开房间的通知3.6 会议发生错误通知3.7 改变自己当前角色3.8 获得自己当前角色 音视频流控制 通话过程中编解码控制 服务端录制… 关于视频会议的网易实现通过接入网易im和音视频两个sdk实现视频会议及通讯的需求 可以用网易云通信打造在线多人音视频会议系统，高实时性保障参与会议人员的有效互动，在线会议节约人力物力成本，减低企业运营成本 可以和白板、文档转码功能搭配使用，让会议内容更丰富，效率更高 可以和IM功能一起使用，支持文字、表情、图片、视频、文件、自定义消息等消息格式，极大地丰富了会议过程中参与者之间的交互方式 腾讯云解决方案 腾讯云通讯im 腾讯im开发文档https://cloud.tencent.com/product/im 计费模式https://cloud.tencent.com/product/im#price按照日活跃人数计费 包括：Android/iOS/Windows/Web的SDK组件、服务端集成接口、第三方回调接口等。利用这些组件，可以在应用中构建自己的即时通信产品 功能实现 单聊 群聊 资料关系链托管 帐号登录集成 接入服务系统 消息推送服务 腾讯音视频 1、安卓离线推送概述：这里的离线指的是应用在没有退出登录的情况下，被系统或者用户杀掉。在这种情况下，如果还想收到ImSDK的消息提醒，可以集成云通信离线推送。 另外，ImSDK 从 2.1.0 版本开始，提供了适配小米、华为离线推送的方案。 注意 对于已经退出登录（主动登出或者被踢下线）的用户，不会收到任何消息通知。 目前，离线推送只提供普通聊天消息，进行消息提醒，暂不提供对系统消息的消息提醒 。 2、集成时间成本：一个月左右 暂未直播模式，与业务需求的多人会议暂时无法满足，咨询工单已提交，待回复。 1、收费标准： 云通信IM： https://cloud.tencent.com/product/im image.png 实时音视频通话： image.png https://cloud.tencent.com/product/trtc 互动直播费用： https://cloud.tencent.com/document/product/268/5127 移动直播费用： https://cloud.tencent.com/document/product/267/2818 互动直播和移动直播的功能区分： 互动直播可以实现视频连麦，移动直播只能实现音频连麦。 image.png 点播和云存储将来能会用到（eg.直播回放的存储和播放） 点播收费： https://cloud.tencent.com/document/product/266/2838 云存储收费： https://cloud.tencent.com/document/product/436/6239 2、消息推送服务 https://cloud.tencent.com/document/product/269/4123 1234567支持全员推送；支持按用户属性推送；支持按用户标签推送；管理员向账号推送消息，接收方看到消息发送者是管理员；管理员指定某一账户向其他账户推送消息，接收方看到发送者不是管理员，而是管理员指定的账号；支持消息离线存储。注意：当前推送功能比较适合低频次推送场景（例如每天或每周一次的营销推送）。如果推送频次过高，则推送可能会有延迟。 计费规则全员推送服务计费：单次推送目标用户数小于1万的免费（每天可推送最多100次），超过限制即需要收费。 推送速度超出限制默认使用共享通道：10万条/秒（共享），速度根据当前所有客户推送需求而定，不保证速度； 消息保存离线保存消息条数：5条 收费价格2000/月 备注单次推送目标用户数超过1万（每天可推送最多100次），即需要按套餐收费 关于技术实现和两个sdk的对比 网易sdk的更新迭代基本维持在一个月左右，腾讯sdk更新较慢 网易的demo实现实用度（ios）很高，基本可以在demo的基础上进行自定义的修改，ui和网络还有消息监听等封装的比较好。腾讯的im demo处于demo级别，后期接入需要重新开发，会增加一定的开发成本。 网易提供一对一7*24小时技术支持的，对比腾讯sdk以工单形式，响应速度会快一些，之前接触过的也基本能很快对应到前后台问题。腾讯的客服响应速度很慢。 网易的计费比较透明，且可选多种计费模式，腾讯存在很多隐形计费，前期无法估计用户量的时候很难预估成本。 较之sdk的稳定性方面，网易使用两年的过程中基本未出现消息丢失等问题，腾讯之前的sdk出现过，并且网易的回调接口丰富，问题对应信息比较全面，方便对应。 网易sdk提供了 GitHub 发布仓库 。NIMSDK，此仓库包含 IM 和音视频功能。并提供了开源的 聊天 UI 组件 , 通过简单的配置就可以实现聊天功能。 局域网简历视频通话调研后应该无法实现 环信IM 100以内的注册用户，免费使用； 提供基础的即时通讯云功能和存储空间； 全平台SDK工具包以及集成文档说明； 工单进行技术支持； 环信社区互动http://www.imgeek.org/ 融云IM","categories":[],"tags":[]},{"title":"SLB配置","slug":"SLB配置","date":"2020-03-01T13:21:53.000Z","updated":"2020-06-01T07:55:36.943Z","comments":true,"path":"posts/9ba6599e.html","link":"","permalink":"https://chengtong.me/posts/9ba6599e.html","excerpt":"","text":"TCP设置 HTTPS配置 注意：健康检查配置-域名，设置访问域名即可。 nginx配置 12345server &#123; listen 443; server_name localhost; return 301 https://$server_name$request_uri;&#125;","categories":[{"name":"负载均衡","slug":"负载均衡","permalink":"https://chengtong.me/categories/负载均衡/"}],"tags":[{"name":"SLB","slug":"SLB","permalink":"https://chengtong.me/tags/SLB/"}]},{"title":"Adobe Reader一打开就闪退","slug":"Adobe Reader 一打开就闪退","date":"2020-02-17T14:00:01.000Z","updated":"2020-06-01T07:55:36.899Z","comments":true,"path":"posts/d649053f.html","link":"","permalink":"https://chengtong.me/posts/d649053f.html","excerpt":"","text":"Adobe Reader/Adobe Acrobat Reader DC一打开就闪退解决方案1、断网有用2、阻止连接(推荐)2.1开始-控制面板-系统和安全-Windows防火墙-高级设置-出站规则-新建规则-程序度-下一步-此程序路径-下一步-阻止连接问-何时应用该规则 ？（全选）-下一步-自定义一个名称答-完成； 2.2控制面板\\所有控制面板项\\Windows Defender 防火墙-更改通知设置-公网网络设置-关闭windows defender防火墙。","categories":[{"name":"Windows","slug":"Windows","permalink":"https://chengtong.me/categories/Windows/"}],"tags":[]},{"title":"下载工具Motrix","slug":"下载工具Motrix","date":"2020-01-15T16:00:01.000Z","updated":"2020-06-01T07:55:37.023Z","comments":true,"path":"posts/6c396ed4.html","link":"","permalink":"https://chengtong.me/posts/6c396ed4.html","excerpt":"","text":"IDM、Folx、Photon、FDM、迅雷再见！ 改用 Motrix 作为默认下载工具** Q&amp;A 问：有朋友反应说不能用？答：其实和你的种子有关，软件可以正常使用的。 问：怎么是英文版的？答：其实工具是各种语言版的，默认是中文的。 问：在某云下载会限速吗？答：满速下载的。 迅雷再见！你好，Motrix，往后余生，全部是你。么错，你么有看错，霜天已经和迅雷说再见了，弃坑了，不玩了，是在下输了。霜天已经靠Motrix度过余生…下载事业。 下载软件有很多选择，异次元就介绍过 IDM、Folx、Photon、FDM、迅雷等等，一数一大堆。不过正所谓各花入个眼，还是有很多人想寻找不一样的下载工具。 Motrix 是一款开源免费且界面非常清爽简约的全能型下载软件，它跨平台支持 Windows、Mac、Linux 三大系统，可以支持下载 HTTP、FTP、BT、磁力链接以及下载百度网盘等资源。如果你用腻了其他工具，不妨和霜天一样试试 Motrix 吧… 与大多数同类工具基本一致，Motrix 也是采用了「Aria 2」作为核心，所以下载速度、多线程等能力与其他工具几乎一致。 软件代码基于 Electron + Vue + VueX + Element 等技术编写而来，对开发感兴趣的同学可以参考学习一下。 Motrix 比较方便的一点是可支持百度网盘下载，它提供了「百度网盘助手」的 Chrome 浏览器扩展，可以让你通过 Motrix 直接高速下载百度网盘的资源。 Motrix安装MO现已更名为 Motrix，请访问官网或者Github获取最新版本；或者您也可以克隆 GitHub 上最新的源码自行编译打包。 Motrix常见问题2.1 RPC添加下载任务 Motrix 默认开放的 RPC 端口是 16800，暂时不支持修改。如果与其他应用的端口冲突，请避免同时使用，不然可能会无法正常使用 Motrix。 2.2 寻求帮助 如果你对于 Motrix 的使用体验不满意或者有什么疑难问题，请到 GitHub 提交 issue。 Motrix浏览器扩展百度网盘助手 基于开源的Chrome浏览器扩展 BaiduExporter 构建，添加了 MO 2.0 相关的配置，下载地址如下： https://motrix.app/release/BaiduExporter.zip 或 https://www.lanzous.com/i8m5s3g 一.BaiduExporter安装方法下载 BaiduExporter.zip 之后，请解压到你喜欢的目录位置（以 ~/Documents 为例），解压到 ~/Documents/BaiduExporter 备用。 启动你的 Google Chrome，点击顶部菜单栏的「扩展程序」进入扩展程序管理页面；或者直接在地址栏输入 chrome://extensions/ 点击右上角的「开发者模式」开关启用开发者模式 点击「加载已解压的扩展程序」，弹出目录选择框选择弹层，选择前面解压出来的 ~/Documents/BaiduExporter 目录。 确定之后，Google Chrome 会弹出桌面通知告诉你安装成功了。 打开百度网盘网页版，如果页面弹出“初始化成功！”的提示，并且在你的百度网盘网页版界面上还会出现一个「MO.app」的按钮，就说明浏览器扩展安装成功了。 二.Motrix使用方法不保证可用性和下载速度，除非购买百度网盘SVIP，否则使用第三方工具都有被百度限速的可能性: ( 可能的解决方法：更换IP（重启宽带 or 光猫），切换百度云盘账号 注：由于百度网盘限制，请登陆百度帐号之后再下载度盘资源，不然肯定下载失败！如果是下载他人分享的文件，建议先“保存到网盘”之后再下载，不然提交任务到 Motrix 下载时会造成文件名截断 2019/02/19 更新，如果你碰到了文件名截断问题，请尝试重新下载和安装 BaiduExporter MO.app 按钮出现慢的问题打开百度云盘页面时，请求这个域下的两个资源很慢，会阻塞页面，造成 MO.app 的出现也变慢。可以通过修改系统 hosts 加入以下规则屏蔽它： 127.0.0.1 nj.baidupcs.com 选择你要下载的文件 移动鼠标指针到「MO.app」展开下拉菜单，选择「使用MO下载」 提交下载成功 如果你还没有启动MO.app，可以先点击「启动MO」来启动 Motrix 拦截 Chrome 普通下载任务 推荐安装 YAAW for Chrome ，安装完成之后修改配置如下： chrome://extensions/?id=eehlmkfpnagoieibahhcghphdbjcdmen Save之后，你的 Chrome 右键菜单里就有「使用 Motrix 下载」了！ 当然你也可以设置一下文件尺寸大于xx M 拦截下载到 Motrix Motrix特征&#128377; 简单明了的用户界面&#129412; 支持BitTorrent和Magnet&#128190; 支持下载百度网盘&#127899; 最多同时下载10个任务&#128640; 单任务最大支持64线程下载&#128374; 模拟用户代{过}{滤}理&#128276; 下载完成的通知&#128187; 准备触摸条（仅适用于Mac）&#128465; 删除任务时删除相关文件（可选）&#127757;I18n ，目前提供简体中文和英文版&#127887; ……&#128736; 开发中的更多功能注：macOS 和 Linux 版本使用的是 64 位的 aria2c，Windows 版使用的 32 位的） Motrix下载地址： http://wangpant.cn/resource/view/du78aw0txehf.html","categories":[],"tags":[]},{"title":"Windows10双开微信","slug":"Windows10双开微信","date":"2019-12-15T02:26:52.000Z","updated":"2021-04-09T15:36:13.411Z","comments":true,"path":"posts/7be0ffc3.html","link":"","permalink":"https://chengtong.me/posts/7be0ffc3.html","excerpt":"","text":"方法一使用第三方插件，有封号的风险，不推荐； 方法二微信PC端，一个网页版 方法三发现windows 10操作系统一个商店应用可以解决。我就是Windows 10，得益于Windows 10的Microsoft Store应用商店的限制，部分商店内上架的软件和官网下载的是不冲突的，例如微信和QQ。 腾讯在微软应用商店上架了两个版本的微信客户端，一个是普通的 Win32程序，一个则是UWP版本。而这两个版本与在微信官网下载安装的微信版本是可以共存的，这就给了我们在windows 10上实现微信双开甚至三开的可能 我安装的是Microsoft Store应用商店第一个，再加一个PC端，成功实现双开。 最重要的是：还很安全！ 方法四123TASKKILL /F /IM wechat.exestart \"\" \"C:\\Program Files (x86)\\Tencent\\WeChat\\WeChat.exe\"start \"\" \"C:\\Program Files (x86)\\Tencent\\WeChat\\WeChat.exe\" 方法五123456@echo offC:cd C:\\Program Files (x86)\\Tencent\\WeChatstart WeChat.execd C:\\Program Files (x86)\\Tencent\\WeChatstart WeChat.exe 方法六123@echo offstart /d \"C:\\Program Files (x86)\\Tencent\\WeChat\" WeChat.exestart /d \"C:\\Program Files (x86)\\Tencent\\WeChat\" WeChat.exe 优化(针对方法四-六)由于方法四-方法六执行bat脚本时会弹一下黑窗口，不美观，新建一个start_list.vbs脚本，具体脚本如下： 12set ws=WScript.CreateObject(\"WScript.Shell\") ws.Run \"C:\\Users\\TEST.BAT /start\",0 手动双击执行start_list.vbs脚本或将该脚本放入%USERPROFILE%\\AppData\\Roaming\\Microsoft\\Windows\\Start Menu\\Programs\\Startup实现开机启动","categories":[{"name":"Windows","slug":"Windows","permalink":"https://chengtong.me/categories/Windows/"}],"tags":[{"name":"Windows10","slug":"Windows10","permalink":"https://chengtong.me/tags/Windows10/"}]},{"title":"Spring boot设置JWT CORS跨域请求的方式","slug":"Spring boot设置JWT CORS跨域请求的方式","date":"2019-08-22T09:25:00.000Z","updated":"2021-06-08T02:20:06.320Z","comments":true,"path":"posts/5f695ca8.html","link":"","permalink":"https://chengtong.me/posts/5f695ca8.html","excerpt":"","text":"前提： 本文都是基于 spring boot 的解决方案。关于CORS的名词的解释等问题及流程 123456789101112131415161718@Configurationpublic class WebConfig extends WebMvcConfigurationSupport &#123;@Override public void addCorsMappings(CorsRegistry registry) &#123; //设置允许跨域的路径 registry.addMapping(\"/api/**\") //设置允许跨域请求的域名 .allowedOrigins(\"*\") //是配置是否允许发送Cookie，用于凭证请求， 默认不发送cookie .allowCredentials(true) //.allowedHeaders(\"*\") //设置允许的方法 .allowedMethods(\"*\") //跨域允许时间 .maxAge(3600); &#125;&#125; 我的设置如下： 123456789101112131415161718192021@Autowiredprivate Cors cors;@Override public void addCorsMappings(CorsRegistry registry) &#123; //设置允许跨域的路径 registry.addMapping(\"/api/**\") //设置允许跨域请求的域名 //.allowedOrigins(\"*\") .allowedOrigins(cors.getAllowedOrigins()) //是配置是否允许发送Cookie,用于凭证请求,默认不发送cookie .allowCredentials(true) //.allowedHeaders(\"*\") //设置允许的方法 //.allowedMethods(\"*\") .allowedMethods(\"OPTIONS\", \"GET\", \"POST\", \"PUT\", \"DELETE\") //.allowedMethods(cors.getAllowedMethods()) //跨域允许时间 .maxAge(3600); &#125; 1234567@Component@ConfigurationProperties(prefix = \"cors\")@Datapublic class Cors &#123; private String[] allowedOrigins;&#125; application.yml 12cors: allowedOrigins: \"*\" 问题： 和前端对接，JWT token存在跨域问题，统一解决跨域问题后，登录成功后，跳转到首页，记住该地址，然后退出，重新打开首页，应该会跳到登录页面，但是直接报报跨域问题，其他都正常。 解决方案1(统一使用以下代码解决跨域) 123456789101112131415@Bean public FilterRegistrationBean corsFilter() &#123; UrlBasedCorsConfigurationSource source = new UrlBasedCorsConfigurationSource(); CorsConfiguration config = new CorsConfiguration(); config.setAllowCredentials(true); // 设置你要允许的网站域名，如果全允许则设为 * config.addAllowedOrigin(StringUtils.join(cors.getAllowedOrigins())); // 如果要限制 HEADER 或 METHOD 请自行更改 config.addAllowedHeader(\"*\"); config.addAllowedMethod(\"*\"); source.registerCorsConfiguration(\"/api/**\", config); FilterRegistrationBean bean = new FilterRegistrationBean(new CorsFilter(source)); //bean.setOrder(0); return bean; &#125; 解决方案2(统一使用以下代码解决跨域) 123456789101112@Bean public CorsFilter corsFilter() &#123; CorsConfiguration config = new CorsConfiguration(); config.addAllowedOrigin(cors.getAllowedOrigins()); config.setAllowCredentials(true); config.addAllowedHeader(\"*\"); config.setAllowedMethods(Arrays.asList(\"OPTIONS\",\"GET\",\"POST\",\"PUT\",\"DELETE\")); config.setMaxAge(3600L); UrlBasedCorsConfigurationSource configSource = new UrlBasedCorsConfigurationSource(); configSource.registerCorsConfiguration(\"/api/**\", config); return new CorsFilter(configSource); &#125; 解决方案3(之前统一跨域代码不动，在JwtInterceptor拦截器中增加以下方法) 12345678910111213141516171819202122232425/** * 处理跨域问题 */ private void allowedOrigins(HttpServletRequest request, HttpServletResponse response) &#123; ServletContext context = request.getServletContext(); ApplicationContext ctx = WebApplicationContextUtils.getWebApplicationContext(context); Cors cors = ctx.getBean(Cors.class); String[] allowDomains = cors.getAllowedOrigins(); Set allowOrigins = new HashSet(Arrays.asList(allowDomains)); String originHeads = request.getHeader(\"Origin\"); if(allowOrigins.contains(originHeads))&#123; //设置允许跨域的配置 // 这里填写你允许进行跨域的主机ip（生产环境可以动态配置具体允许的域名和IP） response.setHeader(\"Access-Control-Allow-Origin\", originHeads); /*response.setHeader(\"Access-Control-Allow-Headers\", \"Origin, X-Requested-With, Content-Type, Accept, Cookie\"); response.setHeader(\"Access-Control-Allow-Methods\", \"OPTIONS, GET, POST, PUT, DELETE\"); response.setHeader(\"Access-Control-Allow-Credentials\", \"true\");*/ &#125;else if(allowOrigins.contains(\"*\"))&#123; //设置允许跨域的配置 // dev环境设置* response.setHeader(\"Access-Control-Allow-Origin\", \"*\"); &#125; &#125; 在preHandle中调用即可 注意事项： Spring Boot在拦截器中使用注解无效的解决方法 12@Autowiredprivate Cors cors; 然而，事实证明，注入失败。 我们的解决办法： 12ServletContext context = request.getServletContext();ApplicationContext ctx = WebApplicationContextUtils.getWebApplicationContext(context);Cors cors = ctx.getBean(Cors.class); 解决原理：一个http请求，先走filter，到达servlet后才进行拦截器的处理，所以我们可以把cors放在filter里，就可以优先于拦截器执行。","categories":[{"name":"JAVA","slug":"JAVA","permalink":"https://chengtong.me/categories/JAVA/"}],"tags":[{"name":"Spring Boot","slug":"Spring-Boot","permalink":"https://chengtong.me/tags/Spring-Boot/"}]},{"title":"harbor切换主机的ip地址","slug":"harbor切换主机的ip地址","date":"2019-07-28T16:00:01.000Z","updated":"2020-05-23T12:43:24.012Z","comments":true,"path":"posts/7c16aee4.html","link":"","permalink":"https://chengtong.me/posts/7c16aee4.html","excerpt":"","text":"原因harbor的ip地址没有修改，应从192.168.1.110改成192.168.1.111,修改harbor.cfg文件。 解决方法1234567# cd /home/harbor/harbor# docker-comppose down# vi harbor.cfg(老版本)# vi harbor.yml(新版本)hostname = 192.168.1.111# ./prepare# docker-compose up -d","categories":[],"tags":[]},{"title":"小程序接口无法传递session校验验证码","slug":"小程序接口无法传递session校验验证码","date":"2019-07-26T10:00:01.000Z","updated":"2020-05-23T12:43:24.048Z","comments":true,"path":"posts/ed397403.html","link":"","permalink":"https://chengtong.me/posts/ed397403.html","excerpt":"","text":"今天在写接口的时候发现一个问题，我用apiaaz测试一切正常，但是从小程序接口请求验证码，一直验证失败。 最开始用的图形验证码，查阅了不少资料，最后怀疑是cookie的问题，解决无果，换成了短信验证码 换成短信验证码之后，我用apiaaz测试一切正常，小程序请求的时候还是不正常，确定了验证码无误之后 我在控制器里把所有的参数都打印出来，以及session，然后发现session为Null，我又用apiaaz测试了一下 可以登陆，那为什么我可以登陆，小程序不行呢？又查阅了资料，终于找到了答案 普通的Web开发，都是把sessionid保存在cookie中传递的。 不管是java还是php，服务端的会在response的header中加上Set-Cookie 1234Response HeadersContent-Type:application/json;charset=UTF-8Date:Mon, 02 Apr 2018 16:02:42 GMTSet-Cookie:JSESSIONID=781C7F500DFA24D663BA243A4D9044BC;path=/yht;HttpOnly 浏览器的请求也会在header中加上 123456789Request HeadersAccept:*/*Accept-Encoding:gzip, deflate, brAccept-Language:zh-CN,zh;q=0.8Cache-Control:no-cacheConnection:keep-aliveContent-Length:564content-type:application/jsonCookie:JSESSIONID=781C7F500DFA24D663BA243A4D9044BC;path=/yht;HttpOnly 通过这个sessionid就能使浏览器端和服务端保持会话，使浏览器端保持登录状态 但是，微信小程序不能保存Cookie，导致每次wx.request到服务端都会创建一个新的会话，小程序端就不能保持登录状态了 一个比较简单的办法就是在小程序端把cookie保存到storage里，后续请求的时候再读storage，把cookie添加到请求头里，这样做的好处就是，服务端不用做任何改动 具体操作如下： 1、在小程序里把服务端response的Set-Cookie中的值保存到Storage中 123456789101112wx.request(&#123; url: path, method:method, header: header, data:data, success:function(res)&#123; if(res &amp;&amp; res.header &amp;&amp; res.header[&apos;Set-Cookie&apos;])&#123; wx.setStorageSync(&apos;cookieKey&apos;, res.header[&apos;Set-Cookie&apos;]);//保存Cookie到Storage &#125;&#125;, fail:fail &#125;) 2、wx.request再从Storage中取出Cookie,封装到header中 123456789101112131415let cookie = wx.getStorageSync(&apos;cookieKey&apos;);let path=conf.baseurl+url;let header = &#123; &#125;;if(cookie)&#123; header.Cookie=cookie;&#125;wx.request(&#123; url: path, method:method, header: header, data:data, success:success, fail:fail&#125;) 写法可能不太相同，但是重要的是思路，就是需要小程序端获取Set-Cookie中的值，在请求的时候携带在header中，这样就能保持会话啦。","categories":[],"tags":[]},{"title":"Java后台获得微信小程序(getUnlimited)生成的二维码","slug":"Java后台获得微信小程序(getUnlimited)生成的二维码","date":"2019-07-26T07:00:00.000Z","updated":"2020-05-23T12:43:24.127Z","comments":true,"path":"posts/a5ca03ae.html","link":"","permalink":"https://chengtong.me/posts/a5ca03ae.html","excerpt":"","text":"为了直接扫描一个二维码就进入小程序并完成部分业务操作, 需要用到微信小程序提供的二维码接口 wxacode.getUnlimited 官方文档点击此处 说几个注意事项,节省时间. 请求方式为POST 地址为:https://api.weixin.qq.com/wxa/getwxacodeunlimit?access_token=ACCESS_TOKEN 请求参数为JSON例如: 1234&#123; \"scene\":\"id=1\", \"page\":\"pages/practice/practice\"&#125; 返回值有两种,错误时为JSON字符串 ,正确时为Buffer流.错误代码如 {“errcode”:47001,”errmsg”:”data format error hint: [Tj00971523]”}在获取TOKEN之后,替换请求地址中ACCESS_TOKEN. 随后,发送POST请求并获取流,代码如下: 工具方法 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061/* 发送 post请求 用HTTPclient 发送请求*/ public static byte[] postB(String URL, String json) &#123; String obj = null; InputStream inputStream = null; Buffer reader = null; byte[] data = null; // 创建默认的httpClient实例. CloseableHttpClient httpclient = HttpClients.createDefault(); // 创建httppost HttpPost httppost = new HttpPost(URL); httppost.addHeader(\"Content-type\", \"application/json; charset=utf-8\"); httppost.setHeader(\"Accept\", \"application/json\"); try &#123; StringEntity s = new StringEntity(json, Charset.forName(\"UTF-8\")); s.setContentEncoding(\"UTF-8\"); httppost.setEntity(s); CloseableHttpResponse response = httpclient.execute(httppost); try &#123; // 获取相应实体 HttpEntity entity = response.getEntity(); if (entity != null) &#123; inputStream = entity.getContent(); data = readInputStream(inputStream); &#125; return data; &#125; finally &#123; response.close(); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; // 关闭连接,释放资源 try &#123; httpclient.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; return data; &#125; /** 将流 保存为数据数组 * @param inStream * @return * @throws Exception */ public static byte[] readInputStream(InputStream inStream) throws Exception &#123; ByteArrayOutputStream outStream = new ByteArrayOutputStream(); // 创建一个Buffer字符串 byte[] buffer = new byte[1024]; // 每次读取的字符串长度，如果为-1，代表全部读取完毕 int len = 0; // 使用一个输入流从buffer里把数据读取出来 while ((len = inStream.read(buffer)) != -1) &#123; // 用输出流往buffer里写入数据，中间参数代表从哪个位置开始读，len代表读取的长度 outStream.write(buffer, 0, len); &#125; // 关闭输入流 inStream.close(); // 把outStream里的数据写入内存 return outStream.toByteArray(); &#125; Controller 或其他方式调用 123456789101112131415161718192021222324252627282930313233@PostMapping(\"/getwxacodeunlimit\") public ResponseVO getQr(@RequestBody String str) &#123; byte[] data = new byte[]&#123;&#125;; if (StringUtils.isNotBlank(str)) &#123; JSONObject jsonObject = JSON.parseObject(str); if (null != jsonObject &amp;&amp; StringUtils.isNotBlank(jsonObject.getString(\"scene\")) &amp;&amp; StringUtils.isNotBlank(jsonObject.getString(\"page\"))) &#123; try &#123; String scene = jsonObject.getString(\"scene\"); String page = jsonObject.getString(\"page\"); String response = WxGeneral.getAuthAccessToken(); jsonObject = JSONObject.parseObject(response); if (null != jsonObject &amp;&amp; StringUtils.isNotBlank(jsonObject.getString(\"access_token\"))) &#123; String access_token = jsonObject.getString(\"access_token\"); StringBuffer sb = new StringBuffer(\"https://api.weixin.qq.com/wxa/getwxacodeunlimit?access_token=\" + access_token); String url = sb.toString(); HashMap&lt;String, String&gt; params = new HashMap&lt;&gt;(); params.put(\"scene\", scene); params.put(\"page\", page); String paramJson = JSONObject.toJSONString(params); logger.info(\"paramJson:\" + paramJson); data = HttpUtils.postB(url, paramJson); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; &#125; return getFromData(data); &#125; 图片示例: 注意事项： Controller的getQr方法不可返回String类型，否则无法使用，返回如下","categories":[],"tags":[]},{"title":"Docker CE 19.03正式发布,无需root权限","slug":"Docker CE 19.03正式发布,无需root权限","date":"2019-07-26T01:16:01.000Z","updated":"2020-05-23T12:43:23.966Z","comments":true,"path":"posts/7a1938ca.html","link":"","permalink":"https://chengtong.me/posts/7a1938ca.html","excerpt":"","text":"Docker CE 19.03 和 EE 3.0 都已经发布，19.03 主要内容包括无需 root 权限、支持 GPU 的增强功能和 CLI 插件更新等等，19.03 现在是允许非 root 用户运行守护程序，启用 Rootless 模式可以防止攻击者夺取主机的 root 权限，即使 Docker 存在漏洞或设置错误。 更新内容如下： Builder 增加了内联缓存支持 –cache-from docker/engine#215 允许输出配置 moby/moby#38898 固定的 GCR 变通令牌缓存 docker/engine#212 下载错误时调用 stopprogress docker/engine#215 Buildkit 现在使用 systemd 的 resolv.conf docker/engine#260 现在允许设置 buildkit 输出 docker/cli#1766 查找 Dockerfile 特定的 dockerignore 文件(例如，Dockerfile.dockerignore)以查找被忽略的路径 docker/engine#215 自动检测 x86、ARM 和 ARM 64 二进制文件是否可以执行进程 docker/engine#215 更新 buildkit 到 1f89ec1 docker/engine#260 默认情况下使用 Dockerfile 版本 docker/dockerfile:1.1 docker/engine#215 不再依赖外部映像进行复制/添加操作 docker/engine#215 Client 在 docker update 中添加 –pids-limit 标志 docker/cli#1765 添加对服务的系统支持 docker/cli#1754 在复合文件中增加了对 template_driver 的支持 docker/cli#1746 使用该参数–device启动时将设备传递到 Windows 容器中 docker/cli#1606 增加了对数据路径端口配置的支持 docker/cli#1509 添加快速上下文 switch: commands docker/cli#1501 每个节点添加最大副本 docker/cli#1612 添加选项来 pull 图像 docker/cli#882 添加 –domainname 标志 docker/cli#1130 在 docker stack deploy 增加了对秘密驱动程序的支持 docker/cli#1783 在服务上添加使用 Configs 作为 CredentialSpecs 的能力 docker/cli#1781 添加 –security-opt systempaths=unconfined 支持 docker/cli#1808 增加了编写和运行 CLI 插件的基本框架 docker/cli#1564 docker/cli#1898 增加对 Docker Buildx 的支持 docker/docker-ce-packaging#336 增加了对 Docker Cluster v1.0.0-Rc2 的支持 增加了对 Docker Template v0.1.4 的支持 增加了对 Docker Registry v0.1.0-rc1 的支持 CLI 更改为将驱动程序特定的选项传递给 docker run docker/cli#1767 …… API 更新 API 版本至 v1.40 moby/moby#38089 将警告添加到 /info 端点，并将检测移至守护进程 moby/moby#37502 添加了对 /_ping 端点的 HEAD 支持 moby/moby#38570 添加 Cache-Control 头部以禁用缓存 /_ping 端点 moby/moby#38569 对 /version 添加了containerd, runc, 和 docker-initmoby/moby#37974 添加了无文档 /GRPC 端点和注册的 BuildKit 控制器 moby/moby#38990 Networking 移除 IPVLAN 驱动程序 moby/moby#38983 增加了对 dangling 过滤器的支持 moby/moby#31551 docker/libnetwork#2230 当服务被更新为 –Network-rm 时，负载平衡器沙箱被删除 docker/engine#213 Windows：现在强制在 PortBinding 中指定的 nil IP到 IPv4zero(0.0.0.0) docker/libnetwork#2376 此版本改进内容比较多，获取列表查看发布日志","categories":[],"tags":[]},{"title":"Linux根目录爆满解决方案","slug":"Linux根目录爆满解决方案","date":"2019-07-21T16:00:01.000Z","updated":"2020-05-23T12:43:23.983Z","comments":true,"path":"posts/76169928.html","link":"","permalink":"https://chengtong.me/posts/76169928.html","excerpt":"","text":"Linux根目录爆满 解决(/dev/mapper/centos-root 100%问题) 使用df -h命令查看,查看详情 使用du -h -x –max-depth=1 查看哪个目录占用过高，对于过高目录中的内容适当删减腾出一些空间 CentOS 7 调整 home分区扩大root分区 总体过程： 把/home内容备份，然后将/home文件系统所在的逻辑卷删除，扩大/root文件系统，新建/home ，恢复/home内容。 将/home的硬盘空间根据实际需求分配即可；如果/home为600G 重新分配，根路径为450G，实际在以前基础上进行叠加，150G分给/home 1.查看分区 df -h 2.备份home分区文件 tar czvf home.tar.gz /home 3.卸载/home，如果无法卸载，先终止使用/home文件系统的进程 如果提示未识别的命令 先安装yum install psmisc -y fuser -km /home/ umount /home 4.删除/home所在的lv lvremove /dev/mapper/centos-home 5.扩展/root所在的lv，增加450G lvextend -L +450G /dev/mapper/centos-root 6.扩展/root文件系统 xfs_growfs /dev/mapper/centos-root 7.重新创建home lv lvcreate -L 150G -n/dev/mapper/centos-home 8.创建文件系统 mkfs.xfs /dev/mapper/centos-home 9.挂载home mount /dev/mapper/centos-home 10.home文件恢复 tar xzvf /home.tar.gz","categories":[{"name":"Linux","slug":"Linux","permalink":"https://chengtong.me/categories/Linux/"}],"tags":[{"name":"CentOS","slug":"CentOS","permalink":"https://chengtong.me/tags/CentOS/"}]},{"title":"git忽略文件配置.gitignore","slug":"git忽略文件配置.gitignore","date":"2019-07-10T07:26:01.000Z","updated":"2020-05-23T12:43:24.013Z","comments":true,"path":"posts/ef0397e9.html","link":"","permalink":"https://chengtong.me/posts/ef0397e9.html","excerpt":"","text":"123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148# Windows thumbnail cache filesThumbs.dbThumbs.db:encryptableehthumbs.dbehthumbs_vista.db# Dump file*.stackdump# Folder config file[Dd]esktop.ini# Recycle Bin used on file shares$RECYCLE.BIN/# Windows Installer files*.cab*.msi*.msix*.msm*.msp# Windows shortcuts*.lnk# macOS# General.DS_Store.AppleDouble.LSOverride# Icon must end with two \\rIcon# Thumbnails._*# Files that might appear in the root of a volume.DocumentRevisions-V100.fseventsd.Spotlight-V100.TemporaryItems.Trashes.VolumeIcon.icns.com.apple.timemachine.donotpresent# Directories potentially created on remote AFP share.AppleDB.AppleDesktopNetwork Trash FolderTemporary Items.apdisk# Java# Compiled class file*.class# Log file*.log# BlueJ files*.ctxt# Mobile Tools for Java (J2ME).mtj.tmp/# Package Files #*.jar*.war*.nar*.ear*.zip*.tar.gz*.rar# virtual machine crash logs, see http://www.java.com/en/download/help/error_hotspot.xmlhs_err_pid*# Eclipse.metadatabin/tmp/*.tmp*.bak*.swp*~.niblocal.properties.settings/.loadpath.recommenders# External tool builders.externalToolBuilders/# Locally stored &quot;Eclipse launch configurations&quot;*.launch# PyDev specific (Python IDE for Eclipse)*.pydevproject# CDT-specific (C/C++ Development Tooling).cproject# CDT- autotools.autotools# Java annotation processor (APT).factorypath# PDT-specific (PHP Development Tools).buildpath# sbteclipse plugin.target# Tern plugin.tern-project# TeXlipse plugin.texlipse# STS (Spring Tool Suite).springBeans# Code Recommenders.recommenders/# Annotation Processing.apt_generated/# Scala IDE specific (Scala &amp; Java development for Eclipse).cache-main.scala_dependencies.worksheet# IntelliJ project files.idea*.imloutgenlogs/target/","categories":[],"tags":[]},{"title":"java.lang.NoSuchMethodError","slug":"java.lang.NoSuchMethodError","date":"2019-07-08T16:00:01.000Z","updated":"2020-05-23T12:43:24.018Z","comments":true,"path":"posts/c65b3c3e.html","link":"","permalink":"https://chengtong.me/posts/c65b3c3e.html","excerpt":"","text":"java.lang.NoSuchMethodError: javax.persistence.spi.PersistenceUnitInfo.getValidationMode()的解决方法 今天在搭建springboot（2.1.0.RELEASE）+spring data+jpa+maven时按照书上的说法进行配置，结果就报了这个错误。后来经过网上查询资料和自己一步一步尝试，发现原来是我在pom.xml文件中配置了tk.mybatis造成的（我先是搭建了springboot+mybatis+maven的项目，后来在此基础上进行修改，故pom.xml文件中的依赖没有删除掉），因为tk.mybatis会自动引用依赖引入persistence-api-1.0.jar包，而persistence-api-1.0.jar的PersistenceUnitInfo类中并没有getValidationMode()方法，而在springboot（2.1.0.RELEASE）中自动引入的依赖persistence-api-2.2.jar包的PersistenceUnitInfo类则有实现getValidationMode()方法。此时两个类冲突了，导致报了以下的错误。解决方法就是在tk.mybatis中排除掉persistence-api-1.0.jar的自动依赖，如下： 1234567891011&lt;dependency&gt; &lt;groupId&gt;tk.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mapper-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.1.1&lt;/version&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;javax.persistence&lt;/groupId&gt; &lt;artifactId&gt;persistence-api&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt; An attempt was made to call the method javax.persistence.spi.PersistenceUnitInfo.getValidationMode()Ljavax/persistence/ValidationMode; but it does not exist. Its class, javax.persistence.spi.PersistenceUnitInfo, is available from the following locations: jar:file:/d:/Maven/repository/javax/persistence/persistence-api/1.0/persistence-api-1.0.jar!/javax/persistence/spi/PersistenceUnitInfo.classjar:file:/d:/Maven/repository/javax/persistence/javax.persistence-api/2.2/javax.persistence-api-2.2.jar!/javax/persistence/spi/PersistenceUnitInfo.class It was loaded from the following location: file:/d:/Maven/repository/javax/persistence/persistence-api/1.0/persistence-api-1.0.jar","categories":[],"tags":[]},{"title":"OpenProject 9 发布了","slug":"OpenProject 9 发布了","date":"2019-07-07T02:05:24.000Z","updated":"2020-07-22T09:49:31.169Z","comments":true,"path":"posts/b9173e5f.html","link":"","permalink":"https://chengtong.me/posts/b9173e5f.html","excerpt":"","text":"OpenProject 是一个开源项目协作管理软件。它是 Trello 和 Jira 等专有方案的替代品。 如果个人使用，你可以免费使用它，并在你自己的服务器上进行设置（并托管它）。这样，你就可以控制数据。 当然，如果你是企业云版的用户，那么你可以使用高级功能和更优先的帮助。 OpenProject 9 的重点是新的面板视图，包列表视图和工作模板。 如果你对此不了解，可以尝试一下。但是，如果你是已有用户 —— 在迁移到 OpenProject 9 之前，你应该知道这些新功能。 OpenProject 9 有什么新功能？ 以下是最新版 OpenProject 的一些主要更改。 Scrum 和敏捷面板 对于企业云版，有了一个新的 scrum和敏捷面板视图。你还可以看板风格方式展示你的工作，从而更轻松地支持你的敏捷和 scrum 团队。 新的面板视图使你可以轻松了解为该任务分配的人员并快速更新状态。你还有不同的面板视图选项，如基本面板、状态面板和版本面板。 工作包模板 Work Package Template 你不必为每个独立的工作包从头开始创建所有内容。而是，你只需保留一个模板，这样你就可以在需要创建新工作包时使用它。这将节省大量时间。 新的工作包列表视图 Work Package View 在工作包列表中，有一个微小的新增功能，可让你查看特定工作的已分配人员的头像。 “我的”页面的可自定义工作包视图 “我的”页面显示你正在处理的内容（以及进度），它不应该一直那么呆板。因此，现在你可以自定义它，甚至可以添加甘特图来可视化你的工作。 OpenProject下载和安装 OpenProject下载和安装 总结 有关迁移和安装的详细说明，请参阅官方的公告帖，其中包含了必要的细节。","categories":[],"tags":[]},{"title":"微信未绑定企业号开发者","slug":"微信未绑定企业号开发者","date":"2019-06-30T16:00:01.000Z","updated":"2020-05-23T12:43:24.092Z","comments":true,"path":"posts/78e760f3.html","link":"","permalink":"https://chengtong.me/posts/78e760f3.html","excerpt":"","text":"微信开发者工具调试企业微信页面遇到未绑定企业号开发者的问题，如图提示。 自己已经是企业微信的管理员，确还是有这个问题。网上竟然也找不到答案。 解决方法： 登录企业微信后台，在连接微信——微工作台，在页面底部，把开发者工具勾选上。 注意事项： 设置仅对自己账号有效，如果有多个管理员，谁需要用开发者工具，谁登录设置即可。 企业微信后台登录地址： https://work.weixin.qq.com/wework_admin/loginpage_wx","categories":[],"tags":[]},{"title":"Windows安装配置FFmpeg","slug":"Windows安装配置FFmpeg","date":"2019-06-11T14:01:37.000Z","updated":"2020-06-01T07:55:36.989Z","comments":true,"path":"posts/484f15fa.html","link":"","permalink":"https://chengtong.me/posts/484f15fa.html","excerpt":"","text":"ffmpeg是一个开源的音视频转码工具,它提供了录制、转换以及流化音视频的完整解决方案，可以转码、压制、提取、截取、合并、录屏等。 一、下载FFmpeg 下载地址：http://ffmpeg.zeranoe.com/builds/根据你的系统选择下载： 解压到D:\\Program Files 将文件夹ffmpeg-20200315-c467328-win64-static重命名为ffmpeg 配置环境变量 此电脑-属性 选择高级系统设置 选择环境变量 在用户环境变量双击path 选择新建（注意不要更改其他环境变量） 将刚才的bin路径粘贴进去 记得点下方的确定，再关闭当前窗口再点确定以保存 到这里，ffmpeg的配置就差不多了，调用命令行（windows+R输入cmd）输入“ffmpeg –version”，如果出现如下说明配置成功 1ffmpeg –version","categories":[],"tags":[{"name":"FFmpeg","slug":"FFmpeg","permalink":"https://chengtong.me/tags/FFmpeg/"}]},{"title":"配置Spring-boot的main方法","slug":"配置Spring-boot的main方法","date":"2019-05-31T16:00:01.000Z","updated":"2020-05-23T12:43:24.067Z","comments":true,"path":"posts/80dd260f.html","link":"","permalink":"https://chengtong.me/posts/80dd260f.html","excerpt":"","text":"1、配置Spring-boot的main方法 2、Could not find or load main class ${start-class} 修改pom.xml文件，用如下方式实现. 1234&lt;properties&gt;&lt;!-- The main class to start by executing java -jar --&gt;&lt;start-class&gt;com.yihaomen.SpringBootWebApplication&lt;/start-class&gt;&lt;/properties&gt; 当然，还需要可以在Spring-boot-maven插件中配置1234567891011&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;mainClass&gt;com.yihaomen.SpringBootWebApplication&lt;/mainClass&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt;","categories":[],"tags":[]},{"title":"openldap密码加密算法及原理","slug":"openldap密码加密算法及原理","date":"2019-05-29T16:00:01.000Z","updated":"2020-05-23T12:43:24.095Z","comments":true,"path":"posts/e2686736.html","link":"","permalink":"https://chengtong.me/posts/e2686736.html","excerpt":"","text":"openldap 各大数据管理工具密码生成的原理及算法,只为那些需要手动的产生密码的人员提供点帮助。 注：这里说的密码加密不是说openldap管理工具登录的那个密码,是用户数据的userPassword属性从文本到密码的一个过程* 问题： 我们使用openldap管理工具时对ldap里面的数据（一个用户）设置密码时是直接set的 那么这个密码是如何从用户设置的文本(123456)到{MD5}4QrcOUm6Wau+VuBX8g+IPg=== 加密原理 代码示例 String password= “123456”; MessageDigest md = MessageDigest.getInstance(“MD5”); md.update(password.getBytes()); byte[] bs = md.digest(); byte[] base64MD5Password = Base64.encode(bs); openldap 各大数据管理工具密码生成的原理及算法,只为那些需要手动的产生密码的人员提供点帮助。 注：这里说的密码加密不是说openldap管理工具登录的那个密码,是用户数据的userPassword属性从文本到密码的一个过程 System.out.println(“base64MD5Password:{MD5}”+new String(base64MD5Password)); 注意： 不要使用网上的MD5什么32、16位的加密，这里只是用MD5将字符串加密到字节数组，然后在编码。 示例代码如下： 123456789101112131415public String getPassword(String password) &#123; final Base64.Encoder encoder = Base64.getEncoder(); String newPassword = null; try &#123; MessageDigest md = MessageDigest.getInstance(\"MD5\"); md.update(password.getBytes()); byte[] bs = md.digest(); byte[] base64MD5Password = encoder.encode(bs); newPassword = new String(base64MD5Password); newPassword = \"&#123;MD5&#125;\" + newPassword; &#125; catch (NoSuchAlgorithmException e) &#123; e.printStackTrace(); &#125; return newPassword; &#125;","categories":[],"tags":[]},{"title":"安装Centos7.2详细教程","slug":"安装Centos7.2详细教程","date":"2019-05-22T14:12:28.000Z","updated":"2020-05-23T12:43:24.464Z","comments":true,"path":"posts/e6c03d98.html","link":"","permalink":"https://chengtong.me/posts/e6c03d98.html","excerpt":"","text":"以下采用U盘方式安装CentOS 7.2，若采用其他方式安装，仅第一步不同。 第1步：设置U盘为开机启动方式插上U盘，启动服务器，在启动画面时，按F12（机器不同时有所差异），进入设置界面，选择U盘。 第2步：开始安装CentOS7 问题列表此处安装若出现问题 进入这个界面后选择第一个。然后安装不会进到安装配置界面，而是会出如下错： Warning：/dev/root does not exist Generating: &quot;/run/initramfs/rdsosreport.txt&quot; 1、关于修改u盘的位置也就是网上说的比较模糊的一个地方，就是可能第一次从u盘进去之后，可能并没有出现install的界面，而是一整面的scripttimeout 这样的，还有一个命令提示符，可以输入命令。这时候就可以cd /dev 然后ls -all查看所有的设备了，可以看到sda下面的都是原来电脑的分区，而sdb下面可能会有sdb4（我的是这样），一般情况下U盘是sdb4，这里的sdb4代表U盘，U盘是什么就写什么。 这就是安装盘的所挂载的地方，所以知道U盘挂在哪里了，然后reboot。或者我们可能不知道挂在盘的名，我们可以把引导路径写为这样，查看挂在盘的名字。  vmlinuz initrd=initrd.img linux dd quiet 回车后，屏幕闪几下，出现，挂在盘名（DEVICE）、TYPE、标识。记下挂在盘名，重启电脑，进入选择安装界面，把引导路径改为： vmlinuz initrd=initrd.img inst.stage2=hd:/dev/挂载盘名称 quiet 这时候可以看到install 的界面了，就像如下这样，可以根据提示来修改（有的是按e进入，有的是tab） 将原来的 vmlinuz initrd=initrd.img inst.stage2=hd:LABEL=CentOS\\x207\\x20x86_64 rd.live.check quiet 改为： vmlinuz initrd=initrd.img repo=hd:/dev/sdb4 quiet 将标为红色的地方改掉，就是改成U盘挂载的地方。这样再ctrl+x就可以重新开始安装了。进入图形安装界面。 2、硬盘可用空间和硬盘大小不匹配(关于安装介质的检测和分区) 在安装之前一定要检查安装源（指定ISO）和安装位置（分区）。安装源里面有检查安装介质是否可以安装的按钮，这就是为什么要将原来下载的ISO文件拷贝到U盘的原因！ 然后在安装位置可能需要对硬盘分区。在开始的时候可能是只显示为区分的硬盘（也就是原来的硬盘并没有格式化），我1T的硬盘只有15G可用，如下图所示。要想重新格式化分区，就需要选自动分配分区，然后勾选上 我想让额外空间可用，如下图。 这样来回收空间之后，再选择我要分配分区。 最后，回到分区的界面，可以看到可用空间和总空间差不多。 最后点击这里自动创建他们即可。 第3步：选择安装语种选择English即可，选择后，点击右下角的Continue按钮： 第4步：选择系统时间为便于后续定位问题和查看日志，建议配置好系统的本地时间，操作如下：选择&quot;DATE &amp; TIME&quot;： Region选择&quot;Asia&quot;，City选择&quot;Shanghai&quot;，配置完成后，请点击左上角的&quot;Done&quot;完成配置： 第5步：选择安装软件类型选择&quot;SOFTWARE SELECTION&quot;： 选择&quot;Infrastructure Server&quot;，右边的都不需要勾选： 第6步：选择软件安装位置 具体参考问题2即可 第7步：点击右下角的&quot;Begin Installation&quot;，开始安装 第8步：设置root用户密码选择&quot;ROOT PASSWORD&quot;： 设置完成后，请耐心等待安装过程： 第9步：安装完成后，重启电脑 其他设置1、Centos7修改主机名的方法方法1在centos7特地添加了hostnamectl命令查看，修改主机名 使用hostnamectl set-hostname xxx 命令修改主机名，可永久生效： 重新连接主机即可看到主机名发生了改变 hostname 方法2还有一种方法是直接修改主机名文件，vi /etc/hostname，这种方法修改也是永久是生效的： 2、查看mac地址ipconfig –a 3、配置动态IPip a vim /etc/sysconfig/network-scripts/ ifcfg-xxx 将ONBOOT= yes 即可 systemctl restart network 或service network restart ping baidu.com 4、配置静态IP进入网卡目录 cd /etc/sysconfig/network-scripts/ &amp;&amp; ls 查看ip地址和网卡名称 ip a ifconfig查看网卡信息并获取到网卡的名称 编辑网卡的配置文件 vi ifcfg-ens32 ifcfg-ens32 的配置内容如下，不要和内网其它ip地址冲突 vim ifcfg-ens32 TYPE=Ethernet PROXY_METHOD=none BROWSER_ONLY=no BOOTPROTO= static IPADDR= 192.168.1.149 NETMASK= 255.255.255.0 GATEWAY= 192.168.1.1 DEFROUTE=yes IPV4_FAILURE_FATAL=no IPV6INIT=yes IPV6_AUTOCONF=yes IPV6_DEFROUTE=yes IPV6_FAILURE_FATAL=no IPV6_ADDR_GEN_MODE=stable-privacy NAME=ens32 UUID=d16fe359-9256-4414-a557-19d751b4fc72 DEVICE=ens32 ONBOOT= yes 加粗的部分是要修改的地方 退出并保存 重启网卡 systemctl restart network 5、防火墙遇到问题，若连接失败是因为CentOS 7的防火墙端口没有打开，比如开启80，3306端口，最后一定要重启防火墙； #查看防火墙状态 systemctl status firewalld #开启80端口 firewall-cmd –zone=public –add-port=80/tcp –permanent #开启3306端口 firewall-cmd –zone=public –add-port=3306/tcp –permanent #重启防火墙： firewall-cmd –reload 内网使用可直接关闭防火墙即可。 参考：https://blog.51cto.com/13363488/2308000 https://www.cnblogs.com/leewhite/p/5248314.html https://blog.csdn.net/chenlou123/article/details/53367156 https://blog.csdn.net/qq_38386316/article/details/78733995","categories":[],"tags":[]},{"title":"Windows下安装Docker的步骤","slug":"Windows下安装Docker的步骤","date":"2019-05-09T16:00:01.000Z","updated":"2020-05-23T12:43:24.270Z","comments":true,"path":"posts/94480529.html","link":"","permalink":"https://chengtong.me/posts/94480529.html","excerpt":"","text":"win7、win8 系统win7、win8 等需要利用 docker toolbox 来安装，国内可以使用阿里云的镜像来下载，下载地址：http://mirrors.aliyun.com/docker-toolbox/windows/docker-toolbox/ docker toolbox 是一个工具集，它主要包含以下一些内容： 123456Docker CLI 客户端，用来运行docker引擎创建镜像和容器Docker Machine. 可以让你在windows的命令行中运行docker引擎命令Docker Compose. 用来运行docker-compose命令Kitematic. 这是Docker的GUI版本Docker QuickStart shell. 这是一个已经配置好Docker的命令行环境Oracle VM Virtualbox. 虚拟机 下载完成之后直接点击安装，安装成功后，桌边会出现三个图标，入下图所示： 点击 Docker QuickStart 图标来启动 Docker Toolbox 终端。 如果系统显示 User Account Control 窗口来运行 VirtualBox 修改你的电脑，选择 Yes。 $ 符号那你可以输入以下命令来执行。 1234567891011121314151617181920212223$ docker run hello-world Unable to find image &apos;hello-world:latest&apos; locally Pulling repository hello-world 91c95931e552: Download complete a8219747be10: Download complete Status: Downloaded newer image for hello-world:latest Hello from Docker. This message shows that your installation appears to be working correctly. To generate this message, Docker took the following steps: 1. The Docker Engine CLI client contacted the Docker Engine daemon. 2. The Docker Engine daemon pulled the &quot;hello-world&quot; image from the Docker Hub. (Assuming it was not already locally available.) 3. The Docker Engine daemon created a new container from that image which runs the executable that produces the output you are currently reading. 4. The Docker Engine daemon streamed that output to the Docker Engine CLI client, which sent it to your terminal. To try something more ambitious, you can run an Ubuntu container with: $ docker run -it ubuntu bash For more examples and ideas, visit: https://docs.docker.com/userguide/ Win10 系统现在 Docker 有专门的 Win10 专业版系统的安装包，需要开启Hyper-V。 开启 Hyper-V 程序和功能 启用或关闭Windows功能 选中Hyper-V 1、安装 Toolbox最新版 Toolbox 下载地址： https://www.docker.com/get-docker 点击 Download Desktop and Take a Tutorial，并下载 Windows 的版本，如果你还没有登录，会要求注册登录： 2、运行安装文件双击下载的 Docker for Windows Installer 安装文件，一路 Next，点击 Finish 完成安装。 安装完成后，Docker 会自动启动。通知栏上会出现个小鲸鱼的图标，这表示 Docker 正在运行。 桌边也会出现三个图标，入下图所示： 我们可以在命令行执行 docker version 来查看版本号，docker run hello-world 来载入测试镜像测试。 如果没启动，你可以在 Windows 搜索 Docker 来启动： 启动后，也可以在通知栏上看到小鲸鱼图标： 镜像加速鉴于国内网络问题，后续拉取 Docker 镜像十分缓慢，我们可以需要配置加速器来解决，我使用的是网易的镜像地址：http://hub-mirror.c.163.com。 新版的 Docker 使用 /etc/docker/daemon.json（Linux） 或者 %programdata%\\docker\\config\\daemon.json（Windows） 来配置 Daemon。 请在该配置文件中加入（没有该文件的话，请先建一个）： 123&#123; &quot;registry-mirrors&quot;: [&quot;http://hub-mirror.c.163.com&quot;]&#125; 或 点击托盘处docker图标右键选择-Settings，然后修改如下： 点击Apply后会重启Docker。","categories":[{"name":"Windows","slug":"Windows","permalink":"https://chengtong.me/categories/Windows/"}],"tags":[]},{"title":"HTML网页中电子邮箱(Email)地址的加密和混淆防爬取","slug":"HTML网页中电子邮箱(Email)地址的加密和混淆防爬取","date":"2019-05-09T14:32:01.000Z","updated":"2020-07-22T06:39:42.085Z","comments":true,"path":"posts/c2c61a90.html","link":"","permalink":"https://chengtong.me/posts/c2c61a90.html","excerpt":"","text":"邮箱里垃圾邮件一直有很多，这让我不得不重新审视，发布在网页上的电子邮箱地址，为了避免垃圾邮件，我刻意将@更换成#，也许这在十年前是个不错的办法，但是随着神经网络和机器学习新算法的发展，这一类小手段也面临失效的风险，因为大部分都是通过修改电子邮箱地址的“@”符号，通过正则表达式筛选和特征值匹配，比如hotmail.com、gmail.com、163.com这一类疑似电子邮箱地址的特征，还是可以抓取到电子邮箱地址，所以在将Email发布到HTML网页之前我们要对其进行加密和混淆。 下面我以john@example.com为例，介绍几种加密和混淆的反垃圾邮件手段。 1. 生成图片 利用传统的图灵测试CAPTCHA，将防止采集的电子邮箱地址生成图片，利用机器不能识别的特性，来区别人和机器，生成图片的方式有很多，除了高大上的Photoshop外，甚至可以使用系统自带的绘图工具来完成，另外希望偷懒的话，还有一些在线工具可以帮助到你，比如《Top 10 Websites to Turn Your Email Address into An Image》。 当然生成图片也不是万无一失的，有理由相信既然基于图片的验证码能够被机器识别破解，那么基于同样技术的电子邮件地址肯定也再所难免，特别是OCR技术的逐步发展和成熟，采集程序可以对整张网页进行OCR，最后提取需要的内容，所以我们还需要对图片生成的邮箱地址进行噪点、干扰线等混淆，具体可以参考有关如何防止验证码被识别的相关内容。 但是经过这么一设计，我们的邮箱地址对于真正需要的人来说则变得不那么友好，人们获取准确邮箱地址的难度也加大了。 2、替换关键符号 我们知道爬虫抓取电子邮箱地址很多都是通过@这个特征符号，正如我文章一开头所述，将这个符号替换成别的那么将大大降低我们电子邮箱被抓取的概率，当然这样做的坏处是除非给用户以暗示，否则需要另外说明这是个电子邮箱地址，比如john#example.com又或者john{a}example.com等等，当然智能的电子邮箱抓取软件可以对这些小把戏自动免疫，通过判断域名也可以得到这是个电子邮箱地址，所以说将@替换成一个很特别的符号也是一种生存之道，对于这种替换手段来说，更有甚者将邮箱地址变成句子，比如john AT example DOT com，这样看来应该更安全了，但是也给真正需要这个电子邮箱地址的用户带来了少许困扰。 3、使用JavaScript JavaScript简称JS通常作为嵌入到网页的一段小脚本，为其提供更为丰富的交互和应用，我们通过JS混淆我们的电子邮箱地址，最后再用document.write或者innerHTML等输出来，这样的好处是绝大多数爬虫并不能执行网页里的脚本，它们只擅长抓取静态文本，所以完全不必担心邮箱地址泄露给爬虫，另外对于最终用户来说，通过浏览器的解释，展现在他们面前的全是一个完整的电子邮箱地址，用户体验好，不过这种方式有个较为致命的弱点就是如果用户浏览器不支持脚本，那么邮箱地址也就不能正常显示了，虽然这种情况不多见。 一个典型的例子如下，当然有很多变形的实现，比如PHP hide_email我这里也不多介绍了。 123var username = \"john\";var hostname = \"example.com\";document.write(username + \"@\" + hostname); 尤其值得一提的是ROT13算法的应用，ROT13即回转13位，说到底就是将字母表首位衔接成环，将待编码字母映射到其旋转的13位的字母上，如下示意图所示： 对于PHP来说，有函数str_rot13可以直接使用，然后根据其算法反转即可得到加密前的文本，一般使用如下JS代码： 123&lt;script type=\"text/javascript\"&gt;document.write(\"&lt;n uers=\\\"znvygb:xvpx@vaprcgvba.pbz\\\" ery=\\\"absbyybj\\\"&gt;Fraq n zrffntr&lt;/n&gt;\".replace(/[a-zA-Z]/g, function(c)&#123;return String.fromCharCode((c&lt;=\"Z\"?90:122)&gt;=(c=c.charCodeAt(0)+13)?c:c-26);&#125;));&lt;/script&gt; 上述代码将解码成以下HTML： 1&lt;a href=\"mailto:kick@inception.com\" rel=\"nofollow\"&gt;Send a message&lt;/a&gt; 4、使用HTML和CSS混淆 当然我们除了采用JavaScript，还可以利用HTML或者CSS的一些小技巧(tricks)，使用HTML注释混淆，在HTML中以&lt;!--和--&gt;包含的是注释，不会被浏览器渲染给最终用户，那么我们可以充分利用这一点从而将我们的电子邮件地址打造成这样的： 1jo&lt;!-- &gt;@. --&gt;hn@&lt;!-- &gt;@. --&gt;exam&lt;!-- &gt;@. --&gt;ple.com 这里&lt;!-- &gt;@. --&gt;不会被浏览器显示，但是足以混淆机器爬虫的抓取。 同样的结合CSS的display:none，我们仍然可以得到以下类似手段的混淆： 1jo&lt;span style=\"display:none\"&gt;@&lt;/span&gt;hn@&lt;span style=\"display:none\"&gt;@&lt;/span&gt;exam&lt;span style=\"display:none\"&gt;@&lt;/span&gt;ple.com 同样的CSS的display:none必然注定了其包含的文本不会被显示，所以最终显示的也是完整的电子邮箱地址。 对于CSS来说还有一种办法也可以让我们规避爬虫抓取，那就是利用CSS文本显示顺序的特点，比如以下： 1&lt;span class=\"obfuscate\"&gt;moc.noitpecni@kcik&lt;/span&gt; 其中CSS代码如下： 1.obfuscate &#123; unicode-bidi: bidi-override; direction: rtl; &#125; 首先文本是被我们逆序的，如果要还原，在不借助JS的情况下可以通过CSS将其再次逆序，从而得到正确的文本，当然这个方法我试用下来有一点不足，那就是用户选择复制电子邮箱地址仍然是逆序的。 最后总结来看，在对抗垃圾邮件爬虫收集的方法上充分发挥了网友的聪明才智，也涌现出各种有才的实现，限于篇幅我也不一一介绍了，其实没有绝对的安全，最安全的办法就是没有电子邮箱地址，此话怎讲？那就是使用联系表单（Contact From），让需要和你联系的人直接通过表单和你发邮件，从而避免了电子邮件地址的公开，网上联系表单的开源代码也有一堆，我的博客最后考虑的方式也是这个，现在大家可以通过右上角“关于我”找到这个链接并给我发消息了。","categories":[],"tags":[]},{"title":"MQTT入门介绍","slug":"MQTT入门介绍","date":"2019-04-29T16:00:01.000Z","updated":"2020-05-23T12:43:24.148Z","comments":true,"path":"posts/bd13fdcc.html","link":"","permalink":"https://chengtong.me/posts/bd13fdcc.html","excerpt":"","text":"一、简述MQTT（Message Queuing Telemetry Transport，消息队列遥测传输协议），是一种基于发布/订阅（publish/subscribe）模式的”轻量级”通讯协议，该协议构建于TCP/IP协议上，由IBM在1999年发布。MQTT最大优点在于，可以以极少的代码和有限的带宽，为连接远程设备提供实时可靠的消息服务。作为一种低开销、低带宽占用的即时通讯协议，使其在物联网、小型设备、移动应用等方面有较广泛的应用。 MQTT是一个基于客户端-服务器的消息发布/订阅传输协议。MQTT协议是轻量、简单、开放和易于实现的，这些特点使它适用范围非常广泛。在很多情况下，包括受限的环境中，如：机器与机器（M2M）通信和物联网（IoT）。其在，通过卫星链路通信传感器、偶尔拨号的医疗设备、智能家居、及一些小型化设备中已广泛使用。 二、设计规范由于物联网的环境是非常特别的，所以MQTT遵循以下设计原则： （1）精简，不添加可有可无的功能； （2）发布/订阅（Pub/Sub）模式，方便消息在传感器之间传递； （3）允许用户动态创建主题，零运维成本； （4）把传输量降到最低以提高传输效率； （5）把低带宽、高延迟、不稳定的网络等因素考虑在内； （6）支持连续的会话控制； （7）理解客户端计算能力可能很低； （8）提供服务质量管理； （9）假设数据不可知，不强求传输数据的类型与格式，保持灵活性。 三、主要特性MQTT协议工作在低带宽、不可靠的网络的远程传感器和控制设备通讯而设计的协议，它具有以下主要的几项特性： （1）使用发布/订阅消息模式，提供一对多的消息发布，解除应用程序耦合。 这一点很类似于XMPP，但是MQTT的信息冗余远小于XMPP，,因为XMPP使用XML格式文本来传递数据。 （2）对负载内容屏蔽的消息传输。 （3）使用TCP/IP提供网络连接。 主流的MQTT是基于TCP连接进行数据推送的，但是同样有基于UDP的版本，叫做MQTT-SN。这两种版本由于基于不同的连接方式，优缺点自然也就各有不同了。 （4）有三种消息发布服务质量： “至多一次”，消息发布完全依赖底层TCP/IP网络。会发生消息丢失或重复。这一级别可用于如下情况，环境传感器数据，丢失一次读记录无所谓，因为不久后还会有第二次发送。这一种方式主要普通APP的推送，倘若你的智能设备在消息推送时未联网，推送过去没收到，再次联网也就收不到了。 “至少一次”，确保消息到达，但消息重复可能会发生。 “只有一次”，确保消息到达一次。在一些要求比较严格的计费系统中，可以使用此级别。在计费系统中，消息重复或丢失会导致不正确的结果。这种最高质量的消息发布服务还可以用于即时通讯类的APP的推送，确保用户收到且只会收到一次。 （5）小型传输，开销很小（固定长度的头部是2字节），协议交换最小化，以降低网络流量。 这就是为什么在介绍里说它非常适合”在物联网领域，传感器与服务器的通信，信息的收集”，要知道嵌入式设备的运算能力和带宽都相对薄弱，使用这种协议来传递消息再适合不过了。 （6）使用Last Will和Testament特性通知有关各方客户端异常中断的机制。 Last Will：即遗言机制，用于通知同一主题下的其他设备发送遗言的设备已经断开了连接。 Testament：遗嘱机制，功能类似于Last Will。 四、MQTT协议原理4.1 MQTT协议实现方式实现MQTT协议需要客户端和服务器端通讯完成，在通讯过程中，MQTT协议中有三种身份：发布者（Publish）、代理（Broker）（服务器）、订阅者（Subscribe）。其中，消息的发布者和订阅者都是客户端，消息代理是服务器，消息发布者可以同时是订阅者。 MQTT传输的消息分为：主题（Topic）和负载（payload）两部分： （1）Topic，可以理解为消息的类型，订阅者订阅（Subscribe）后，就会收到该主题的消息内容（payload）； （2）payload，可以理解为消息的内容，是指订阅者具体要使用的内容。 4.2 网络传输与应用消息MQTT会构建底层网络传输：它将建立客户端到服务器的连接，提供两者之间的一个有序的、无损的、基于字节流的双向传输。 当应用数据通过MQTT网络发送时，MQTT会把与之相关的服务质量（QoS）和主题名（Topic）相关连。 4.3 MQTT客户端一个使用MQTT协议的应用程序或者设备，它总是建立到服务器的网络连接。客户端可以： （1）发布其他客户端可能会订阅的信息； （2）订阅其它客户端发布的消息； （3）退订或删除应用程序的消息； （4）断开与服务器连接。 4.4 MQTT服务器MQTT服务器以称为”消息代理”（Broker），可以是一个应用程序或一台设备。它是位于消息发布者和订阅者之间，它可以： （1）接受来自客户的网络连接； （2）接受客户发布的应用信息； （3）处理来自客户端的订阅和退订请求； （4）向订阅的客户转发应用程序消息。 4.5 MQTT协议中的订阅、主题、会话一、订阅（Subscription） 订阅包含主题筛选器（Topic Filter）和最大服务质量（QoS）。订阅会与一个会话（Session）关联。一个会话可以包含多个订阅。每一个会话中的每个订阅都有一个不同的主题筛选器。 二、会话（Session） 每个客户端与服务器建立连接后就是一个会话，客户端和服务器之间有状态交互。会话存在于一个网络之间，也可能在客户端和服务器之间跨越多个连续的网络连接。 三、主题名（Topic Name） 连接到一个应用程序消息的标签，该标签与服务器的订阅相匹配。服务器会将消息发送给订阅所匹配标签的每个客户端。 四、主题筛选器（Topic Filter） 一个对主题名通配符筛选器，在订阅表达式中使用，表示订阅所匹配到的多个主题。 五、负载（Payload） 消息订阅者所具体接收的内容。 4.6 MQTT协议中的方法MQTT协议中定义了一些方法（也被称为动作），来于表示对确定资源所进行操作。这个资源可以代表预先存在的数据或动态生成数据，这取决于服务器的实现。通常来说，资源指服务器上的文件或输出。主要方法有： （1）Connect。等待与服务器建立连接。 （2）Disconnect。等待MQTT客户端完成所做的工作，并与服务器断开TCP/IP会话。 （3）Subscribe。等待完成订阅。 （4）UnSubscribe。等待服务器取消客户端的一个或多个topics订阅。 （5）Publish。MQTT客户端发送消息请求，发送完成后返回应用程序线程。 五、MQTT协议数据包结构在MQTT协议中，一个MQTT数据包由：固定头（Fixed header）、可变头（Variable header）、消息体（payload）三部分构成。MQTT数据包结构如下： （1）固定头（Fixed header）。存在于所有MQTT数据包中，表示数据包类型及数据包的分组类标识。 （2）可变头（Variable header）。存在于部分MQTT数据包中，数据包类型决定了可变头是否存在及其具体内容。 （3）消息体（Payload）。存在于部分MQTT数据包中，表示客户端收到的具体内容。 5.1 MQTT固定头固定头存在于所有MQTT数据包中，其结构如下： 5.1.1 MQTT数据包类型 位置：Byte 1中bits 7-4。 相于一个4位的无符号值，类型、取值及描述如下： 5.1.2 标识位 位置：Byte 1中bits 3-0。 在不使用标识位的消息类型中，标识位被作为保留位。如果收到无效的标志时，接收端必须关闭网络连接： （1）DUP：发布消息的副本。用来在保证消息的可靠传输，如果设置为1，则在下面的变长中增加MessageId，并且需要回复确认，以保证消息传输完成，但不能用于检测消息重复发送。 （2）QoS：发布消息的服务质量，即：保证消息传递的次数 1234567Ø00：最多一次，即：&lt;=1Ø01：至少一次，即：&gt;=1Ø10：一次，即：=1Ø11：预留 （3）RETAIN： 发布保留标识，表示服务器要保留这次推送的信息，如果有新的订阅者出现，就把这消息推送给它，如果设有那么推送至当前订阅者后释放。 5.1.3 剩余长度（Remaining Length） 地址：Byte 2。 固定头的第二字节用来保存变长头部和消息体的总大小的，但不是直接保存的。这一字节是可以扩展，其保存机制，前7位用于保存长度，后一部用做标识。当最后一位为1时，表示长度不足，需要使用二个字节继续保存。例如：计算出后面的大小为0 5.2 MQTT可变头MQTT数据包中包含一个可变头，它驻位于固定的头和负载之间。可变头的内容因数据包类型而不同，较常的应用是作为包的标识： 很多类型数据包中都包括一个2字节的数据包标识字段，这些类型的包有：PUBLISH (QoS &gt; 0)、PUBACK、PUBREC、PUBREL、PUBCOMP、SUBSCRIBE、SUBACK、UNSUBSCRIBE、UNSUBACK。 5.3 Payload消息体Payload消息体位MQTT数据包的第三部分，包含CONNECT、SUBSCRIBE、SUBACK、UNSUBSCRIBE四种类型的消息： （1）CONNECT，消息体内容主要是：客户端的ClientID、订阅的Topic、Message以及用户名和密码。 （2）SUBSCRIBE，消息体内容是一系列的要订阅的主题以及QoS。 （3）SUBACK，消息体内容是服务器对于SUBSCRIBE所申请的主题及QoS进行确认和回复。 （4）UNSUBSCRIBE，消息体内容是要订阅的主题。","categories":[],"tags":[]},{"title":"springboot jpa注解自动生成表及注释","slug":"springboot jpa注解自动生成表及注释","date":"2019-04-27T03:49:01.000Z","updated":"2021-06-08T02:20:15.999Z","comments":true,"path":"posts/85af5292.html","link":"","permalink":"https://chengtong.me/posts/85af5292.html","excerpt":"","text":"springboot jpa注解自动生成修改表，添加索引、字段注释、字段长度、引擎等 用jpa自动生成表，只用@Entity、@Table这两个注解生成的表：引擎是MyISAM、字段长度全是默认最大、字段没注释、没有添加索引 先设置InnoDB引擎 生成表注解，并制定唯一索引（索引名、字段、类型） 1234@Entity@Table(name = \"pmi_t_user_version\", indexes = &#123;@Index(name = \"my_index_name\", columnList=\"user_id\", unique = true)&#125; ) 添加表名注释 1@org.hibernate.annotations.Table(appliesTo = \"pmi_t_user_version\",comment=\"用户登录版本信息\") 制定字段类型、长度、注释 1234@ApiModelProperty(value = \"用户id\", required = true) @NotBlank(message = \"用户id不能为空\") @Column(name = \"user_id\", nullable = false,columnDefinition=\"int(11) COMMENT '用户id'\") private long userId; 完整代码 123456789101112131415161718@Data@Entity@Table(name = \"sys_user\")@org.hibernate.annotations.Table(appliesTo = \"sys_user\",comment=\"用户\")public class User extends BaseEntity &#123; @Column(columnDefinition=\"varchar(50) COMMENT '用户名'\") private String username; @Column(columnDefinition=\"varchar(50) COMMENT '密码'\") @JSONField(serialize = false) private String password; @Column(columnDefinition=\"varchar(50) COMMENT '名称'\") private String name; @Column(columnDefinition=\"int(11) COMMENT '状态(默认1,有效;0,无效)'\") @JSONField(serialize = false) private Integer status; //省略部分字段&#125; 表截图：","categories":[{"name":"JAVA","slug":"JAVA","permalink":"https://chengtong.me/categories/JAVA/"}],"tags":[{"name":"Spring Boot","slug":"Spring-Boot","permalink":"https://chengtong.me/tags/Spring-Boot/"}]},{"title":"springboot jpa自动生成表指定引擎","slug":"springboot jpa自动生成表指定引擎","date":"2019-04-27T03:30:01.000Z","updated":"2021-06-08T02:20:24.599Z","comments":true,"path":"posts/655a5d4b.html","link":"","permalink":"https://chengtong.me/posts/655a5d4b.html","excerpt":"","text":"springboot jpa自动生成表的引擎是MyISAM，这不是我们需要的，需要更换，在配置文件中进行配置 配置默认引擎InnoDB application.properties spring.jpa.database-platform=org.hibernate.dialect.MySQL5InnoDBDialect application.yml spring: jpa: database-platform: org.hibernate.dialect.MySQL5InnoDBDialect 示例： 123456789101112131415161718spring: datasource: url: jdbc:mysql://10.2.12.31:3306/yx?useUnicode=true&amp;characterEncoding=utf-8&amp;useSSL=false&amp;serverTimezone=Hongkong username: xxx password: xxx driver-class-name: com.mysql.cj.jdbc.Driver sql-script-encoding: UTF-8 mvc: #出现错误时, 直接抛出异常 throw-exception-if-no-handler-found: true resources: #不要为我们工程中的资源文件建立映射 add-mappings: false jpa: hibernate: ddl-auto: update database-platform: org.hibernate.dialect.MySQL5InnoDBDialect show-sql: true","categories":[{"name":"JAVA","slug":"JAVA","permalink":"https://chengtong.me/categories/JAVA/"}],"tags":[{"name":"Spring Boot","slug":"Spring-Boot","permalink":"https://chengtong.me/tags/Spring-Boot/"}]},{"title":"MAC下使用ngrok实现内网穿透","slug":"MAC下使用ngrok实现内网穿透","date":"2019-04-22T02:47:52.000Z","updated":"2020-12-16T07:19:09.246Z","comments":true,"path":"posts/ab76c535.html","link":"","permalink":"https://chengtong.me/posts/ab76c535.html","excerpt":"","text":"ngrok 是一个反向代理，通过在公共的端点和本地运行的 Web 服务器之间建立一个安全的通道。ngrok 可捕获和分析所有通道上的流量，便于后期分析和重放 为什么要使用ngrok？作为一个Web开发者，我们有时候会需要临时地将一个本地的Web网站部署到外网，以供他人体验评价或协助调试等等，通常我们会这么做： 找到一台运行于外网的Web服务器 服务器上有网站所需要的环境，否则自行搭建 将网站部署到服务器上 调试结束后，再将网站从服务器上删除 只是想在公网上访问一下网站，要不要这么麻烦，累觉不爱…… 如何在Mac上使用ngrok？ 下载Mac版ngrok：https://ngrok.com/download 新建一个文件夹，将下载的压缩包拷贝到该文件夹下 解压该压缩包 打开Mac终端，cd 到该文件夹 执行如下命令，开启内网穿透服务 1./ngrok http localhost:8080 执行完上面的命令后，当Session Status 为online表示内网穿透已经成功，即可在公网通过http和https两种方式访问了 其中 ba3ca71c不是固定的，在每次启动ngrok 服务的时候都会重新生成（新的）。","categories":[{"name":"MAC","slug":"MAC","permalink":"https://chengtong.me/categories/MAC/"}],"tags":[{"name":"ngrok","slug":"ngrok","permalink":"https://chengtong.me/tags/ngrok/"}]},{"title":"PowerDesigner16.5汉化破解版安装教程","slug":"PowerDesigner16.5汉化破解版安装教程","date":"2019-04-08T16:00:01.000Z","updated":"2020-05-23T12:43:24.313Z","comments":true,"path":"posts/a169a1fd.html","link":"","permalink":"https://chengtong.me/posts/a169a1fd.html","excerpt":"","text":"一、软件下载1.下载地址http://wangpant.cn/resource/view/w64ae25r4fzq.html 2.失效请留言，会及时补上 二、软件安装1.下载安装包（包含安装文件、汉化包、破解文件） 2.下载后文件内容如下 3.进入安装文件中双击安装文件等待初始化完成后选择next 4.继续下一步 5.选择People R…China(PRC)，然后选择我同意协议 6.更改安装路径 7.根据自己需要选择，也可以全选 8.根据自己需要选择，这里选择全选 9.直接下一步 10.继续下一步 11.等待安装结束 12.安装完成选择finish 三、软件破解1.找到下载的破解文件并复制 2.找到软件的安装路径，例如我的是D盘下的powerdesign文件夹 3.将复制的破解补丁文件粘贴到改目录，会提示是否替换，替换就行 4.启动软件，没有提示激活或输入…的表示激活成功 四、软件汉化1.查看软件版本 2.汉化注意事项：此汉化包针对版本16.5.0.3982做的汉化（汉化包来自网友提供），请确认好自己的版本 3.全选汉化文件夹下的所有文件 4.复制到安装目录，和激活一样 5.重启软件，汉化完成","categories":[],"tags":[]},{"title":"win10本地打包maven程序为docker镜像报错","slug":"win10本地打包maven程序为docker镜像报错","date":"2019-03-26T09:20:33.000Z","updated":"2020-12-07T03:29:13.074Z","comments":true,"path":"posts/56813c64.html","link":"","permalink":"https://chengtong.me/posts/56813c64.html","excerpt":"","text":"#Connect to localhost:2375 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] 错误信息： 1234567[ERROR] Failed to execute goal com.spotify:docker-maven-plugin:1.0.0:build (default-cli) on project libreoffice-demo: Exception caught: java.util.concurrent.ExecutionException: com.spotify.docker.client.shaded.javax.ws.rs.ProcessingException: org.apache.http.conn.HttpHostConnectException: Connect to localhost:2375 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: connect -&gt; [Help 1][ERROR] [ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.[ERROR] Re-run Maven using the -X switch to enable full debug logging.[ERROR] [ERROR] For more information about the errors and possible solutions, please read the following articles:[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoExecutionException 我的错误原因是我没有打开本地的docker 2375端口 打开方式：右击右下角的小鲸鱼（我用的是docker for window），点击settings如下图","categories":[{"name":"Windows","slug":"Windows","permalink":"https://chengtong.me/categories/Windows/"}],"tags":[{"name":"Windows10","slug":"Windows10","permalink":"https://chengtong.me/tags/Windows10/"}]},{"title":"flume-ng-sql-source编译jar","slug":"flume-ng-sql-source编译jar","date":"2019-01-28T10:07:16.000Z","updated":"2020-05-22T02:03:24.923Z","comments":true,"path":"posts/30026bfd.html","link":"","permalink":"https://chengtong.me/posts/30026bfd.html","excerpt":"","text":"编译项目地址：https://github.com/keedio/flume-ng-sql-sourceFlume-ng-sql-source 1.5.2下载地址：https://codeload.github.com/keedio/flume-ng-sql-source/tar.gz/v1.5.21234tar -xzvf flume-ng-sql-source-1.5.2.tar.gzcd flume-ng-sql-source-1.5.2/mvn install -DskipTests -Dtarcd target 将flume-ng-sql-source-1.5.2.jar复制到FLUME_HOME/lib。编译后的flume-ng-sql-source-1.5.2.jar，下载地址：http://wangpant.cn/resource/view/hxgyv4nhjwqs.html","categories":[{"name":"数据采集","slug":"数据采集","permalink":"https://chengtong.me/categories/数据采集/"}],"tags":[{"name":"Flume","slug":"Flume","permalink":"https://chengtong.me/tags/Flume/"},{"name":"flume-ng-sql-source","slug":"flume-ng-sql-source","permalink":"https://chengtong.me/tags/flume-ng-sql-source/"}]},{"title":"为什么说GraphQL可以取代REST API","slug":"为什么说GraphQL可以取代REST API","date":"2019-01-21T03:58:21.000Z","updated":"2020-05-23T12:43:24.157Z","comments":true,"path":"posts/fbd35054.html","link":"","permalink":"https://chengtong.me/posts/fbd35054.html","excerpt":"","text":"作者：Azat Mardan 几年前，我在 DocuSign 带领了一个开发团队，任务是重写一个有数千万个用户在使用的 Web 应用程序。当时还没有可以支持前端的 API，因为从一开始，Web 应用程序就是一个.NET 大单体。西雅图的 API 团队在将拆分单体，并逐步暴露出 RESTful API。这个 API 团队由两名工程师组成，发布周期为一个月，而我们在旧金山的前端团队每周都会发布新版本。 API 团队的发布周期太长，因为很多（几乎所有）功能都必须进行手动测试，这是可以理解的。它毕竟是一个单体，而且没有适当的自动化测试——如果他们修改了一个地方，不知道在应用程序的其他地方会出现什么问题。 我记得有一次，我们的前端团队面临为某大会交付新版本的压力，但我们忘记跟进一个重要的 API 变更，这个变更未被包含在即将发布的 API 版本中。我们要么一直等待，直到错过截止日期，要么有人愿意放弃优先权，以便让我们的变更包括在即将发布的版本中。所幸的是，这个变更最后被包含在新版本中，我们也及时发布了新的前端版本。我真的希望当时我们已经使用了 GraphQL，因为它可以消除对外部团队及其发布周期的重度依赖。 在这篇文章中，我将介绍 GraphQL 的优势，以及为什么它会变得如此受欢迎。 很多公司已经在内部从 RESTful 转向了 GraphQL API：IBM、Twitter、Walmart Labs、纽约时报、Intuit、Coursera，等等。 其他一些公司不仅是在内部而且还将外部 API 也转为 GraphQL：AWS、Yelp、GitHub、Facebook 和 Shopify，等等。GitHub 甚至打算停止使用 REST API，他们的 v4 版本只使用 GraphQL。 GraphQL 究竟是一个炒作流行语还是真正会带来一场变革？有趣的是，我之前列出的大多数从 GraphQL 获益的公司都有以下这些共同点。 他们拥有包括移动端在内的多个客户端； 他们正在转向或者已经采用了微服务架构； 他们的遗留 REST API 数量暴增，变得十分复杂； 他们希望消除客户端团队对 API 团队的依赖； 他们注重良好的 API 文档和开发者体验。 GitHub 工程团队表明了他们的动机： “GraphQL 弥合了发布的内容与可以使用的内容之间的差距。我们真的很期待能够同时发布它们。GraphQL 代表了 API 开发的巨大飞跃。类型安全、内省、生成文档和可预测的响应都为我们平台的维护者和消费者带来了好处。我们期待着由 GraphQL 提供支持的平台进入新时代，也希望你们也这样做！” GraphQL 加速了开发速度，提升了开发者体验，并提供了更好的工具。我并不是说这绝对是这样的，但我会尽力说明 GraphQL 与 REST 之间的争论点及其原因。 超级数据聚合器我是 Indeed（世界排名第一的求职网站）的软件工程负责人，所以让我们先来看看 Indeed.com 的主页和职位查询结果页面。它们分别发出了 10 和 11 个 XHR 请求。 需要注意的是，在 REST 中使用 POST 进行页面浏览并不是很“正规”。 以下是其中的一些调用： GET https://inbox.indeed.com/api/getConversationCount GET https://www.indeed.com/rpc/jobdescs GET https://www.indeed.com/rpc/vjslog GET https://www.indeed.com/rpc/preccount POST https://www.indeed.com/rpc/jobalert POST https://www.indeed.com/rpc/count 在使用 GraphQL 时，上面的这些请求可以被包含在单个查询和单个请求中。 复制代码 1query HomePage &#123; getConversationCount(...) &#123; ... &#125; jobdescs(...) &#123; ... &#125; vjslog(...) &#123; ... &#125; preccount(...) &#123; … &#125; jobalert(...) &#123; … &#125; count(...) &#123; … &#125;&#125; 响应结果可能是这样的： 复制代码 1&#123; &quot;data&quot;: &#123; &quot;getConversationCount&quot;: [ &#123; ... &#125; ], &quot;vjslog&quot;: [...], &quot;preccount&quot;: [...], &quot;jobalert&quot;: [...], &quot;count&quot;: &#123;&#125; &#125;, &quot;errors&quot;: []&#125; 通常，单个调用比多个调用更方便、更有效，因为它需要更少的代码和更少的网络开销。来自 PayPal 过程团队的开发体验还证实，很多 UI 工作实际上不是 UI 工作，而是其他任务，例如前端和后端之间的通信： “我们发现，UI 开发人员实际用于构建 UI 的时间不到三分之一，剩下的时间用于确定在何处以及如何获取数据、过滤 / 映射数据以及编排 API 调用，还有一些用于构建和部署。” 需要注意的是，有实时使多个请求也是有必要的，例如多个单独的请求可以快速且异步独立地获取不同的数据，如果采用了微服务架构，它们会增加部署灵活性，而且它们的故障点是多个，而不是一个。 此外，如果页面是由多个团队开发的，GraphQL 提供了一个功能，可以将查询分解称为片段。稍后我们将详细介绍这方面的内容。 从更大的角度来看，GraphQL API 的主要应用场景是 API 网关，在客户端和服务之间提供了一个抽象层。 微服务架构很好，但也存在一些问题，GraphQL 可以用来解决这些问题。以下是来自 IBM 在微服务架构中使用 GraphQL 的经验： “总的来说，GraphQL 微服务的开发和部署都非常快。他们 5 月份开始开发，7 月份就进入了生产环境。因为他们不需要征得许可，直接开干。他强烈推荐这个方案，比开会讨论好太多了。” 接下来，让我们逐一讨论 GraphQL 的每一个好处。 提高开发速度首先，GraphQL 有助于减少发出的请求数。通过单个调用来获取所需的数据比使用多个请求要容易得多。从工程师的角度来看，这加快了开发速度。后面我会解释更多有关为什么会提升开发速度的原因，但现在我想先说明另一个问题。 后端和客户端团队需要通过密切合作来定义 API、测试它们，并做出更改。前端、移动、物联网（例如 Alexa）等客户端团队不断迭代功能，并尝试使用新的 UX 和设计。他们的数据需求经常发生变化，后端团队必须跟上他们的节奏。如果客户端和后端代码由同一团队负责，那么问题就没那么严重了。Indeed 的大多数工程团队都是由全栈工程师组成，但并非全部都是这样。对于非全栈团队，客户端团队经常因为依赖了后端团队开发速度受到影响。 当我转到 Job Seeker API 团队时，移动团队开始我们的开发进度。我们之间有很多关于参数、响应字段和测试的事情需要沟通。 在使用了 GraphQL 之后，客户端工程师就可以完全控制前端，不需要依赖任何人，因为他们可以告诉后端他们需要什么以及响应结构应该是怎样的。他们使用了 GraphQL 查询，它们会告诉后端 API 应该要提供哪些数据。 客户端工程师不需要花时间让后端 API 团队添加或修改某些内容。GraphQL 具有自文档的特点，所以可以节省一些用于查找文档以便了解如何使用 API 的时间。我相信大多数人曾经在找出确切的请求参数方面浪费了很多时间。GraphQL 协议本身及其社区在文档方面为我们提供了一些有用的工具。在某些情况下，可以从模式自动生成文档。其他时候，只需使用 GraphiQL Web 界面就足以编写一个查询。 来自纽约时报的工程师表示，他们在转到 GraphQL 和 Relay 之后，在做出变更时不需要改太多的东西： “当我们想要更新所有产品的设计时，不再需要修改多个代码库。这就是我们想要的。我们认为 Relay 和 GraphQL 是帮助我们实现这个伟大目标的完美工具。” 当一家公司已经拥有大量 GraphQL API，然后有人想出了一个新的产品创意，这也是我最喜欢 GraphQL 的应用场景。使用已有的 GraphQL API 实现原型比调用各种 REST 端点（将提供太少或太多的数据）或为新应用程序构建新的 REST API 要快得多。 开发速度的提升与开发者体验的提升密切相关。 提升开发者体验GraphQL 提供了更好的开发者体验（DX），开发者将花更少的时间思考如何获取数据。在使用 Apollo 时，他们只需要在 UI 中声明数据。数据和 UI 放在一起，阅读代码和编写代码都变得更方便。 通常，在开发 UI 时需要在 UI 模板、客户端代码和 UI 样式之间跳转。GraphQL 允许工程师在客户端开发 UI，减少摩擦，因为工程师在添加或修改代码时无需在文件之间切换。如果你熟悉 React，这里有一个很好的比喻：GraphQL 之于数据，就像 React 之于 UI。 下面是一个简单的示例，UI 中直接包含了属性名称launch.name和 launch.rocket.name 。 复制代码 1const GET_LAUNCHES = gql` query launchList($after: String) &#123; launches(after: $after) &#123; launches &#123; id name isBooked rocket &#123; id name &#125; &#125; &#125; &#125;`; export default function Launches() &#123; return ( &lt;Query query=&#123;GET_LAUNCHES&#125;&gt; &#123;(&#123; data, loading, error &#125;) =&gt; &#123; if (loading) return &lt;Loading /&gt;; if (error) return &lt;p&gt;ERROR&lt;/p&gt;; return ( &lt;div&gt; &#123;data.launches.launches.map(launch =&gt; ( &lt;div key=&#123;launch.id&#125; &gt;&#123;launch.name&#125;&lt;br/&gt; Rocket: &#123;launch.rocket.name&#125; &lt;/div&gt; ))&#125; &lt;/div&gt; ); &#125;&#125; &lt;/Query&gt; );&#125;; 使用这种方法，可以非常容易地修改或向 UI 或查询（gql）添加新字段。React 组件的可移植性更强了，因为它们描述了所需的所有数据。 如前所述， GraphQL 提供了更好的文档，而且还有一个叫作 GraphiQL 的 IDE： 前端工程师很喜欢 GraphiQL，下面引用 Indeed 的一位高级工程师说过的话： “我认为开发体验中最好的部分是能够使用 GraphiQL。对我来说，与典型的 API 文档相比，这是一种编写查询更有效的辅助方法”。 GraphQL 的另一个很棒的功能是片段，因为它允许我们在更高的组件层面重用查询。 这些功能改善了开发者体验，让开发人员更快乐，更不容易出现 JavaScript 疲劳。 提升性能工程师并不是唯一从 GraphQL 中受益的人。用户也会从中受益，因为应用程序的性能获得了提升（可以感知到的）： 减少了有效载荷（客户端只需要必要的东西）； 多个请求合并为一个请求可减少网络开销； 使用工具可以更轻松地实现客户端缓存和后端批处理和后端缓存； 预取； 更快的 UI 更新。 PayPal 使用 GraphQL 重新设计了他们的结账流程。下面是来自用户的反馈： “REST 的原则并没有为 Web 和移动应用及其用户的需求考虑，这个在结账优化交易中体现得尤为明显。用户希望能够尽快完成结账，如果应用程序使用了很多原子 REST API，就需要在客户端和服务器之间进行多次往返以获取数据。我们的结账每次往返网络时间至少需要 700 毫秒，这还不包括服务器处理请求的时间。每次往返都会导致渲染变慢，用户体验不好，结算转换率也会降低。” 性能改进中有一项是“多个请求组合成一个请求可以减少网络开销”。对于 HTTP/1 而言，这是非常正确的，因为它没有 HTTP/2 那样的多路复用机制。但尽管 HTTP/2 提供的多路复用机制有助于优化单独的请求，但它对于图遍历（获取相关或嵌套对象）并没有实际帮助。让我们来看一看 REST 和 GraphQL 是如何处理嵌套对象和其他复杂请求的。 标准化和简化复杂的 API通常，客户端会发出复杂的请求来获取有序、排好序、被过滤过的数据或子集（用于分页），或者请求嵌套对象。GraphQL 支持嵌套数据和其他难以使用标准 REST API 资源（也叫端点或路由）实现的查询。 例如，我们假设有三种资源：用户、订阅和简历。工程师需要按顺序进行两次单独的调用（这会降低性能）来获取一个用户简历，首先需要通过调用获取用户资源，拿到简历 ID，然后再使用简历 ID 来获取简历数据。对于订阅来说也是一样的。 1.GET /users/123：响应中包含了简历 ID 和工作岗位通知订阅的 ID 清单； 2.GET /resumes/ABC：响应中包含了简历文本——依赖第一个请求； 3.GET /subscriptions/XYZ：响应中包含了工作岗位通知的内容和地址——依赖第一个请求。 上面的示例很糟糕，原因有很多：客户端可能会获得太多数据，并且必须等待相关的请求完成了以后才能继续。此外，客户端需要实现如何获取子资源（例如建立或订阅）和过滤。 想象一下，一个客户端可能只需要第一个订阅的内容和地址以及简历中的当前职位，另一个客户端可能需要所有订阅和整个简历列表。所以，如果使用 REST API，对第一个客户端来说有点不划算。 另一个例子：用户表里可能会有用户的名字和姓氏、电子邮件、简历、地址、电话、社会保障号、密码（当然是经过混淆的）和其他私人信息。并非每个客户端都需要所有字段，有些应用程序可能只需要用户电子邮件，所以向这些应用程序发送社会保障号等信息就不太安全。 当然，为每个客户端创建不同的端点也是不可行的，例如 /api/v1/users 和 /api/v1/usersMobile。事实上，各种客户端通常都有不同的数据需求：/api/v1/userPublic、/api/v1/userByName、/api/v1/usersForAdmin，如果这样的话，端点会呈指数级增长。 GraphQL 允许客户要求 API 发送他们想要的字段，这将使后端工作变得更加容易：/api/gql——所有客户端只需要这个端点。 注意：对于 REST 和 GraphQL，后端都需要使用访问控制级别。 或者可以使用旧 REST 来实现 GraphQL 的很多功能。但是这样要付出什么代价？后端可以支持复杂的 RESTful 请求，这样客户端就可以使用字段和嵌套对象进行调用： 复制代码 1GET /users/?fields=name,address&amp;include=resumes,subscriptions 上面的请求将比使用多个 REST 请求更好，但它不是标准化的，不受客户端库支持，而且这样的代码也更难编写和维护。对于相对复杂的 API，工程师需要在查询中使用自己的查询字符串参数约定，最终得到类似 GraphQL 的东西。既然 GraphQL 已经提供了标准和库，为什么还要基于 REST 设计自己的查询约定呢？ 将复杂的 REST 端点与以下的 GraphQL 嵌套查询进行对比，嵌套查询使用了更多的过滤条件，例如“只要给我前 X 个对象”和“按时间按升序排列”（可以添加无限制的过滤选项）： 复制代码 1&#123; user (id: 123) &#123; id firstName lastName address &#123; city country zip &#125; resumes (first: 1, orderBy: time_ASC) &#123; text title blob time &#125; subscriptions(first: 10) &#123; what where time &#125; &#125;&#125;&#125; 在使用 GraphQL 时，我们可以在查询中保留嵌套对象，对于每个对象，我们将精确地获得我们需要的数据，不多也不少。 响应消息的数据格式反映了请求查询的结构，如下所示： 复制代码 1&#123; &quot;data&quot;: &#123; &quot;user&quot;: &#123; &quot;id&quot;: 123, &quot;firstName&quot;: &quot;Azat&quot;, &quot;lastName&quot;: &quot;Mardan&quot;, &quot;address&quot;: &#123; &quot;city&quot;: &quot;San Francisco&quot;, &quot;country&quot;: &quot;US&quot;, &quot;zip&quot;: &quot;94105&quot; &#125;, &quot;resumes&quot; [ &#123; &quot;text&quot;: &quot;some text here...&quot;, &quot;title&quot;: &quot;My Resume&quot;, &quot;blob&quot;: &quot;&lt;BLOB&gt;&quot;, &quot;time&quot;: &quot;2018-11-13T21:23:16.000Z&quot; &#125;, ], &quot;subscriptions&quot;: [ ] &#125;, &quot;errors&quot;: [] &#125; 相比复杂的 REST 端点，使用 GraphQL 的另一个好处是提高了安全性。这是因为 URL 经常会被记录下来，而 RESTful GET 端点依赖于查询字符串（是 URL 的一部分）。这可能会暴露敏感数据，所以 RESTful GET 请求的安全性低于 GraphQL 的 POST 请求。我打赌这就是为什么 Indeed 主页会使用 POST 发出“阅读”页面请求。 使用 GraphQL 可有更容易地实现分页等关键功能，这要归功于查询以及 BaaS 提供商提供的标准，以及后端的实现和客户端库使用的标准。 改进的安全性、强类型和验证GraphQL 的 schema 与语言无关。对前面的示例进行扩展，我们可以在 schema 中定义 Address 类型： 复制代码 1type Address &#123; city: String! country: String! zip: Int&#125; String 和 Int 是标量类型，! 表示字段不可为空。 schema 验证是 GraphQL 规范的一部分，因此像这样的查询将返回错误，因为 name 和 phone 不是 Address 对象的字段： 复制代码 1&#123; user (id: 123) &#123; address &#123; name phone &#125; &#125;&#125; 我们可以使用我们的类型构建复杂的 GraphQL schema。例如，用户类型可能会使用我们的地址、简历和订阅类型，如下所示： 复制代码 1type User &#123; id: ID! firstName: String! lastName: String! address: Address! resumes: [Resume] subscriptions: [Subscription]&#125; Indeed 的大量对象和类型都是使用 ProtoBuf 定义的。类型化数据并不是什么新鲜事物，而且类型数据的好处也是众所周知。与发明新的 JSON 类型标准相比，GraphQL 的优点在于已经存在可以从 ProtoBuf 自动换换到 GraphQL 的库。即使其中一个库（rejoiner）不能用，也可以开发自己的转换器。 GraphQL 提供了比 JSON RESTful API 更强的安全性，主要有两个原因：强类型 schema（例如数据验证和无 SQL 注入）以及精确定义客户端所需数据的能力（不会无意泄漏数据）。 静态验证是另一个优势，可以帮助工程师节省时间，并在进行重构时提升工程师的信心。诸如eslint-plugin-graphql之类的工具可以让工程师知道后端发生的变化，并让后端工程师确保不会破坏客户端代码。 保持前端和后端之间的契约是非常重要的。在使用 REST API 时，我们要小心不要破坏了客户端代码，因为客户端无法控制响应消息。相反，GraphQL 为客户端提供了控制，GraphQL 可以频繁更新，而不会因为引入了新类型造成重大变更。因为使用了 schema，所以 GraphQL 是一种无版本的 API。 GraphQL 的实现在选择实现 GraphQL API 的平台时，Node 是一个候选项，因为最初 GraphQL 用于 Web 应用程序和前端，而 Node 是开发 Web 应用程序的首选，因为它是基于 JavaScript 的。使用 Node 可以非常容易地实现 GraphQL（假设提供了 schema）。事实上，使用 Express 或 Koa 来实现只需要几行代码： 复制代码 1const Koa = require(&apos;koa&apos;);const Router = require(&apos;koa-router&apos;); // koa-router@7.xconst graphqlHTTP = require(&apos;koa-graphql&apos;); const app = new Koa();const router = new Router(); router.all(&apos;/graphql&apos;, graphqlHTTP(&#123; schema: schema, graphiql: true&#125;)); app.use(router.routes()).use(router.allowedMethods()); schema 是使用 npm 的 graphql 中的类型来定义的。Query 和 Mutation 是特殊的 schema 类型。 GraphQL API 的大部分实现都在于 schema 和解析器。解析器可以包含任意代码，但最常见的是以下五个主要类别： 调用 Thrift、gRPC 或其他 RPC 服务； 调用 HTTP REST API（当优先事项不是重写现有 REST API 时）； 直接调用数据存储； 调用其他 GraphQL schema 查询或服务； 调用外部 API。 这里有一个示例。 Node 很棒，但在 Indeed，我们主要使用 Java。包括 Java 在内的很多语言都支持 GraphQL，例如https://github.com/graphql-go和https://github.com/graphql-python。 由于 Indeed 主要使用了 Java，因此这里给出一个使用 graphql-java 的 Java GraphQL 示例，完整代码位于这里。它定义了 /graphql 端点： 复制代码 1import com.coxautodev.graphql.tools.SchemaParser;import javax.servlet.annotation.WebServlet;import graphql.servlet.SimpleGraphQLServlet; @WebServlet(urlPatterns = &quot;/graphql&quot;)public class GraphQLEndpoint extends SimpleGraphQLServlet &#123; public GraphQLEndpoint() &#123; super(SchemaParser.newParser() .file(&quot;schema.graphqls&quot;) //parse the schema file created earlier .build() .makeExecutableSchema()); &#125;&#125; GraphQL 的 schema 使用 POJO 来定义。GraphQL 端点类使用了 LinkRepository POJO。解析器包含了操作的（例如获取链接）实际代码： 复制代码 1@WebServlet(urlPatterns = &quot;/graphql&quot;)public class GraphQLEndpoint extends SimpleGraphQLServlet &#123; public GraphQLEndpoint() &#123; super(buildSchema()); &#125; private static GraphQLSchema buildSchema() &#123; LinkRepository linkRepository = new LinkRepository(); return SchemaParser.newParser() .file(&quot;schema.graphqls&quot;) .resolvers(new Query(linkRepository)) .build() .makeExecutableSchema(); &#125;&#125; 在很多情况下，GraphQL 的 schema 可以从其他类型的 schema 自动生成，例如 gRPC、Boxcar、ProtoBuf 或 ORM/ODM。 GraphQL 不一定需要客户端。一个简单的 GraphQL 请求就是一个常规的 POST HTTP 请求，其中包含了查询内容。我们可以使用任意的 HTTP 代理库（如 CURL、axios、fetch、superagent 等）来生成请求。例如，在终端中使用 curl 发送请求： 复制代码 1curl \\ -X POST \\ -H &quot;Content-Type: application/json&quot; \\ --data &apos;&#123; &quot;query&quot;: &quot;&#123; posts &#123; title &#125; &#125;&quot; &#125;&apos; \\ https://1jzxrj179.lp.gql.zone/graphql 以下代码可以在任意一个现代浏览器（为了避免 CORS，请访问 launchpad.graphql.com）中运行。 复制代码 1fetch(&apos;https://1jzxrj179.lp.gql.zone/graphql&apos;, &#123; method: &apos;POST&apos;, headers: &#123; &apos;Content-Type&apos;: &apos;application/json&apos; &#125;, body: JSON.stringify(&#123; query: &apos;&#123; posts &#123; title &#125; &#125;&apos; &#125;),&#125;) .then(res =&gt; res.json()) .then(res =&gt; console.log(res.data)); 虽然构建 GraphQL 请求很容易，但是还需要实现很多其他东西，比如缓存，因为缓存可以极大地改善用户体验。构建客户端缓存不是那么容易，所幸的是，Apollo 和 Relay Modern 等提供了开箱即用的客户端缓存。 什么时候不该使用 GraphQL？当然，完美的解决方案是不存在的（尽管 GraphQL 接近完美），还有一些问题需要注意，例如： 它有单点故障吗？ 它可以扩展吗？ 谁在使用 GraphQL？ 最后，以下列出了我们自己的有关 GraphQL 可能不是一个好选择的主要原因： 当客户端的需求很简单时：如果你的 API 很简单，例如 /users/resumes/123，那么 GraphQL 就显得有点重了； 为了加快加载速度使用了异步资源加载； 在开发新产品时使用新的 API，而不是基于已有的 API； 不打算向公众公开 API； 不需要更改 UI 和其他客户端； 产品开发不活跃； 使用了其他一些 JSON schema 或序列化格式。 总结GraphQL 是一种协议和一种查询语言。GraphQL API 可以直接访问数据存储，但在大多数情况下，GraphQL API 是一个数据聚合器和一个抽象层，一个可以提升开发速度、减少维护工作并让开发人员更快乐的层。因此，GraphQL 比公共 API 更有意义。很多公司开始采用 GraphQL。IBM、PayPal 和 GitHub 声称在使用 GraphQL 方面取得了巨大的成功。如果 GraphQL 很有前途，我们现在是否可以停止构建过时且笨重的 REST API，并拥抱 GraphQL？","categories":[],"tags":[]},{"title":"浅谈三种API设计风格RPC、REST、GraphQL","slug":"浅谈三种API设计风格RPC、REST、GraphQL","date":"2019-01-19T16:00:01.000Z","updated":"2020-05-23T12:43:24.161Z","comments":true,"path":"posts/f1766b5e.html","link":"","permalink":"https://chengtong.me/posts/f1766b5e.html","excerpt":"","text":"前言Web API设计其实是一个挺重要的设计话题，许多公司都会有公司层面的Web API设计规范，几乎所有的项目在详细设计阶段都会进行API设计，项目开发后都会有一份API文档供测试和联调。本文尝试根据自己的理解总结一下目前常见的四种API设计风格以及设计考虑点。 正文 RPC 这是最常见的方式，RPC说的是本地调用远程的方法，面向的是过程。 RPC形式的API组织形态是类和方法，或者说领域和行为。 因此API的命名往往是一个动词，比如GetUserInfo和CreateUser。 因为URI会非常多而且往往没有一些约定规范，所以需要有详细的文档。 也是因为无拘无束，HTTP方法基本只用GET和POST，设计起来比较简单。 这里就不贴例子了，估计超过50%的API是这种风格的。 REST 是一种架构风格，有四个级别的成熟度： 级别0：定义一个 URI，所有操作是对此 URI 发出的 POST 请求。 级别1：为各个资源单独创建 URI。 级别2：使用 HTTP 方法来定义对资源执行的操作。 级别3：使用超媒体（HATEOAS）。 级别0其实就是类RPC的风格，级别3是真正的REST，大多数号称REST的API在级别2。REST实现一些要点包括： REST形式的API组织形态是资源和实体，一切围绕资源（级别1的要点）。设计流程包括： 确定API提供的资源 确定资源之间的关系 根据资源类型和关系确定资源URI结构 确定资源的结构体 会定义一些标准方法（级别2的要点），然后把标准方法映射到实现（比如HTTP Method）： GET：获取资源详情或资源列表。对于collection类型的URI（比如/customers）就是获取资源列表，对于item类型的URI（比如/customers/1）就是获取一个资源。 POST：创建资源，请求体是新资源的内容。往往POST是用于为集合新增资源。 PUT：创建或修改资源，请求体是新资源的内容。往往PUT用于单个资源的新增或修改。实现上必须幂等。 PATCH：部分修改资源，请求体是修改的那部分内容。PUT一般要求提交整个资源进行修改，而PATCH用于修改部分内容（比如某个属性）。 DELETE：移除资源。和GET一样，对于collection类型的URI（比如/customers）就是删除所有资源，对于item类型的URI（比如/customers/1）就是删除一个资源。 需要考虑资源之间的导航（级别3的要点，比如使用HATEOAS，HATEOAS是Hypertext as the Engine of Application State的缩写）。有了资源导航，客户端甚至可能不需要参阅文档就可以找到更多对自己有用的资源，不过HATEOAS没有固定的标准，比如： 1&#123; &quot;content&quot;: [ &#123; &quot;price&quot;: 499.00, &quot;description&quot;: &quot;Apple tablet device&quot;, &quot;name&quot;: &quot;iPad&quot;, &quot;links&quot;: [ &#123; &quot;rel&quot;: &quot;self&quot;, &quot;href&quot;: &quot;http://localhost:8080/product/1&quot; &#125; ], &quot;attributes&quot;: &#123; &quot;connector&quot;: &quot;socket&quot; &#125; &#125;, &#123; &quot;price&quot;: 49.00, &quot;description&quot;: &quot;Dock for iPhone/iPad&quot;, &quot;name&quot;: &quot;Dock&quot;, &quot;links&quot;: [ &#123; &quot;rel&quot;: &quot;self&quot;, &quot;href&quot;: &quot;http://localhost:8080/product/3&quot; &#125; ], &quot;attributes&quot;: &#123; &quot;connector&quot;: &quot;plug&quot; &#125; &#125; ], &quot;links&quot;: [ &#123; &quot;rel&quot;: &quot;product.search&quot;, &quot;href&quot;: &quot;http://localhost:8080/product/search&quot; &#125; ]&#125; Spring框架也提供了相应的支持：https://spring.io/projects/spring-hateoas 1@RestControllerpublic class GreetingController &#123; private static final String TEMPLATE = &quot;Hello, %s!&quot;; @RequestMapping(&quot;/greeting&quot;) public HttpEntity&lt;Greeting&gt; greeting( @RequestParam(value = &quot;name&quot;, required = false, defaultValue = &quot;World&quot;) String name) &#123; Greeting greeting = new Greeting(String.format(TEMPLATE, name)); greeting.add(linkTo(methodOn(GreetingController.class).greeting(name)).withSelfRel()); return new ResponseEntity&lt;&gt;(greeting, HttpStatus.OK); &#125;&#125; 产生如下的结果： 除了之前提到的几个要点，REST API的设计还有一些小点： 必须无状态的，相互独立的，不区分顺序的 API需要有一致的接口来解耦客户端和服务实现，如果基于HTTP那么务必使用HTTP Method来操作资源，而且尽量使用HTTP响应码来处理错误 需要尽量考虑缓存、版本控制、内容协商、部分响应等实现 可以说REST的API设计是需要设计感的，需要仔细来思考API的资源，资源之间的关系和导航，URI的定义等等。对于一套设计精良的REST API，其实客户端只要知道可用资源清单，往往就可以轻易根据约定俗成的规范以及导航探索出大部分API。比较讽刺的是，有很多网站给前端和客户端的接口是REST的，爬虫开发者可以轻易探索到所有接口，甚至一些内部接口，毕竟猜一下REST的接口比RPC的接口容易的多。 作为补充，下面再列几个有关REST API设计大家争议讨论纠结的比较多的几个方面。 \\3. GraphQL 如果说RPC面向过程，REST面向资源，那么GraphQL就是面向数据查询了。GraphQL 既是一种用于 API 的查询语言也是一个满足你数据查询的运行时。 GraphQL 对你的 API 中的数据提供了一套易于理解的完整描述，使得客户端能够准确地获得它需要的数据，而且没有任何冗余，也让 API 更容易地随着时间推移而演进，还能用于构建强大的开发者工具。 采用GraphQL，甚至不需要有任何的接口文档，在定义了Schema之后，服务端实现Schema，客户端可以查看Schema，然后构建出自己需要的查询请求来获得自己需要的数据。 image 1## Schemas must have at least a query root type#schema &#123; query: Query&#125;type Query &#123; characters( episode: Episode ) : [Character] human( # The id of the human you are interested in id : ID! ) : Human droid( # The non null id of the droid you are interested in id: ID! ): Droid&#125;# One of the films in the Star Wars Trilogyenum Episode &#123; # Released in 1977 NEWHOPE # Released in 1980. EMPIRE # Released in 1983. JEDI&#125;# A character in the Star Wars Trilogyinterface Character &#123; # The id of the character. id: ID! # The name of the character. name: String! # The friends of the character, or an empty list if they # have none. friends: [Character] # Which movies they appear in. appearsIn: [Episode]! # All secrets about their past. secretBackstory : String @deprecated(reason : &quot;We have decided that this is not canon&quot;)&#125;# A humanoid creature in the Star Wars universe.type Human implements Character &#123; # The id of the human. id: ID! # The name of the human. name: String! # The friends of the human, or an empty list if they have none. friends: [Character] # Which movies they appear in. appearsIn: [Episode]! # The home planet of the human, or null if unknown. homePlanet: String # Where are they from and how they came to be who they are. secretBackstory : String @deprecated(reason : &quot;We have decided that this is not canon&quot;)&#125;# A mechanical creature in the Star Wars universe.type Droid implements Character &#123; # The id of the droid. id: ID! # The name of the droid. name: String! # The friends of the droid, or an empty list if they have none. friends: [Character] # Which movies they appear in. appearsIn: [Episode]! # The primary function of the droid. primaryFunction: String # Construction date and the name of the designer. secretBackstory : String @deprecated(reason : &quot;We have decided that this is not canon&quot;)&#125; 采用GraphQL Playground（https://github.com/prisma/graphql-playground） 其实就是__schema： 然后我们可以根据客户端的UI需要自己来定义查询请求，服务端会根据客户端给的结构来返回数据： 再来看看Github提供的GraphQL（更多参考https://developer.github.com/v4/guides/）： 查询出了最后的三个repo： GraphQL就是通过Schema来明确数据的能力，服务端提供统一的唯一的API入口，然后客户端来告诉服务端我要的具体数据结构（基本可以说不需要有API文档），有点客户端驱动服务端的意思。虽然客户端灵活了，但是GraphQL服务端的实现比较复杂和痛苦的，GraphQL不能替代其它几种设计风格，并不是传说中的REST 2.0。 小结在下列情况考虑RPC风格的API或说是RPC： 偏向内部的API 没有太多的时间考虑API的设计或没有架构师 提供的API很难进行资源、对象抽象 对性能有高要求 在下列情况考虑REST风格： 偏向外部API 提供的API天生围绕资源、对象、管理展开 不能耦合客户端实现 资源的CRUD是可以对齐的（功能完整的） 在下列情况考虑GraphQL： 客户端对于数据的需求多变 数据具有图的特点","categories":[],"tags":[]},{"title":"ADS RDS","slug":"ADS RDS","date":"2019-01-15T16:00:01.000Z","updated":"2020-05-23T12:43:23.922Z","comments":true,"path":"posts/3d17837d.html","link":"","permalink":"https://chengtong.me/posts/3d17837d.html","excerpt":"","text":"RDS 数据库的优点：高性能，高安全性，高可靠性。支持各种数据库引擎: Mysql, Sql Server, PostgresSQL, PPAS RDS：关系型数据库ADS: 分析型数据库 分析型数据库： 批量导入 实时写入 网络类型： 经典网络：不通过网络隔离，只能依赖实例自身的白名单阻止非法访问。 专有网络：隔离的网络环境，安全性比较高。 云服务器ESC和RDS在同一个区域下，且网络类型相同，可以通过联网，无需申请外网地址。","categories":[{"name":"数据库","slug":"数据库","permalink":"https://chengtong.me/categories/数据库/"}],"tags":[]},{"title":"Flume修改SQLSource以针对时间戳增量数据传输","slug":"flume修改sqlsource以针对时间戳增量数据传输","date":"2019-01-14T06:19:52.000Z","updated":"2020-05-22T02:03:24.924Z","comments":true,"path":"posts/3f943cf8.html","link":"","permalink":"https://chengtong.me/posts/3f943cf8.html","excerpt":"","text":"flume github关于增量数据传输的原理，是通过唯一id，递增，每次记录传输的数据量+current_index=last_index，只能识别新增数据，检测不到删除与更新。不符合没有增量id的情况。由于数据存在时间戳标志，因此改写flume sqlsource以应对实际需求： 1. 每次增量传输先查询数据库中当前最大的时间戳，记录为maxtime2. 查询数据库：select * from table where time&gt;=current_index and time&lt;maxtime,此时不能取到time=maxtime的数据，不排除在数据查询之后会继续生成maxtime的新数据，则会出现数据遗漏3. 增量数据操作完成，将current_index=maxtime，写入状态表 SQLSourceHelper增加以下两段代码：1234567891011121314151617181920//增加取数据库最大值的代码public String maxQuery() &#123; return \"SELECT max(\" + time + \") FROM \" + table; &#125;//增量查询oracle语句public String buildQuery(String maxTime) &#123; if (customQuery == null) &#123; return \"SELECT \" + columnsToSelect + \" FROM \" + table + \" \" + \"WHERE \"+ time + \"&gt;=to_date('\" + currentIndex + \"','yyyy-mm-dd hh24:mi:ss') AND \" + time + \"&lt;to_date('\" + maxTime + \"','yyyy-mm-dd hh24:mi:ss') \" + \"order by \"+time+\" asc\"; &#125; else &#123; if (customQuery.contains(\"$@$\")) &#123; return customQuery.replace(\"$@$\", currentIndex) ; &#125; else &#123; return customQuery ; &#125; &#125;&#125; HibernateHelper修改executeQuery方法：123456789101112131415161718192021222324public List&lt;List&lt;Object&gt;&gt; executeQuery() throws InterruptedException, ParseException &#123; List&lt;List&lt;Object&gt;&gt; rowsList = new ArrayList&lt;List&lt;Object&gt;&gt;() ; Query query; if (!session.isConnected())&#123; resetConnection(); &#125; String sql = sqlSourceHelper.maxQuery(); LOG.info(\"sql \"+sql); List&lt;List&lt;Object&gt;&gt; max = session.createSQLQuery(sql).setResultTransformer(Transformers.TO_LIST).list(); String maxtime = max.get(0).get(0).toString().substring(0,19); query = session.createSQLQuery(sqlSourceHelper.buildQuery(maxtime)); try &#123; rowsList = query.setResultTransformer(Transformers.TO_LIST).list(); LOG.info(\"Current time is \"+sqlSourceHelper.getCurrentIndex()+\",and lasttime is \"+maxtime); LOG.info(\"Records count: \"+rowsList.size()); &#125;catch (Exception e)&#123; LOG.error(\"Exception thrown, resetting connection.\",e); resetConnection(); &#125; sqlSourceHelper.setCurrentIndex(maxtime); return rowsList;&#125;","categories":[{"name":"数据采集","slug":"数据采集","permalink":"https://chengtong.me/categories/数据采集/"}],"tags":[{"name":"Flume","slug":"Flume","permalink":"https://chengtong.me/tags/Flume/"}]},{"title":"为什么不用原生Spring-Cloud-Config","slug":"为什么不用原生Spring-Cloud-Config","date":"2019-01-12T11:56:19.000Z","updated":"2020-05-22T02:03:24.981Z","comments":true,"path":"posts/68ef0897.html","link":"","permalink":"https://chengtong.me/posts/68ef0897.html","excerpt":"","text":"引言近几年传统应用架构已经逐渐朝着微服务架构演进。那么随着业务的发展，微服务越来越庞大，此时服务配置的管理变得会复杂起来。为了方便服务配置文件统一管理，实时更新，配置中心应运而生。其实，所谓配置中心，就是将配置的数据放在某种存储介质中，该介质可以是 File(例如Git、Svn) Database(例如mysql、oracle) nosql Database(例如Redis、Memacache、MongoDb) 其他第三方中间件(例如Zookeeper) 那么配置中心可以简单理解为是封装了对这些介质进行操作的接口，供客户端拉取使用。 由于我们采用的是Spring-Boot的架构，因此当时自然而然会考虑到Spring-Cloud中提供的配置中心Spring-Cloud-Config，但是当时做完调研以后，觉得并不能直接用。因此，本文想来分享一下，原生Spring-Cloud-Config的配置中心的缺点，以及我们对Spring-Cloud-Config做了哪些改动。 正文OK，我们当时做配置中心的选型的时候。第一选择是Spring-Cloud- Config。Spring-Cloud-Config在存储介质的选择这块，基本上网上所有的文章都在推荐使用Git，即将配置文件放在Git中，服务端从Git中读取。其实官网上讲的最详细的配置，也是采取用Git作为存储介质。因此，我相信大部分读者在生产上也是用Git作为存储介质，搭配Spring-Cloud-Config使用。但是呢，博主认为以Git作为存储介质存在一些硬伤。 Git的权限控制是个坑Git的权限管理是说控制用户能不能Push或者Delete分支，或者能不能Push代码，而不是能不能访问某个目录的文件。对目录和文件的可读是Git的最基本要求，不可能做到针对目录级别的不可读。因此如果直接使用，会出现这样一种情形 不同团队之间可以互看对方配置！ 于是，可能会有如下情形发生 A团队同事A:&quot;小B,这个地方不懂怎么配？&quot;A团队同事B:&quot;去看看B团队的配置，直接贴过来。&quot;然后B团队就会发现自己的中间件里总是会多出一些莫名奇妙的数据！ 当然，你可以禁止研发直接登陆Git改配置。然后呢，基于Git研发一套配置管理系统，在上面做权限控制，但是又有几个公司这么做呢？因为，这可能带来第二个问题。 粒度问题将配置信息放在Git中，有一个致命问题: 粒度太粗了！你每次对一条配置发生crud的操作，其带来的影响是整个文件发生变动。如果将来我们需要对某条配置做灰度发布，基于Git来做是比较麻烦的，注意了，我没说不能做，只是比较麻烦。 那么，当时我们最理想的存储介质就是数据库，将配置信息放在数据库里有 两个好处 基于数据库开发一套配置管理系统，显然比基于git来开发容易的多！ 将配置放在数据库里，每条配置对应数据库的表中的一条记录。这么做粒度够细，针对某些重要的配置，做灰度发布，实现起来就容易很多。 因此，我们采用数据库作为存储介质。庆幸的是，这一点在Spring-Cloud-Config中是支持的。在该组件下，只需要设置 spring.profiles.active=jdbc 就能够激活jdbc模式。但是我们很快发现了一个更大的问题，也正是因为这个问题，我们不得以需要进行改写Spring-Cloud-Config。 Spring-Cloud-Config的刷新机制是个坑！ 因为一个配置中心应该要能够做到，配置发生改动的时候，项目能够自动感知，自动更新配置才对。在Spring-Cloud-Config中，这套机制是借助一些代码仓库（SVN、Github等）提供的Webhook机制加上Spring-Cloud-Bus来实现的。在Webhook中配置一个回调地址，刷新流程如下图所示 OK，那么问题又来了！(1)配置数据放在数据库中，数据库里没有Webhook这种东西啊，怎么做到实时刷新？(2)__Spring-Cloud-Config的这套刷新机制依赖于消息总线，依赖于消息队列，存在延迟的情况!且依赖于消息队列的可用性，系统的复杂度大大增加。如果生产环境上消息队列出问题了，我们的刷新功能就会受到影响！ 所以，笔者认为这套刷新机制并不是很尽如人意，需要进行修改。因此，我们很自然而然的想到了利用长轮询来改写Spring-Cloud-Config的刷新机制！ 长轮询是什么既然有长轮询，那必定有短轮询，我顺便讲讲短轮询是什么！假设我们有一个需求 在页面上要实时显示后台的库存数量！比如库存减少了，用户不需要进行刷新，页面上的数字自己会变化。 那么，如果采取短轮询就是在客户端(js)中不断访问后台，后台接到请求马上返回最新的库存数，然后刷新到这个页面当中。短轮询的缺点？很明显资源浪费。假设有几百人打开了该页面，就有几百个请求在不停的请求服务端，明显听着就不合理。 因此，自然就有了长轮询的出现!其实也很简单，客户端(js)依然是不断的去请求。但是呢，服务端不是马上返回。而是等待库存数量变化了再返回。大家知道，HTTP都有超时时间。如果在该时间内，依然没有变化，客户端将再次发起请求。 注意了，长短轮询对于客户端来说是没有区别的，就是不断的轮询。但是对于服务端，区别就比较大了。在短轮询情况下，服务端对于每次请求不管有没有变化都会立即返回结果。而长轮询情况下，如果有变化才会立即返回结果。而如果没有变化，服务端则不会再立即给客户端返回结果，直到超时为止。 怎么实现那么，我们在项目中采用Spring的DeferredResult来实现。在Servlet3.0以后引入了异步请求之后，Spring封装了一下提供了相应的支持，也就是DeferredResult，能够极大的提升吞吐量。可能有人对Servlet的异步化不熟，我大概介绍一下。我们平时常用的是同步Servlet，其执行流程如下图所示 缺点很明显啦，业务逻辑线程和servlet容器线程是同一个，一般的业务逻辑总得发生点IO，比如查询数据库，比如产生RPC调用，这个时候就会发生阻塞，而我们的servlet容器线程肯定是有限的，当servlet容器线程都被阻塞的时候我们的服务这个时候就会发生拒绝访问，从而吞吐量上不去！那么，你使用异步Servlet如下图所示 在异步Servlet中，业务线程有自己的线程池进行处理，并不会占用Tomcat中的线程，从而提升了吞吐量！ 那么，怎么利用DeferredResult怎么实现长轮询呢？流程如下(1)客户端和服务端建立TCP连接(2)客户端发起HTTP请求(3)服务端发起请求，监听60s内是否有配置发生变动(如何监听配置发生变动？)(4)如果没发生变动，给客户端返回304标志位，客户端继续发起请求(5)如果发生了变动，服务端会调用DeferredResult.setResult返回200状态码，客户端收到响应结果后，会发起请求获取变更后的配置信息。 最后一个问题:如何有效快速的监听出配置表的数据发生了变动？因为我们用的是mysql。这里有一个Mysql的自定义函数叫mysql-udf-http。具有http_get()、http_post()、http_put()、http_delete()四个函数，可以在MySQL数据库中利用HTTP协议进行REST相关操作。然后再和mysql的触发器结合起来用，可以实现在配置表发生变动的时候，主动通知我们的配置中心服务端。让服务端明白配置发生了变动！ 一个疑问采用长轮询技术来实现配置刷新，客户端和服务端需之间需要一直保持TCP连接进行通信。可能有些朋友会担心，到底服务端能撑多少的连接？可能觉得对性能有影响？这里给出参考配置使用了内存8G、4核的虚拟机约可以撑8000左右的连接！ 总结最后这套配置中心，我基于原有的Spring-Cloud-Config，改写其中的刷新机制，更加符合我们的业务场景!现已将改写思路说清，大家可以自行尝试！","categories":[{"name":"Spring-Cloud","slug":"Spring-Cloud","permalink":"https://chengtong.me/categories/Spring-Cloud/"}],"tags":[]},{"title":"Centos7配置阿里云yum镜像","slug":"Centos7配置阿里云yum镜像","date":"2018-12-31T14:05:30.000Z","updated":"2020-05-23T12:43:23.952Z","comments":true,"path":"posts/97614a38.html","link":"","permalink":"https://chengtong.me/posts/97614a38.html","excerpt":"","text":"备份旧的 yum 源1mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backup 下载阿里云 repo1wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo 清除缓存1yum clean all 生成缓存1yum makecache","categories":[{"name":"Linux","slug":"Linux","permalink":"https://chengtong.me/categories/Linux/"}],"tags":[{"name":"CentOS","slug":"CentOS","permalink":"https://chengtong.me/tags/CentOS/"}]},{"title":"Rust语言开发工具","slug":"Rust语言开发工具","date":"2018-12-26T09:00:00.000Z","updated":"2020-05-23T12:43:24.207Z","comments":true,"path":"posts/13874da1.html","link":"","permalink":"https://chengtong.me/posts/13874da1.html","excerpt":"","text":"Sublime Text 编辑器VSCode 编辑器简介VSCode 是微软出的一款开源代码编辑器，继承了微软在 IDE 领域的优秀基因，是一款潜力相当大的代码编辑器。 VSCode 目前也对 Rust 也有良好的支持。接下来我们来配置下 VSCode 使其更加利于 Rust 项目的开发。 下载 VSCode点击这里进入官方页面下载与操作系统相对应的 VSCode 编辑器。官方提供了完善的 GUI 安装包，按照指示一步步安装下去即可。 安装 Rust 扩展 打开 VScode 编辑器，按 Ctrl + p 打开命令面板，在编辑器中上部浮现出的输入框中，输入 ext install Rust 后回车确认： VSCode 会自动搜索可用的插件，搜索出来后，选择 Rust（rls）进行安装： 注：推荐使用 RLS 模式，即使用 Rust Langular Server 提供各项功能支持 安装完成后会显示 installed： 使用 VScode 打开任意一个.rs 文件，输入一些 Rust 代码，可以发现会出现方法补全： VSCode 还可以使用内置的命令行工具： 通过内置命令行直接使用命令编译 Rust 脚本： 通过内置命令行直接测试运行编译成功的应用程序： intellij-idea中安装rust插件需要安装两个插件 intellij-rust和intellij-toml, intellij-rust是Rust语言插件，intellij-toml是为Toml语言的插件，是为cargo的配置文件cargo.toml使用。 安装方式：Perferences.. -&gt; Plugins在Marketplact中直接搜索Rust 可以看到 Toolchain location 是配置的$HOME/.cargo/bin,而Standard library是之前安装的rust-src的目录。 创建项目成功可以看到一个完整的rust项目: IntelliJ Rust官网https://intellij-rust.github.io/","categories":[{"name":"Rust","slug":"Rust","permalink":"https://chengtong.me/categories/Rust/"}],"tags":[]},{"title":"Rust语言环境安装","slug":"Rust语言环境安装","date":"2018-12-25T03:07:00.000Z","updated":"2020-05-23T12:43:24.246Z","comments":true,"path":"posts/271b275c.html","link":"","permalink":"https://chengtong.me/posts/271b275c.html","excerpt":"","text":"Windows 开发环境说明本文示范的操作系统为 Windows 10 操作系统。 在 Windows 操作系统下可以点击此处进入下载页面，然后按照以下步骤进行安装。 安装步骤 进入下载页面后，点击 RUSTUP-INIT.EXE 按钮进行下载 Rust 安装包： 下载完成后打开安装包进入安装页面，输入 1 选择 1) Proceed with installation (default) 后回车进行默认安装： 安装成功会显示 stable installed： 安装完成后，打开命令行工具查看 Rust 版本： Windows 注意事项在 Windows 上， Rust 需要 Visual C++ 生成工具 2013 或更新版本的支持。获取 Visual C++ 生成工具最方便的方法是安装 Microsoft Visual C++ Build Tools 2017 。或者，你可以 安装 Visual Studio 2017, Visual Studio 2015, 或 Visual Studio 2013 并在安装过程中选择安装 「C++ 工具」。 关于在 Windows 上配置 Rust 的更多信息请查看 Windows-specific rustup 文档。 其他安装方法上述通过 rustup 的安装方法是大多数开发者的首选。 此外， Rust 也可以 通过其他方法安装。 Mac 开发环境 (Homebrew)说明Mac 上有两种安装方式，一种是官方的命令行运行： 1$ curl https://sh.rustup.rs -sSf | sh 可以参考： Wiki：Rust 语言环境安装：Linux 开发环境（Ubuntu 18） 另一种是使用 Homebrew，这里我们使用此方法来安装，还没有安装 Homebrew 的用户需先自行安装。 以下操作使用 macOS Mojave (10.14.2) 系统，其他比较新的 Mac 系统应该也类似。 brew install rust命令行： 1$ brew install rust 会安装下载已经编译好的二进制文件，总共大几百兆，安装成功后测试下： 1$ rustc --version 和 1$ cargo --version Hello World创建 hello.rs 文件，内容如下： hello.rs 123456789// This is a comment// hello.rs// main functionfn main() &#123; // Print text to the console println!(\"Hello World!\");&#125; 命令行 rustc 将 hello.rs 编译为可自行文件： 1$ rustc hello.rs 接下来运行可执行文件： 12$ ./helloHello World! Linux 开发环境（Ubuntu 18）说明本文演示在 Ubuntu 18 下安装 Rust，其他 Ubuntu 版本或者其他 Linux 发行操作类似。 开始之前，请确保系统中已经安装了 curl 命令行工具。 开始安装1$ curl https://sh.rustup.rs -sSf | sh 会输出： 请选择 1，然按 Enter 键： 配置执行路径安装工具会自动在 ~/.profile 里加入 ~/.cargo/bin 的 PATH 设置，类似以下： 如果你的文件没有自动加上 PATH 设置，你可以尝试手动加上。 ~/.cargo/bin 目录存储着 Rust 的命令工具： 为了使上面的配置生效，我们需要： 1$ source ~/.profile 测试下1$ rustc --version 和 1$ cargo --version 输出： Hello World创建 hello.rs 文件，内容如下： hello.rs 123456789// This is a comment// hello.rs// main functionfn main() &#123; // Print text to the console println!(\"Hello World!\");&#125; 命令行 rustc 将 hello.rs 编译为可自行文件： 1$ rustc hello.rs 接下来运行可执行文件： 12$ ./helloHello World! 输出示例：","categories":[{"name":"Rust","slug":"Rust","permalink":"https://chengtong.me/categories/Rust/"}],"tags":[]},{"title":"CentOS7添加开机启动服务或脚本","slug":"CentOS7添加开机启动服务或脚本","date":"2018-12-19T00:53:00.000Z","updated":"2020-06-01T07:55:36.910Z","comments":true,"path":"posts/85a085d9.html","link":"","permalink":"https://chengtong.me/posts/85a085d9.html","excerpt":"","text":"方法一(rc.local) 由于在centos7中/etc/rc.d/rc.local的权限被降低了，所以需要赋予其可执行权 1chmod +x /etc/rc.d/rc.local 赋予脚本可执行权限假设/opt/script/autostart.sh是你的脚本路径，给予执行权限 1chmod +x /opt/script/autostart.sh 打开 1/etc/rc.d/rc/local 文件，在末尾增加如下内容 1/opt/script/autostart.sh 方法二(chkconfig)说明/etc/init.d是/etc/rc.d/init.d的软链接，可以通过ll命令查看。当Linux启动时，会寻找这些目录中的服务脚本，并根据脚本的运行级别确定不同的启动级别。 教程 将脚本移动到 1/etc/rc.d/init.d 目录下 1mv /opt/script/autostart.sh /etc/rc.d/init.d 增加脚本的可执行权限 1chmod +x /etc/rc.d/init.d/autostart.sh 添加脚本到开机自动启动项目中 123cd /etc/rc.d/init.dchkconfig --add autostart.shchkconfig autostart.sh on 关于chkconfig及liunx运行级别 chkconfig启动脚本规范 在脚本开头加入下面内容： 123#!/bin/bash# chkconfig: 2345 90 10# description: myservice 说明：chkonfig后面是启动级别和优先级，description后面是服务描述。如上面脚本意思是，服务必须在运行级2，3，4，5下被启动或关闭，启动的优先级是90，停止的优先级是10。 优先级范围是0－100，数字越大，优先级越低。 注意：不添加以上内容的话添加启动项时会提示service myservice does not support chkconfig。 Linux启动优先级运行级别就是操作系统当前正在运行的功能级别。这个级别从0到6 ，具有不同的功能。这些级别在/etc/inittab文件里指定。这个文件是init程序寻找的主要文件，最先运行的服务是那些放在/etc/rc.d 目录下的文件。不同的运行级定义如下：(可以参考Linux里面的/etc/inittab) 1234567891011121314151617# 缺省的运行级，RHS用到的级别如下：0：关机1：单用户模式2：无网络支持的多用户模式3：有网络支持的多用户模式4：保留，未使用5：有网络支持有X-Window支持的多用户模式6：重新引导系统，即重启# 对各个运行级的详细解释：0 为停机，机器关闭。1 为单用户模式，就像Win9x下的安全模式类似。2 为多用户模式，但是没有NFS支持。 3 为完整的多用户模式，是标准的运行级。4 一般不用，在一些特殊情况下可以用它来做一些事情。例如在笔记本 电脑的电池用尽时，可以切换到这个模式来做一些设置。5 就是X11，进到X Window系统了。6 为重启，运行init 6机器就会重启。 方法三(systemd)可以通过systemd添加自定义服务启动，具体步骤这里不再赘述。","categories":[{"name":"Linux","slug":"Linux","permalink":"https://chengtong.me/categories/Linux/"}],"tags":[{"name":"CentOS","slug":"CentOS","permalink":"https://chengtong.me/tags/CentOS/"}]},{"title":"springboot2.x整合spring-data-jpa的问题","slug":"springboot2-x整合spring-data-jpa的问题","date":"2018-12-06T05:28:00.000Z","updated":"2020-05-22T02:03:24.978Z","comments":true,"path":"posts/ff34caee.html","link":"","permalink":"https://chengtong.me/posts/ff34caee.html","excerpt":"","text":"今天使用springboot整合spring-data-jpa遇到一些问题，直接使用JpaRepository的getOne()方法是会报错的。报错信息为：org.hibernate.LazyInitializationException: could not initialize proxy - no Session。在SpringBoot1.xx版本应该使用findOne()方法根据主键来查找对象。 这里是findOne和getOne的区别getOne API：返回对具有给定标识符的实体的引用。当我查询一个不存在的id数据时，直接抛出异常，因为它返回的是一个引用，简单点说就是一个代理对象。 findOne API：按ID查找实体。当我查询一个不存在的id数据时，返回的值是null. 详细对比参考这里。 但是新版本的JPA中，已经不存在用ID查找实体的findOne方法了，取而代之的是：findById().get()方法。 spring配置如下1234567891011121314spring: datasource: username: root password: 123456 url: jdbc:mysql://127.0.0.1:3306/jpa?useUnicode=true&amp;characterEncoding=UTF8 driver-class-name: com.mysql.cj.jdbc.Driver jpa: hibernate: #更新数据表结构 ddl-auto: update show-sql: true open-in-view: true 实体类123456789101112131415161718192021222324252627282930313233343536373839package com.wang.springboot06jap.entity;import javax.persistence.*;//使用JPA注解配置映射关系@Entity@Table(name = \"tbl_user\") //配置表名，若省略则默认表名是userpublic class User &#123; @Id @GeneratedValue(strategy = GenerationType.IDENTITY) //自增主键 private Integer id; @Column(name = \"lastName\",length = 20) //若省略就是属性名 private String username; private String email; public Integer getId() &#123; return id; &#125; public void setId(Integer id) &#123; this.id = id; &#125; public String getUsername() &#123; return username; &#125; public void setUsername(String username) &#123; this.username = username; &#125; public String getEmail() &#123; return email; &#125; public void setEmail(String email) &#123; this.email = email; &#125;&#125; Reposity123public interface UserRepository extends JpaRepository&lt;User,Integer&gt; &#123;&#125; 调用JPAReposity的方法123456789101112131415@Controllerpublic class UserController &#123; @Autowired UserRepository userRepository; @GetMapping(\"/user/&#123;id&#125;\") @ResponseBody public User getUser(@PathVariable(\"id\") Integer id)&#123; User user = userRepository.findById(id).get(); // System.out.println(userRepository.getOne(id)); // return user; &#125;&#125;","categories":[],"tags":[]},{"title":"Https之postman请求失败","slug":"Https之postman请求失败","date":"2018-12-04T07:42:07.000Z","updated":"2020-05-23T12:43:24.172Z","comments":true,"path":"posts/7774b55a.html","link":"","permalink":"https://chengtong.me/posts/7774b55a.html","excerpt":"","text":"今天用postman访问https的时候遇到这个 后来查了一下，果然，postman有暗门！ 关掉该选项，就可以了！","categories":[],"tags":[]},{"title":"Spring data Jpa自动更新实体创建时间和修改时间","slug":"Spring data Jpa自动更新实体创建时间和修改时间","date":"2018-12-01T10:30:21.000Z","updated":"2020-05-23T12:43:23.995Z","comments":true,"path":"posts/f78c14dc.html","link":"","permalink":"https://chengtong.me/posts/f78c14dc.html","excerpt":"","text":"1.实体类加注解 1234567891011121314/** * 创建时间 */@CreatedDate@Column(name = \"create_time\")private Date createTime;/** * 修改时间 */@LastModifiedDate@Column(name = \"modify_time\")private Date modifyTime;12345678910111213 2.实体类头加注解 1@EntityListeners(AuditingEntityListener.class) 3.SpringBoot启动类加注解 1@EnableJpaAuditing 另外数据库添加相应控制也可以：createTime ： CURRENT_TIMESTAMPmodifyTime ： CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP","categories":[],"tags":[]},{"title":"创建时间和修改时间(更新时间)","slug":"创建时间和修改时间(更新时间)","date":"2018-12-01T05:30:21.000Z","updated":"2020-12-11T08:55:35.283Z","comments":true,"path":"posts/c398b326.html","link":"","permalink":"https://chengtong.me/posts/c398b326.html","excerpt":"","text":"123ALTER TABLE xxx ADD created_time TIMESTAMP NULL DEFAULT CURRENT_TIMESTAMP COMMENT &apos;创建时间&apos;;ALTER TABLE xxx ADD modified_time TIMESTAMP NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT &apos;更新时间&apos;; 而在界面的mysql工具里,创建时间仅设置为:而修改时间(更新时间)需要设置为: 实体类： 1234567891011/** * 创建时间 */@Transientprivate Date createdTime = new Date();/** * 修改时间 */@Transientprivate Date modifiedTime; JPA如下： 123456789101112131415@ApiModelProperty(\"创建日期\")@Column(name = \"gmt_create\", updatable = false)@CreatedDate@Temporal(TemporalType.TIMESTAMP)@DateTimeFormat(pattern = \"yyyy-MM-dd HH:mm:ss\")@JsonFormat(pattern = \"yyyy-MM-dd HH:mm:ss\", timezone = \"GMT+8\")protected Date createdDate;@ApiModelProperty(\"最后修改日期\")@Column(name = \"gmt_modified\")@LastModifiedDate@Temporal(TemporalType.TIMESTAMP)@DateTimeFormat(pattern = \"yyyy-MM-dd HH:mm:ss\")@JsonFormat(pattern = \"yyyy-MM-dd HH:mm:ss\", timezone = \"GMT+8\")protected Date lastModifiedDate;","categories":[{"name":"数据库","slug":"数据库","permalink":"https://chengtong.me/categories/数据库/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://chengtong.me/tags/MySQL/"}]},{"title":"Git修改已提交的commit注释","slug":"Git修改已提交的commit注释","date":"2018-10-30T09:47:19.000Z","updated":"2020-05-23T12:43:24.113Z","comments":true,"path":"posts/61334b74.html","link":"","permalink":"https://chengtong.me/posts/61334b74.html","excerpt":"","text":"两种情况： 1.已经将代码push到远程仓库 2.还没将代码push到远程仓库，还在本地的仓库中 这两种情况下的修改大体相同，只是第一种情况最后会多一步 下面来说怎么修改 先搞清楚你要修改哪次的提交注释或者哪几次的提交注释 修改最后一次注释如果你只想修改最后一次注释（就是最新的一次提交），那好办： git commit --amend 出现有注释的界面（你的注释应该显示在第一行）， 输入i进入修改模式，修改好注释后，按Esc键 退出编辑模式，输入:wq保存并退出。ok，修改完成。 例如修改时编辑界面的图： 编辑commit注释.png 修改之前的注释修改之前的某次注释 输入： git rebase -i HEAD~2 最后的数字2指的是显示到倒数第几次 比如这个输入的2就会显示倒数的两次注释（最上面两行） 显示倒数两次的commit注释.png 你想修改哪条注释 就把哪条注释前面的pick换成edit。方法就是上面说的编辑方式：i—编辑，把pick换成edit—Esc—:wq. 然后：（接下来的步骤Terminal会提示） git commit --amend 修改注释，保存并退出后，输入： git rebase --continue 提示输入的命令.png 其实这个原理我的理解就是先版本回退到你想修改的某次版本，然后修改当前的commit注释，然后再回到本地最新的版本 修改之前的某几次注释修改多次的注释其实步骤和上面的一样，不同点在于： 同上 你可以将多个想修改的commit注释前面的pick换成edit 依次修改你的注释（顺序是从旧到新），Terminal基本都会提示你接下来的操作，每修改一个注释都要重复上面的3和4步，直到修改完你所选择的所有注释 已经将代码push到远程仓库首先，你把最新的版本从远程仓库先pull下来，修改的方法都如上，最后修改完成后，强制push到远程仓库： git push --force origin master 注：很重要的一点是，你最好保证在你强制push之前没有人提交代码，如果在你push之前有人提交了新的代码到远程仓库，然后你又强制push，那么会被你的强制更新覆盖！！！ 最后，可以检查一下远程的提交记录~~","categories":[{"name":"源代码版本管理工具","slug":"源代码版本管理工具","permalink":"https://chengtong.me/categories/源代码版本管理工具/"}],"tags":[{"name":"Git","slug":"Git","permalink":"https://chengtong.me/tags/Git/"}]},{"title":"什么是产品的痛点、爽点、痒点","slug":"什么是产品的痛点、爽点、痒点","date":"2018-10-14T15:11:48.000Z","updated":"2020-05-23T12:43:24.046Z","comments":true,"path":"posts/7a45e1a3.html","link":"","permalink":"https://chengtong.me/posts/7a45e1a3.html","excerpt":"","text":"1，什么叫“痛点”？“对于产品来说，痛点多是指尚未被满足的、而又被广泛渴望的需求。”这是搜索给的答案。 而梁宁老师认为：没有被满足，用户只是难受而已，不能拿用户的难受当痛点。 为什么？ 比如你第一次拜访岳父岳母，肩上都是头皮屑，让老人一脸嫌弃；面试的时候衣服上都是白点，让面试官皱眉头……这些都是很痛的事情。 我们看看海飞丝的广告词： 1，头屑去无踪，秀发更出众。 2，去头屑，让你靠的更近。 所以梁宁老师认为：痛点是恐惧。 2，那么爽点是什么呢？人在满足时的状态叫愉悦，人不被满足就会难受，就会开始寻求。如果这个人在寻求中，能立刻得到即时满足，这种感觉就是爽。 所以这就解释了吃鸡这款游戏，从年初的时候就开始这么火爆的原因。 你吃鸡成功了，就满足了你仿佛“天下第一”的成就感，你当然就愉悦了，你要是落地成盒了，当然不爽，那怎么办？当然是从开一局。而如果你恰是那个让别人落地成盒的那个人，当然爽的不要不要的，继续，不要停。 再比如说，你饿了，你在美团上下单，吃的就送到你家来了。你迷路了，需要导航，高德地图一直都在。还可以有林志玲或者郭德纲两种声音可选。你喝醉了，用滴滴代驾。 有需求，还能被即时满足，这就是爽。 3，痒点是满足虚拟自我前段时间“企鹅大战野猪林”，不外呼流量之争，可对于互联网公司来说，流量就是他们的生命。是生死存亡“必争之地”。 你看抖音推什么火什么，各种网红产品层出不穷。比如网红奶茶、网红酸奶、网红曲奇、网红洗发水，它们的爆红是靠抓住痛点吗？ 显然不是，网红产品们靠的是痒点。 什么是痒点？ 痒点是什么？梁宁老师说，痒点满足的是人的虚拟自我。 什么是虚拟自我？就是想象中那个理想的自己。 比如，我们看偶像剧，追明星八卦，看网文，… 这就是为什么我们这么喜欢看手机的原因，因为手机里有“另外一个我”啊。 这就是一种虚拟自我的实现。 这是看产品的“痛点，爽点，痒点”，其实好像我们接触一个人也是。只要研究一个人的“痛点，爽点，痒点”，卖产品，卖想法都是可以的。","categories":[],"tags":[]},{"title":"关于SpringJpa中getOne方法遇到延迟加载报错no Session的问题","slug":"关于SpringJpa中getOne方法遇到延迟加载报错no-Session的问题","date":"2018-10-11T02:02:00.000Z","updated":"2020-05-22T02:03:24.983Z","comments":true,"path":"posts/c1ba8626.html","link":"","permalink":"https://chengtong.me/posts/c1ba8626.html","excerpt":"","text":"报错如下：123org.hibernate.LazyInitializationException: could not initialize proxy - no Session... 看到报错信息推测如下：遇到延迟加载，session关闭了，导致不能得到有效信息。网上搜集了下资料，有关解释说，T getOne(ID id)依赖于EntityManager.getReference()执行实体延迟加载。https://stackoverflow.com/questions/24482117/when-use-getone-and-findone-methods-spring-data-jpa因为本人英文水平有限，所以用翻译软件，翻译其中一段：1234567891011121314151617181920212223242526272829虽然T getOne(ID id)javadoc声明（重点是我的）：返回对具有给定标识符的实体的引用。实际上，参考术语实际上是板，而JPA API没有指定任何getOne()方法。因此，了解Spring包装器的作用最好的方法是查看实现：@Overridepublic T getOne(ID id) &#123; Assert.notNull(id, ID_MUST_NOT_BE_NULL); return em.getReference(getDomainClass(), id);&#125;这em.getReference()是一个EntityManager声明为的方法：public &lt;T&gt; T getReference(Class&lt;T&gt; entityClass, Object primaryKey);幸运的是，EntityManagerjavadoc更好地定义了它的意图（重点是我的）：获取一个实例，其状态可能会被懒惰地取出。如果数据库中不存在请求的实例，则在首次访问实例状态时将引发EntityNotFoundException 。（在调用getReference时，允许持久性提供程序运行时抛出EntityNotFoundException。）除非在实体管理器打开时应用程序访问实例状态，否则应用程序不应期望实例状态在分离时可用。因此，调用getOne()可能会返回一个延迟获取的实体。这里，延迟提取不是指实体的关系，而是指实体本身。这意味着如果我们调用getOne()然后关闭Persistence上下文，则实体可能永远不会被加载，因此结果实际上是不可预测的。例如，如果代理对象是序列化的，则可以将null引用作为序列化结果获取，或者如果在代理对象上调用方法，LazyInitializationException则会引发异常，例如抛出。因此，在这种情况下，抛出EntityNotFoundException这是getOne()用于处理数据库中不存在的实例的主要原因，因为在实体不存在时可能永远不会执行错误情况。在任何情况下，为确保其加载，您必须在会话打开时操纵实体。您可以通过调用实体上的任何方法来完成此操作。或者更好的替代用途findById(ID id)而不是。 哈哈哈，有点乱，感兴趣的还是参考上面原文链接吧。 有关于对getOne和findOne区别的说明12getOne API：返回对具有给定标识符的实体的引用。当我查询一个不存在的id数据时，直接抛出异常，因为它返回的是一个引用，简单点说就是一个代理对象。findOne API：按ID查找实体。当我查询一个不存在的id数据时，返回的值是null. 但是新版本的JPA中，已经不存在用ID查找实体的findOne方法了，取而代之的是：**findById().get()**方法。而解决方法中，有一种是说在application.properites中加上如下配置：1spring.jpa.properties.hibernate.enable_lazy_load_no_trans=true 但是 我试了下没有效果~~，不知哪里出了问题。所有还是采用**findById().get()**来代替吧。","categories":[],"tags":[]},{"title":"Java中List,Set,数组的互相转换","slug":"Java中List,Set,数组的互相转换","date":"2018-09-18T06:23:01.000Z","updated":"2020-05-23T12:43:23.986Z","comments":true,"path":"posts/7e91ff56.html","link":"","permalink":"https://chengtong.me/posts/7e91ff56.html","excerpt":"","text":"1. List转数组 通过toArray()推荐 123456789public static void main(String[] args) &#123; //1. 通过 toArray() List&lt;String&gt; list = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; 10; i++) &#123; list.add(\"value\" + i); &#125; String[] arrays = list.toArray(new String[0]); System.out.println(Arrays.toString(arrays));&#125; jdk1.8 stream 123456789public static void main(String[] args) &#123; //2. jdk1.8 stream List&lt;String&gt; list = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; 10; i++) &#123; list.add(\"value\" + i); &#125; String[] arrays = list.stream().toArray(String[]::new); System.out.println(Arrays.toString(arrays));&#125; 2.数组转List Arrays.asList() 123456789public static void main(String[] args) &#123; /* * 此种方法生成的List不可进行add和remove操作 * 因为它是一个定长的List集合，跟数组长度一致 */ String[] array = new String[]&#123;\"value1\", \"value2\", \"value3\"&#125;; List&lt;String&gt; stringList = Arrays.asList(array); System.out.println(stringList.toString());&#125; 通过Collections.addAll(list, arrays) 1234567public static void main(String[] args) &#123; //2.通过Collections.addAll(list, arrays); List&lt;String&gt; stringList=new ArrayList&lt;&gt;(); String[] array=new String[]&#123;\"value1\",\"value2\",\"value3\"&#125;; Collections.addAll(stringList, array); System.out.println(stringList.toString());&#125; jdk1.8 通过Stream 12345678public static void main(String[] args) &#123; //3. jdk1.8 通过Stream String[] arrays = new String[]&#123;\"value1\", \"value2\", \"value3\"&#125;; List&lt;String&gt; listStrings = Stream .of(arrays) .collect(Collectors.toList()); System.out.println(listStrings.toString());&#125; 3. Set转数组 通过 toArray() 123456789private static void setToArray1() &#123; Set&lt;String&gt; set = new HashSet&lt;&gt;(); set.add(\"value1\"); set.add(\"value2\"); set.add(\"value3\"); //Set--&gt;数组 String[] array=set.toArray(new String[0]); System.out.println(Arrays.toString(array));&#125; 通过Stream jdk1.8 123456789private static void setToArray2() &#123; Set&lt;String&gt; set = new HashSet&lt;&gt;(); set.add(\"value1\"); set.add(\"value2\"); set.add(\"value3\"); //Set--&gt;数组 String[] array= set.stream().toArray(String[]::new); System.out.println(Arrays.toString(array));&#125; 4. 数组转Set-通过先转List之后引入Set 123456//数组--&gt;Set private static void arrayToSet() &#123; String[] array = &#123;\"value1\",\"value2\",\"value3\"&#125;; Set&lt;String&gt; set = new HashSet&lt;&gt;(Arrays.asList(array)); System.out.println(set); &#125; jdk1.8之后通过Stream 12345private static void arrayToSet2() &#123; String[] array = &#123;\"value1\",\"value2\",\"value3\"&#125;; Set&lt;String&gt; set = Stream.of(array).collect(Collectors.toSet()); System.out.println(set);&#125; 5. Set转List 普遍使用 12345678910//set为null会报错private static void setToList() &#123; Set&lt;String&gt; set = new HashSet&lt;&gt;(); set.add(\"value1\"); set.add(\"value2\"); set.add(\"value3\"); set=null; List&lt;String&gt; list=new ArrayList&lt;&gt;(set); System.out.println(list.toString());&#125; jdk1.8通过Stream 123456789//效率低不推荐private static void setToList2() &#123; Set&lt;String&gt; set = new HashSet&lt;&gt;(); set.add(\"value1\"); set.add(\"value2\"); set.add(\"value3\"); List list=Stream.of(set.toArray(new String[0])).collect(Collectors.toList()); System.out.println(list.toString());&#125; 6. List转Set123456789//list为null会报错private static void listToSet() &#123; List&lt;String&gt; list = new ArrayList&lt;&gt;(); list.add(\"value1\"); list.add(\"value2\"); list.add(\"value3\"); Set&lt;String&gt; set=new HashSet&lt;&gt;(list); System.out.println(set.toString());&#125;","categories":[],"tags":[]},{"title":"TS型网页视频下载方法","slug":"TS型网页视频下载方法","date":"2018-09-14T02:19:00.000Z","updated":"2020-08-21T04:41:23.211Z","comments":true,"path":"posts/102d67a.html","link":"","permalink":"https://chengtong.me/posts/102d67a.html","excerpt":"","text":"首先使用Chrome打开网页，单击F12打开开发者工具 开始视频播放，在F12出来的界面中单击Network 在Network中有文件列表，检查当中是否存在m3u8结尾的文件 如果有m3u8结尾的文件，把它的源地址复制下来 源地址复制下来可能分两段（两个http），一段是跳转地址，一段是目标地址，将目标地址保留下来即可。 正确的m3u8文件地址大概的样子在下面的命令示例中 使用以下命令一键下载并自动合成、转码为mp4 1ffmpeg -i http://xxx.com:8891/1231/index.m3u8 -c copy -bsf:a aac_adtstoasc output.mp4 注意事项必须安装ffmpeg，Linux、Mac可以使用常规方法安装，Windows直接去官网下载二进制包直接用、当网页中播放的视频流是ts格式的时候，本方法适用。","categories":[],"tags":[{"name":"FFmpeg","slug":"FFmpeg","permalink":"https://chengtong.me/tags/FFmpeg/"}]},{"title":"springboot部署测试环境和生产环境","slug":"springboot部署测试环境和生产环境","date":"2018-09-08T16:00:01.000Z","updated":"2021-06-08T02:20:46.557Z","comments":true,"path":"posts/5f9b9ec2.html","link":"","permalink":"https://chengtong.me/posts/5f9b9ec2.html","excerpt":"","text":"我们在日常开发工作经常会根据不同的项目运行环境，添加不同的配置文件，例如: 开发环境，测试环境，生产环境等。 配置springboot的application.properties或aoolication.yml配置文件的spring.profiles.active属性 开发环境 IDEA Maven 配置文件由于springboot会默认加载application配置文件，所以我们需要在application修改配置参数。 以下为application.yml文件格式 123spring profiles active: dev 这段配置代码的意思是，spingboot会加载项目中的名字为application-dev的配置文件。 所以如果需要在打包时打包生产环境的包，那么创建一个名为application-prod.yml的配置文件，然后修改application.yml如下： 123spring profiles active: prod 这样就可以区分打包生产环境和测试环境了 Maven由于每次打包都需要手动修改application配置文件，会很麻烦并且不安全，并且大多数项目都是使用maven,所以集成maven可以使我们方便很多。 先配置pom.xml: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152 &lt;!-- 多环境配置方案 --&gt; &lt;profiles&gt; &lt;!-- 本地开发 --&gt; &lt;profile&gt; &lt;id&gt;local&lt;/id&gt; &lt;properties&gt; &lt;profiles.active&gt;local&lt;/profiles.active&gt; &lt;/properties&gt; &lt;!-- 是否默认 true表示默认--&gt; &lt;activation&gt; &lt;activeByDefault&gt;true&lt;/activeByDefault&gt; &lt;/activation&gt; &lt;/profile&gt; &lt;!-- 开发环境 打包命令mvn clean package -Pdev或mvn clean package -D profiles.active=dev --&gt; &lt;profile&gt; &lt;id&gt;dev&lt;/id&gt; &lt;properties&gt; &lt;profiles.active&gt;dev&lt;/profiles.active&gt; &lt;/properties&gt; &lt;/profile&gt; &lt;!-- 测试环境 打包命令mvn clean package -Ptest --&gt; &lt;profile&gt; &lt;id&gt;test&lt;/id&gt; &lt;properties&gt; &lt;profiles.active&gt;test&lt;/profiles.active&gt; &lt;/properties&gt; &lt;/profile&gt; &lt;!-- 生产环境 打包命令mvn clean package -Pprod --&gt; &lt;profile&gt; &lt;id&gt;prod&lt;/id&gt; &lt;properties&gt; &lt;profiles.active&gt;prod&lt;/profiles.active&gt; &lt;/properties&gt; &lt;/profile&gt; &lt;/profiles&gt;&lt;build&gt; &lt;finalName&gt;$&#123;project.artifactId&#125;-$&#123;project.version&#125;&lt;/finalName&gt; &lt;resources&gt; &lt;!--需要动态添加的资源--&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;!-- 开启过滤替换功能--&gt; &lt;filtering&gt;true&lt;/filtering&gt; &lt;includes&gt; &lt;!-- 项目打包完成的包中只包含当前环境文件 --&gt; &lt;include&gt;application.yml&lt;/include&gt; &lt;include&gt;application-$&#123;profiles.active&#125;.yml&lt;/include&gt; &lt;/includes&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;/build&gt; 对这段代码做下说明，首先在maven中配置了多个环境的配置文件，根据需求配置即可； 其中 &lt;profiles.active&gt;&lt;/profiles.active&gt;是变量的key,test是变量的value 接下来在application中引用该变量 123spring profiles active: @profiles.active@ &lt;!-- 这里引用的是pom.xml中配置的key --&gt; 打包 命令行以下两种maven参数都可以 -P 参数激活相应的profile。对应pom.xml中 profiles-&gt;profile-&gt;id -D 指定maven属性 123456&lt;!--本地开发 --&gt;mvn clean package &lt;!--测试环境 --&gt;mvn clean package -D profiles.active=test&lt;!--生产环境--&gt;mvn clean package -Pprod IDEA MAVEN插件通过idea右侧maven窗口勾选相应的Profiles,再package即可 高级不同环境的日志级别及其他配置也不一样，所以使用文件夹进行区分 1234567891011121314151617181920212223&lt;build&gt; &lt;finalName&gt;$&#123;project.artifactId&#125;-$&#123;project.version&#125;&lt;/finalName&gt; &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;excludes&gt; &lt;exclude&gt;env/local/*&lt;/exclude&gt; &lt;exclude&gt;env/dev/*&lt;/exclude&gt; &lt;exclude&gt;env/test/*&lt;/exclude&gt; &lt;exclude&gt;env/prod/*&lt;/exclude&gt; &lt;/excludes&gt; &lt;filtering&gt;true&lt;/filtering&gt; &lt;/resource&gt; &lt;!--需要动态添加的资源--&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources/env/$&#123;profiles.active&#125;&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;*.*&lt;/include&gt; &lt;/includes&gt; &lt;filtering&gt;true&lt;/filtering&gt; &lt;/resource&gt; &lt;/resources&gt;&lt;/build&gt; 问题1.==‘@’ that cannot start any token. (Do not use @ for indentation) 在本地启动该项目时有时候会报如下错误 123found character &apos;@&apos; that cannot start any token. (Do not use @ for indentation) in &apos;reader&apos;, line 4, column 11: name: @profiles.active@ 意思是识别不了@profiles.active@这个变量，这是因为这个变量没有被替换成我们需要的参数，如test,prod等，所以在本地启动时要加上参数启动，这样springboot会自动替换掉这个变量。 作者使用的是idea，所以启动springboot时在右上Edit Configurations–&gt;Active Profiles 增加一个参数，参数值为你需要运行的环境名称，如test","categories":[{"name":"JAVA","slug":"JAVA","permalink":"https://chengtong.me/categories/JAVA/"}],"tags":[{"name":"Spring Boot","slug":"Spring-Boot","permalink":"https://chengtong.me/tags/Spring-Boot/"}]},{"title":"Git远程仓库地址变更本地如何修改","slug":"Git远程仓库地址变更本地如何修改","date":"2018-09-08T16:00:01.000Z","updated":"2020-05-23T12:43:23.972Z","comments":true,"path":"posts/74d2c17b.html","link":"","permalink":"https://chengtong.me/posts/74d2c17b.html","excerpt":"","text":"公司搬移， 作为git仓库的服务器IP地址变了。 本地代码挺多，重新检出太占时间，可以修改一个什么配置让我本地仓库和新的远程仓库建立关联吗， 答案是肯定的！ 方法有很多，这里简单介绍几种：以下均以项目git_test为例： 老地址：http://192.168.1.12:9797/john/git_test.git新地址：http://192.168.100.235:9797/john/git_test.git远程仓库名称： origin 方法一 通过命令直接修改远程地址 进入git_test根目录 git remote 查看所有远程仓库， git remote xxx 查看指定远程仓库地址 git remote set-url origin http://192.168.100.235:9797/john/git_test.git 方法二 通过命令先删除再添加远程仓库 进入git_test根目录 git remote 查看所有远程仓库， git remote xxx 查看指定远程仓库地址 git remote rm origin git remote add origin http://192.168.100.235:9797/john/git_test.git 方法三 直接修改配置文件 进入git_test/.git vim config [core] repositoryformatversion = 0 filemode = true logallrefupdates = true precomposeunicode = true[remote “origin”] url = http://192.168.100.235:9797/shimanqiang/assistant.git fetch = +refs/heads/:refs/remotes/origin/[branch “master”] remote = origin merge = refs/heads/master 修改[remote “origin”]下面的url即可 方法四 通过第三方git客户端修改。以SourceTree为例，点击 仓库 -&gt; 仓库配置 -&gt; 远程仓库 即可管理此项目中配置的所有远程仓库， 而且这个界面最下方还可以点击编辑配置文件，同样可以完成方法三。","categories":[{"name":"源代码版本管理工具","slug":"源代码版本管理工具","permalink":"https://chengtong.me/categories/源代码版本管理工具/"}],"tags":[{"name":"Git","slug":"Git","permalink":"https://chengtong.me/tags/Git/"}]},{"title":"Docker配置私有仓库","slug":"Docker配置私有仓库","date":"2018-09-08T16:00:01.000Z","updated":"2021-06-02T02:46:27.885Z","comments":true,"path":"posts/c4bccc0e.html","link":"","permalink":"https://chengtong.me/posts/c4bccc0e.html","excerpt":"","text":"Mac系统配置DockerMac系统中配置Docker的Preferences -&gt; Daemon，Insecure registies中添加192.168.1.112，即：Harbor私服的ip地址，如下： 2.1.2 登录私有仓库进行验证1docker login 192.168.1.112 Window系统配置Docker Apply即可 3 Linux系统3.1.1 配置Docker在/etc/docker新建daemon.json文件: 12mkdir -p /etc/docker #新建docker目录vim /etc/docker/daemon.json #新建daemon.json文件 编辑内容如下: 1&#123; &quot;insecure-registries&quot;:[&quot;192.168.1.112&quot;] &#125; 重启docker 1systemctl restart docker 3.1.2 登录私有仓库进行验证1docker login 192.168.1.112","categories":[{"name":"容器","slug":"容器","permalink":"https://chengtong.me/categories/容器/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://chengtong.me/tags/Docker/"}]},{"title":"Windows10自动更新无法关闭的解决方法","slug":"Windows10自动更新无法关闭的解决方法","date":"2018-09-08T16:00:01.000Z","updated":"2020-05-23T12:43:24.259Z","comments":true,"path":"posts/1c4fca.html","link":"","permalink":"https://chengtong.me/posts/1c4fca.html","excerpt":"","text":"最近Windows10系统出现了令人头疼的问题，系统自动更新无法关闭，伴随而来的是大量的新版bug，严重影响用户体验，下面就教大家如何真正关闭Windows update 工具/原料 Windows10 方法一：关闭Windows update服务 我们右击【任务栏】空白处，在右键中选择【任务管理器】 在【任务管理器】界面，选择【服务】选项卡，然后选择下面的【打开服务】 这里顺便说一种打开【服务】的快捷方法，大家以后用来打开别的应用也是很方便的。操作方法如下： ​ 点击任务栏的小娜图标，在弹出页面下面的搜索框输入要搜索的内容，如：服务，直接就可以找到【服务】这一桌面应用，点击就可以打开服务窗口 在打开的【服务】窗口，我们找到服务“Windows update”，发现它可耻的“正在运行”，并且启动类型还是“手动”，我们右击“Windows update”，选择【属性】 在打开的【Windows update的属性】窗口的【常规】选项卡，我们将【启动类型】改为【禁用】，然后单击下面的【停止】按钮。以前这样就可以停止更新程序，但是现在还需要一步 6. 选择【恢复】选项卡，将【第一次失败】改为【无操作】，点击【确定】，这样关闭更新后就不会自动启动了 方法二：组策略禁用更新 快捷键“win+r”打开【运行】，在运行文本框输入‘gpedit.msc’后点击【确定】或者回车 在打开的【本地组策略编辑器】界面左侧定位到：计算机配置&gt;管理模板&gt;windows组件&gt;Windows更新，然后双击右侧的【配置自动更新】选项 在打开的【配置自动更新】窗口选择【已禁用】，点击【应用】后【确定】，退出就行了","categories":[{"name":"Windows","slug":"Windows","permalink":"https://chengtong.me/categories/Windows/"}],"tags":[{"name":"Windows10","slug":"Windows10","permalink":"https://chengtong.me/tags/Windows10/"}]},{"title":"git版本控制如何恢复误删除的本地文件","slug":"git版本控制如何恢复误删除的本地文件","date":"2018-09-06T03:51:48.000Z","updated":"2020-05-23T12:43:24.007Z","comments":true,"path":"posts/f82ccd38.html","link":"","permalink":"https://chengtong.me/posts/f82ccd38.html","excerpt":"","text":"使用git status查看，是否已删除 使用命令git reset HEAD 文件名 找回来此文件 最后使用git checkout 文件名，文件就重新找回来了！","categories":[{"name":"源代码版本管理工具","slug":"源代码版本管理工具","permalink":"https://chengtong.me/categories/源代码版本管理工具/"}],"tags":[{"name":"Git","slug":"Git","permalink":"https://chengtong.me/tags/Git/"}]},{"title":"Kudu设计原理初探","slug":"Kudu设计原理初探","date":"2018-08-26T15:00:00.000Z","updated":"2020-05-22T02:03:24.842Z","comments":true,"path":"posts/92eadbe.html","link":"","permalink":"https://chengtong.me/posts/92eadbe.html","excerpt":"","text":"如何在一个系统中融合OLTP型随机读写能力与OLAP型分析能力，Kudu提供了优秀的设计思路。本文主要从Kudu的设计论文着手，结合与HBase的对比分析，来初步揭示Kudu的设计原理，部分设计在最新的Kudu版本中可能已经过时，但最初的设计思想依然值得借鉴。 Kudu的设计初衷在介绍Kudu是什么之前，还是先简单的说一下现存系统针对结构化数据存储与查询的一些痛点问题，结构化数据的存储，通常包含如下两种方式： 静态数据通常以Parquet/Carbon/Avro形式直接存放在HDFS中，对于分析场景，这种存储通常是更加适合的。但无论以哪种方式存在于HDFS中，都难以支持单条记录级别的更新，随机读取也并不高效。 可变数据的存储通常选择HBase或者Cassandra，因为它们能够支持记录级别的高效随机读写。但这种存储却并不适合离线分析场景，因为它们在大批量数据获取时的性能较差（针对HBase而言，有两方面的主要原因：一是HFile本身的结构定义，它是按行组织数据的，这种格式针对大多数的分析场景，都会带来较大的IO消耗，因为可能会读取很多不必要的数据，相对而言Parquet格式针对分析场景就做了很多优化。 二是由于HBase本身的LSM-Tree架构决定的，HBase的读取路径中，不仅要考虑内存中的数据，同时要考虑HDFS中的一个或多个HFile，较之于直接从HDFS中读取文件而言，这种读取路径是过长的）。 可以看出，如上两种存储方式，都存在明显的优缺点： 直接存放于HDFS中，适合离线分析，却不利于记录级别的随机读写。 直接将数据存放于HBase/Cassandra中，适合记录级别的随机读写，对离线分析却不友好。但在很多实际业务场景中，两种场景时常是并存的。我们的通常做法有如下几种： 1. 数据存放于HBase中，对于分析任务，基于Spark/Hive On HBase进行，性能较差。2. 对于分析性能要求较高的，可以将数据在HDFS/Hive中多冗余存放一份，或者，将HBase中的数据定期的导出成Parquet/Carbon格式的数据。 明显这种方案对业务应用提出了较高的要求，而且容易导致在线数据与离线数据之间的一致性问题。Kudu的设计，就是试图在OLAP与OLTP之间，寻求一个最佳的结合点，从而在一个系统的一份数据中，既能支持OLTP型实时读写能力又能支持OLAP型分析。另外一个初衷，在Cloudera发布的《Kudu: New Apache Hadoop Storage for Fast Analytics on Fast Data》一文中有提及，Kudu作为一个新的分布式存储系统期望有效提升CPU的使用率，而低CPU使用率恰是HBase/Cassandra等系统的最大问题。下面的章节中，主要从论文所揭示的内容来解读Kudu的设计原理。 Kudu的原理介绍Kudu自身的架构，部分借鉴了Bigtable/HBase/Spanner的设计思想。论文的作者列表中，有几位是HBase社区的Committer/PBC成员，因此，在论文中也能很深刻的感受到HBase对Kudu设计的一些影响，因此，在本文的多个地方都有谈及Kudu与HBase在设计上的异同。 表与SchemaKudu设计是面向结构化存储的，因此，Kudu的表，需要用户在建表时定义它的Schema信息，这些Schema信息包含：列定义（含类型），Primary Key定义（用户指定的若干个列的有序组合）。数据的唯一性，依赖于用户所提供的Primary Key中的Column组合的值的唯一性。 Kudu提供了Alter命令来增删列，但位于Primary Key中的列是不允许删除的。Kudu当前并不支持二级索引。 APIKudu提供了Java/C++两种语言的API（尽管也提供了Python API，但尚处于Experimental阶段）。通过这些API，可以进行如下一些操作： 1. Insert/Update/Delete2. 批量数据导入/更新操作3. Scan(可支持简单的Filter) 事务与一致性模型Kudu仅仅提供单行事务，也不支持多行事务。这一点与HBase是相似的。但在数据一致性模型上，与HBase有较大的区别。 Kudu提供了如下两种一致性模型： 1. Snapshot Consistency这是Kudu中的默认一致性模型。在这种模型中，只保证一个客户端能够看到自己所提交的写操作，而并不保障全局的（跨多个客户端的）事务可见性。 2. External Consistency最早提出External Consistency机制的，应该是在Google的Spanner论文中。传统关系型数据库中的两阶段提交机制，需要两回合通信，这过程中带来的代价是较高的，但同时这过程中的复杂的锁机制也可能会带来一些可用性问题。一个更好的实现分布式事务/一致性的思路，是基于一个全局发布的Timestamp机制。Spanner提出了Commit-wait的机制，来保障全局事务的有序性：如果一个事务T1的提交先于另外一个事务T2的开始，则T1的Timestamp要小于T2的TimeStamp。我们知道，在分布式系统中，是很难于做这样的承诺的。在HBase中，我们可以想象，如果所有RegionServer中的SequenceID发布自同一个数据源，那么，HBase的很多事务性问题就迎刃而解了，然后最大的问题在于这个全局的SequenceID数据源将会是整个系统的性能瓶颈点。回到External Consistency机制，Spanner是依赖于高精度与可预见误差的本地时钟(TrueTime API)实现的(即需要一个高可靠和高精度的时钟源，同时，这个时钟的误差是可预见的。感兴趣的同学可以阅读Spanner论文，这里不赘述)。Kudu中提供了另外一种思路来实现External Consistency,基于Timestamp扩散机制，即，多个客户端可相互通信来告知彼此所提交的Timestamp值，从而保障一个全局的顺序。这种机制也是相对较为复杂的。与Spanner类似，Kudu不允许用户自定义用户数据的Timestamp，但在HBase中却是不同，用户可以发起一次基于某特定Timestamp的查询。 Kudu的架构Kudu也采用了Master-Slave形式的中心节点架构，管理节点被称作Kudu Master，数据节点被称作Tablet Server（可对比理解HBase中的RegionServer角色）。一个表的数据，被分割成1个或多个Tablet，Tablet被部署在Tablet Server来提供数据读写服务。Kudu Master在Kudu集群中，发挥如下的一些作用：1. 用来存放一些表的Schema信息，且负责处理建表等请求。2. 跟踪管理集群中的所有的Tablet Server，并且在Tablet Server异常之后协调数据的重部署。3. 存放Tablet到Tablet Server的部署信息。Tablet与HBase中的Region大致相似，但存在如下一些明显的区别点： 1. Tablet包含两种分区策略，一种是基于Hash Partition方式，在这种分区方式下用户数据可较均匀的分布在各个Tablet中，但原来的数据排序特点已被打乱。另外一种是基于Range Partition方式，数据将按照用户数据指定的有序的Primary Key Columns的组合String的顺序进行分区。而HBase中仅仅提供了一种按用户数据RowKey的Range Partition方式。2. 一个Tablet可以被部署到了多个Tablet Server中。在HBase最初的架构中，一个Region只能被部署在一个RegionServer中，它的数据多副本交由HDFS来保障。从1.0版本开始，HBase有了Region Replica（HBASE-10070）特性，该特性允许将一个Region部署在多个RegionServer中来提升读取的可用性，但多Region副本之间的数据却不是实时同步的。 Kudu的底层数据模型Kudu的底层数据文件的存储，未采用HDFS这样的较高抽象层次的分布式文件系统，而是自行开发了一套可基于Table/Tablet/Replica视图级别的底层存储系统。这套实现基于如下的几个设计目标： 可提供快速的列式查询。 可支持快速的随机更新 可提供更为稳定的查询性能保障。为了实现如上目标，Kudu参考了一种类似于Fractured Mirrors的混合列存储架构。Tablet在底层被进一步细分成了一个称之为RowSets的单元： MemRowSets可以对比理解成HBase中的MemStore, 而DiskRowSets可理解成HBase中的HFile。MemRowSets中的数据按照行试图进行存储，数据结构为B-Tree。MemRowSets中的数据被Flush到磁盘之后，形成DiskRowSets。 DisRowSets中的数据，按照32MB大小为单位，按序划分为一个个的DiskRowSet。DiskRowSet中的数据按照Column进行组织，与Parquet类似。这是Kudu可支持一些分析性查询的基础。每一个Column的数据被存储在一个相邻的数据区域，而这个数据区域进一步被细分成一个个的小的Page单元，与HBase File中的Block类似，对每一个Column Page可采用一些Encoding算法，以及一些通用的Compression算法。既然可对Column Page可采用Encoding以及Compression算法，那么，对单条记录的更改就会比较困难了。前面提到了Kudu可支持单条记录级别的更新/删除，是如何做到的？与HBase类似，也是通过增加一条新的记录来描述这次更新/删除操作的。一个DiskRowSet包含两部分数据：基础数据(Base Data)，以及变更数据(Delta Stores)。更新/删除操作所生成的数据记录，被保存在变更数据部分。 从上图（源自Kudu的源工程文件）来看，Delta数据部分应该包含REDO与UNDO两部分，这里的REDO与UNDO与关系型数据库中的REDO与UNDO日志类似（在关系型数据库中，REDO日志记录了更新后的数据，可以用来恢复尚未写入Data File的已成功事务更新的数据。 而UNDO日志用来记录事务更新之前的数据，可以用来在事务失败时进行回滚），但也存在一些细节上的差异： REDO Delta Files包含了Base Data自上一次被Flush/Compaction之后的变更值。REDO Delta Files按照Timestamp顺序排列。 UNDO Delta Files包含了Base Data自上一次Flush/Compaction之前的变更值。这样才可以保障基于一个旧Timestamp的查询能够看到一个一致性视图。UNDO按照Timestamp倒序排列。 数据读写流程写数据的流程，如下图所示： Kudu不允许用户数据的Primary Key重复，因此，在Tablet内部写入数据之前，需要先从已有的数据中检查当前新写入的数据的Primary Key是否已经存在，尽管在DiskRowSets中增加了BloomFilter来提升这种判断的效率，但可以预见，Kudu的这种设计将会明显增大写入的时延。数据一开始先存放于MemRowSets中，待大小超出一定的阈值之后，再Flush成DiskRowSets。这部分已经在图4中有详细的介绍。随着Flush次数的不断增加，生成的DiskRowSets也会不断的增多，在Kudu内部也存在一个Compaction流程，这样可以将已经存在的多个存在Primary Key交集的DiskRowSets重新排序而生成一个新的DiskRowSets。如下图所示：读数据的流程，既要考虑存在于内存中的MemRowSets,又要读取位于磁盘中的一个或多个DiskRowSets，在Scanner的高层抽象中，应该与HBase类似。如下重点提一些细节的优化点： 通过Scan的范围，与每一个DiskRowSets中的Primary Key Range进行对比，可以首先过滤掉一些不必要参与此次Scan的DiskRowSets。 Delta Store部分，针对记录级别的更改，记录了Base Data中对应原始数据的Offset。这样，在判断一条记录是否存在更改的记录时，将会更加的快速。 由于DiskRowSets的底层文件是按照列组织的，基于一些列的条件进行过滤查询时，可以优先过滤掉一些不必要的Primary Keys。Kudu并不会在一开始读取的时候就将一行数据的所有列读取出来，而是先读取与过滤条件相关的列，通过将这些列与查询条件匹配之后，再来决定是否去读取符合条件的行中的其它的列信息。这样可以节省一些磁盘IO。这就是Kudu所提供的Lazy Materialization特性。 Raft模型Kudu的多副本之间的数据共识协议采用了Raft协议，Raft是比Paxos更容易理解且更简单的一种一致性协议。关于Raft的更多信息，请参考：https://raft.github.io/ Kudu与HBase的区别这里再总结一下Kudu与HBase的一些大的区别点： Kudu的数据分区方式相对多样化，而HBase较单一。 Kudu的Tablet自身具备多副本机制，而HBase的Region依赖于底层HDFS的多副本机制。 Kudu底层直接采用本地文件系统， 而HBase依赖于HDFS。 Kudu的底层文件格式采用了类似于Parquet的列式存储格式，而HBase的底层HFile文件却是按行来组织的。 Kudu关于底层的Flush任务以及Compaction任务，能够结合忙时或者闲时进行自动的调整。HBase还尚不具备这种调度能力。 Kudu的Compaction无Minor/Major的区分，限制每一次Compaction的IO总量在128MB大小，因此，并不存在长久执行的Compaction任务。 Compaction是按需进行的，例如，如果所有的写入都是顺序写入，则将不会触发Compaction。 Kudu的设计，既兼顾了分析型的查询能力，又兼顾了随机读写能力，这样，势必也会付出一些代价。 例如，写入数据时关于Primary Key唯一性的限制，就要求写入前要检查对应的Primary Key是否已经存在，这样势必会增大写入的时延。而底层尽管采用了类似于Parquet的列式文件设计，但与HBase类似的冗长的读取路径，也会对分析性的查询带来一些影响。另外，这种设计在整行读取时，也会付出较高的代价。 Kudu与现有系统的对接Kudu提供了与如下一些系统的对接： MapReduce: 提供针对Kudu用户表的Input以及Output任务对接。 Spark: 提供与Spark SQL以及DataFrames的对接。 Impala: Kudu自身未提供Shell以及SQL Parser，所以，它的SQL能力源自与Impala的集成。在这些集成中，能够很好的感知Kudu表数据的本地性信息，能够充分利用Kudu所提供的过滤器对查询进行优化，同时，Impala本身的DDL/DML语法针对Kudu也做了一些扩展。可以想象，Cloudera在Impala与Kudu的集成上，一定会有更多的发力点。 Kudu的适用场景Todd Lipcon在Strata+Hadoop World 2015大会上所提供的主题为《Kudu: Resolving transactional and analytic trade-offs in Hadoop》的演讲中，这样子描述Kudu的适用场景： Kudu Benchmark数据解析如下是对Kudu WhitePage中所提供的一些Benchmark性能测试数据的简单解析(详细的结果请参考论文的第6章节)：1. 基于TPC-H测试标准：针对Impala On Parquet以及Impala On Kudu做了对比测试，Impala On Kudu的平均性能比Impala On Parquet提升了31%。这是由于Kudu所提供的Lazy Meterialization特性以及对对CPU效率的提升而带来的成果。2. Impala-Kudu与Phoenix-HBase的对比：测试使用到了TPC-H中的lineitem一表，共导入了62GB的CSV格式的数据。在导入Phoenix时使用了Phoenix所提供的CsvBulkLoadTool工具。测试时的一些配置信息如下所示： 为Phoenix表划分了100个Hash Partitions。为Kudu创建了100个Tablets。 HBase采用默认的Block Cache策略，为每一个RegionServer配置了9.6GB的Cache内存。而Kudu配置了1GB的Block Cache的进程内存，但同时还依赖于操作系统的Buffer。 HBase表中采用了FAST_DIFF的Block Encoding算法，未启用任何压缩。数据导入到HBase中之后，主动触发了一次Major Compaction，来确保数据的本地化率。62GB原始数据导入到HBase中之后的总大小约为570GB（这是由于未启用Compression压缩，同时，由于多个列都是独立存在的带来的膨胀导致），而导入到Kudu中之后的大小约为227GB。如下是相应的对比测试场景以及对比结果：除了基于Key值的整行数据的查询性能，Phoenix有明显的优势以外，其它的基于整表扫描，或者是基于一些列的查询，Impala-Kudu是有明显的优势的。基于Scan + Filter的查询，HBase本身就不擅长。3. 随机读写能力的对比如下是对比测试的一些场景：如下是对比测试的结果：关于加载以及Zipfian分布模式下，HBase的优势更加明显，当前Kudu也正在做关于Zipfian分布模式下的优化（KUDU-749），而在Uniform模式下，HBase的优势稍弱。整体来看，在随机读写上，Kudu的设计较之HBase而言，存在一些劣势，这是为了兼顾分析型查询所付出的一些代价。参考信息[1] Kudu: New Apache Hadoop Storage for Fast Analytics on Fast Data[2] http://getkudu.io/kudu.pdf[3] Kudu: Resolving transactional and analytic trade-offs in Hadoop[4] Spanner: Google’s Globally-Distributed Database[5] https://kudu.apache.org/docs/ 注： 本文中大多数图源自Kudu论文以及参考信息中的相关内容。","categories":[],"tags":[{"name":"Kudu","slug":"Kudu","permalink":"https://chengtong.me/tags/Kudu/"}]},{"title":"Kudu介绍","slug":"KUDU介绍","date":"2018-08-25T14:30:00.000Z","updated":"2020-05-22T02:03:24.835Z","comments":true,"path":"posts/8920857f.html","link":"","permalink":"https://chengtong.me/posts/8920857f.html","excerpt":"","text":"前言近两年，KUDU 在大数据平台的应用越来越广泛。在阿里、小米、网易等公司的大数据架构中，KUDU 都有着不可替代的地位。本文通过分析 KUDU 的设计， 试图解释为什么 KUDU 会被广泛应用于大数据领域，因为还没有研究过 KUDU 的代码，下面的介绍是根据 KUDU 的论文和网上的一些资料学习自己理解所得，如有不实之处，劳请指正。 背景在 KUDU 之前，大数据主要以两种方式存储： 静态数据：以 HDFS 引擎作为存储引擎，适用于高吞吐量的离线大数据分析场景。这类存储的局限性是数据无法进行随机的读写。 动态数据：以 HBase、Cassandra 作为存储引擎，适用于大数据随机读写场景。这类存储的局限性是批量读取吞吐量远不如 HDFS，不适用于批量数据分析的场景。 从上面分析可知，这两种数据在存储方式上完全不同，进而导致使用场景完全不同，但在真实的场景中，边界可能没有那么清晰，面对既需要随机读写，又需要批量分析的大数据场景，该如何选择呢？这个场景中，单种存储引擎无法满足业务需求，我们需要通过多种大数据工具组合来满足这一需求，一个常见的方案是：如上图所示，数据实时写入 HBase，实时的数据更新也在 HBase 完成，为了应对 OLAP 需求，我们定时（通常是 T+1 或者 T+H）将 HBase 数据写成静态的文件（如：Parquet）导入到 OLAP 引擎（如：HDFS）。这一架构能满足既需要随机读写，又可以支持 OLAP 分析的场景，但他有如下缺点： 架构复杂。从架构上看，数据在 HBase、消息队列、HDFS 间流转，涉及环节太多，运维成本很高。并且每个环节需要保证高可用，都需要维护多个副本，存储空间也有一定的浪费。最后数据在多个系统上，对数据安全策略、监控等都提出了挑战。 时效性低。数据从 HBase 导出成静态文件是周期性的，一般这个周期是一天（或一小时），在时效性上不是很高。 难以应对后续的更新。真实场景中，总会有数据是「延迟」到达的。如果这些数据之前已经从 HBase 导出到 HDFS，新到的变更数据就难以处理了，一个方案是把原有数据应用上新的变更后重写一遍，但这代价又很高。 为了解决上述架构的这些问题，KUDU 应运而生。KUDU 的定位是 「Fast Analytics on Fast Data」，是一个既支持随机读写、又支持 OLAP 分析的大数据存储引擎。从上图可以看出，KUDU 是一个「折中」的产品，在 HDFS 和 HBase 这两个偏科生中平衡了随机读写和批量分析的性能。从 KUDU 的诞生可以说明一个观点：底层的技术发展很多时候都是上层的业务推动的，脱离业务的技术很可能是「空中楼阁」。 概览数据模型KUDU 的数据模型与传统的关系型数据库类似，一个 KUDU 集群由多个表组成，每个表由多个字段组成，一个表必须指定一个由若干个（&gt;=1）字段组成的主键，如下图：KUDU 表中的每个字段是强类型的，而不是 HBase 那样所有字段都认为是 bytes。这样做的好处是可以对不同类型数据进行不同的编码，节省空间。同时，因为 KUDU 的使用场景是 OLAP 分析，有一个数据类型对下游的分析工具也更加友好。 核心 APIKUDU 的对外 API 主要分为写跟读两部分。其中写包括：Insert、Update、Delete，所有写操作都必须指定主键；读 KUDU 对外只提供了 Scan 操作，Scan 时用户可以指定一个或多个过滤器，用于过滤数据。 一致性模型跟大多数关系型数据库一样，KUDU 也是通过 MVCC（Multi-Version Concurrency Control）来实现内部的事务隔离。KUDU 默认的一致性模型是 Snapshot Consistency，即客户端可以一致的访问到某个时间点的一个快照。如果有更高的外部一致性（external consistency）需求，KUDU 目前还没有实现，不过 KUDU 提供了一些设计方案。这里先介绍下外部一致性，它是指：多个事务并发执行达到串行效果，并且保证修改时间戳严格按照事务发生先后顺序，即如果有先后两个事务 A、B， A 发生在 B 之前，那么对于客户端来说，要么看到 A，要么看到 A、B，不会只看到 B 而看不到 A。KUDU 提供了两个实现外部一致性的方案： 方案一：在各个 Client 之间传播带有时间戳的 token，大致思路是 Client 提交完一个写请求后，生成一个带时间戳的 token，然后把这个 token 传播给其他客户端，其他客户端请求的时候可以带上这个 token。 方案二：类似 Google Spanner 的方案，通过 commit-wait 机制实现外部一致性。 这里我们衍生介绍下 Google Spanner 是如何实现分布式事务的外部一致性的。首先我们先明确下分布式事务外部一致性这个问题的由来。首先，在数据库中，我们出于性能考虑，一般我们对读不加排他锁，只对写进行加排他锁，这就会带来一个问题，数据在读取的时候可能正在被修改，导致同一事务中多次读取到的数据可能不一致，为了解决这个问题，我们引入了 MVCC。在单机系统中，通过 MVCC 就能解决外部一致性问题，因为每个事务都有一个在本机生成的一个时间戳，根据事务的时间戳先后，我们就能判断出事务发生的先后顺序。但是在分布式系统中，要实现外部一致性就没有那么简单了，核心问题是事务在不同的机器上执行，而不同机器的本地时钟是有误差的，因此就算是真实发生的事务顺序是 A-&gt;B，但是在事务持久化的时候记录的时间戳可能是 B &lt; A，这时如果一个事务 C 来读取数据，可能只读到 B 而没有读到 A。从上面的分析我们可以发现，分布式系统中保证事务的外部一致性的核心是一个精确的事务版本（时间戳），而最大的难点也在这里，计算机上的时钟不是一个绝对精确的时间，它跟标准时间是有一定的随机的误差的，导致分布式系统中不同机器之间的时间有偏差。Google Spanner 的解决思路是把不同机器的误差时间控制在一个很小的确定的范围内，再配合 commit-wait 机制来实现外部一致性。 控制时间误差的方案称为 TrueTime，它通过硬件（GPS 和原子钟）和软件结合，保证获取到的时间在较小误差（±4ms）内绝对正确，具体的实现这里就不展开了，有兴趣的同学可以自行找资料研究。TrueTime 对外只提供 3 个 API，如下：这里最主要的 API 是 TT.now()，它范围当前绝对精确时间的上下界，表示当前绝对精确时间在 TT.now().earliest 和 TT.now().latest 之间。 有了一个有界误差的 TrueTime 后，就可以通过 commit-wait 机制来实现外部一致性了，具体的方案如下：如上图所示，在一个事务开始获取锁执行后，生成事务的时间版本 s=TT.now().latest，然后开始执行事务的具体操作，但是一个事务的结束并不只由事务本身的时间消耗决定，它还要保证后续的事务时间版本不会早于自己，因此，事务需要等待直到 TT.now().earliest &gt; s 后，才算真正结束。根据整个 commit-wait 过程我们可以知道，整个事务提交过程需要等待 2 倍的平均误差时间（ε），TrueTime 的平均误差时间是 4 ms，因此一次 commit-wait 需要至少 8 ms。 之前我们提到，KUDU 也借鉴 Spanner 使用 commit-wait 机制实现外部一致性，但是 commit-wait 强依赖于 TrueTime，而 TrueTime 需要各种昂贵的硬件设备支持，目前 KUDU 通过纯软件算法的方式来实现时钟算法，为 HybridTime，但这个方案时间误差较大，考虑到 commit-wait 需要等待 2ε 时间，因此误差一大实际场景使用限制就很多了。 架构整体架构KUDU 中存在两个角色 Mater Server：负责集群管理、元数据管理等功能 Tablet Server：负责数据存储，并提供数据读写服务 为了实现分区容错性，跟其他大数据产品一样，对于每个角色，在 KUDU 中都可以设置特定数量（一般是 3 或 5）的副本。各副本间通过 Raft 协议来保证数据一致性。Raft 协议与 ZAB 类似，都是 Paxos 协议的工程简化版本，具体细节有兴趣的同学可以搜索相关资料学习。KUDU Client 在与服务端交互时，先从 Master Server 获取元数据信息，然后去 Tablet Server 读写数据，如下图： 数据分区策略与大多数大数据存储引擎类似，KUDU 对表进行横向分区，KUDU 表会被横向切分存储在多个 tablets 中。不过相比与其他存储引擎，KUDU 提供了更加丰富灵活的数据分区策略。 一般数据分区策略主要有两种，一种是 Range Partitioning，按照字段值范围进行分区，HBase 就采用了这种方式，如下图：Range Partitioning 的优势是在数据进行批量读的时候，可以把大部分的读变成同一个 tablet 中的顺序读，能够提升数据读取的吞吐量。并且按照范围进行分区，我们可以很方便的进行分区扩展。其劣势是同一个范围内的数据写入都会落在单个 tablet 上，写的压力大，速度慢。 另一种分区策略是 Hash Partitioning，按照字段的 Hash 值进行分区，Cassandra 采用了这个方式，见下图：与 Range Partitioning 相反，由于是 Hash 分区，数据的写入会被均匀的分散到各个 tablet 中，写入速度快。但是对于顺序读的场景这一策略就不太适用了，因为数据分散，一次顺序读需要将各个 tablet 中的数据分别读取并组合，吞吐量低。并且 Hash 分区无法应对分区扩展的情况。 各种分区策略的优劣对比见下图：既然各分区策略各有优劣，能否将不同分区策略进行组合，取长补短呢？这也是 KUDU 的思路，KUDU 支持用户对一个表指定一个范围分区规则和多个 Hash 分区规则，如下图： 存储存储设计目标 快速的列扫描 低延迟的随机更新 稳定的性能表现存储方式KUDU 是一个列式存储的存储引擎，其数据存储方式如下： 列式存储的数据库很适合于 OLAP 场景，其特点如下： 优势1. 查询少量列时 IO 少，速度快2. 数据压缩比高3. 便于查询引擎性能优化：延迟物化、直接操作压缩数据、向量化执行 劣势1. 查询列太多时性能下降（KUDU 建议列数不超过 300 ）2. 不适合 OLTP 场景 存储实现与其他大数据存储引擎类似，KUDU 的存储也是通过 LSM 树（Log-Structured Merge Tree）来实现的。KUDU 的最小存储单元是 RowSets，KUDU 中存在两种 RowSets：MemRowSets、DiskRowSets，数据先写内存中的 MemRowSet，MemRowSet 满了后刷到磁盘成为一个 DiskRowSet，DiskRowSet 一经写入，就无法修改了。见下图：当然上面只是最粗粒度的一个写入过程，为了解释 KUDU 的为什么既能支持随机读写，又能支持大数据量的 OLAP 分析，我们需要更进一步进行解剖分析。我们需求探究的主要两个问题是： 如何应对数据变更？ 如何优化读写性能以满足 OLAP 场景？ 应对数据变更首先上面我们讲了，DiskRowSet 是不可修改了，那么 KUDU 要如何应对数据的更新呢？在 KUDU 中，把 DiskRowSet 分为了两部分：base data、delta stores。base data 负责存储基础数据，delta stores负责存储 base data 中的变更数据。整个数据更新方案如下：如上图所示，数据从 MemRowSet 刷到磁盘后就形成了一份 DiskRowSet（只包含 base data），每份 DiskRowSet 在内存中都会有一个对应的 DeltaMemStore，负责记录此 DiskRowSet 后续的数据变更（更新、删除）。DeltaMemStore 内部维护一个 B-树索引，映射到每个 row_offset 对应的数据变更。DeltaMemStore 数据增长到一定程度后转化成二进制文件存储到磁盘，形成一个 DeltaFile，随着 base data 对应数据的不断变更，DeltaFile 逐渐增长。 优化读写性能首先我们从 KUDU 的 DiskRowSet 数据结构上分析：从上图可知，在具体的数据（列数据、变更记录）上，KUDU 都做了 B- 树索引，以提高随机读写的性能。在 base data 中，KUDU 还针对主键做了好几类索引（实际上由于 delta store 只记录变更数据，base data 中对主键的索引即本 DiskRowSet 中全局的主键索引）： 主键范围索引：记录本 DiskRowSet 中主键的范围，用于粗粒度过滤一些主键范围 布隆过滤器：通过主键的布隆过滤器来实现不存在数据的过滤 主键索引：要精确定位一个主键是否存在，以及具体在 DiskRowSet 中的位置（即：row_offset），通过以 B-树为数据结构的主键索引来快速查找。 随着时间的推移，KUDU 中的小文件会越来越多，主要包括各个 DiskRowSet 中的 base data，还有每个 base data 对应的若干份 DeltaFile。小文件的增多会影响 KUDU 的性能，特别是 DeltaFile 中还有很多重复的数据。为了提高性能，KUDU 会进行定期 compaction，compaction 主要包括两部分： DeltaFile compaction：过多的 DeltaFile 影响读性能，定期将 DeltaFile 合并回 base data 可以提升性能。在通常情况下，会发生频繁变更的字段是集中在少数几个字段中的，而 KUDU 是列式存储的，因此 KUDU 还在 DeltaFile compaction 时做了优化，文件合并时只合并部分变更列到 base data 中对应的列。 DiskRowSet compaction：除了 DeltaFile，定期将 DiskRowSet 合并也能提升性能，一个原因是合并时我们可以将被删除的数据彻底的删除，而且可以减少同样 key 范围内数据的文件数，提升索引的效率。 当用户的查询存在列的过滤条件时，KUDU 还可以在查询时进行 延迟物化（Lazy Materialization ）来提升性能。举例说明，现在我们有这样一张表：用户的 SQL 是这样的：1SELECT * FROM tb WHERE sex=‘男’ ADN age &gt; 20 KUDU 中数据查询过程是这样的： 1. 扫描 sex 列，过滤出要查询的行 [1,3]2. 扫描 age 列，过滤出要查询的行 [3,4]3. 过滤条件相交，得到 34. 真正读取 id=3 行对应的所有列信息，组装 上述查询中，KUDU 真正需要去物理读取的数据只有 id=3 这一行，这样就减少了 IO 数量。 读写过程数据写过程如上图，当 Client 请求写数据时，先根据主键从 Mater Server 中获取要访问的目标 Tablets，然后到依次对应的 Tablet 获取数据。因为 KUDU 表存在主键约束，所以需要进行主键是否已经存在的判断，这里就涉及到之前说的索引结构对读写的优化了。一个 Tablet 中存在很多个 RowSets，为了提升性能，我们要尽可能地减少要扫描的 RowSets 数量。首先，我们先通过每个 RowSet 中记录的主键的（最大最小）范围，过滤掉一批不存在目标主键的 RowSets，然后在根据 RowSet 中的布隆过滤器，过滤掉确定不存在目标主键的 RowSets，最后再通过 RowSets 中的 B-树索引，精确定位目标主键是否存在。如果主键已经存在，则报错（主键重复），否则就进行写数据（写 MemRowSet）。 数据更新过程数据更新的核心是定位到待更新数据的位置，这块与写入的时候类似，就不展开了，等定位到具体位置后，然后将变更写到对应的 delta store 中。 数据读过程如上图，数据读取过程大致如下：先根据要扫描数据的主键范围，定位到目标的Tablets，然后读取 Tablets 中的 RowSets。在读取每个 RowSet 时，先根据主键过滤要 scan 范围，然后加载范围内的 base data，再找到对应的 delta stores，应用所有变更，最后 union 上 MenRowSet 中的内容，返回数据给 Client。 应用案例这里介绍一个小米使用 KUDU 的案例。具体的业务场景是这样的：收集手机App和后台服务发送的 RPC 跟踪事件数据，然后构建一个服务监控和问题诊断的工具。 高写入吞吐：每天大于200亿条记录为了能够尽快定位和解决问题，要求系统能够查询最新的数据并能快速返回结果为了方便问题诊断，要求系统能够查询/搜索明细数据（而不只是统计信息）在使用 KUDU 前，小米的架构是这样的：一部分源系统数据是通过Scribe（日志聚合系统）把数据写到HDFS，另一部分源系统数据直接写入HBase。然后通过Hive/MR/Spark作业把两部分数据合并，给离线数仓和 OLAP 分析。 在使用 KUDU 后，架构简化成了：从上图我们可以看到，所有的数据存储都集中到的 KUDU 一个上，减少了整体的架构复杂度，同时，也大大提升了实时性。","categories":[],"tags":[{"name":"Kudu","slug":"Kudu","permalink":"https://chengtong.me/tags/Kudu/"}]},{"title":"HBase对比HDFS","slug":"HBase对比HDFS","date":"2018-08-24T13:16:54.000Z","updated":"2020-05-22T02:03:24.800Z","comments":true,"path":"posts/21e5a7a5.html","link":"","permalink":"https://chengtong.me/posts/21e5a7a5.html","excerpt":"","text":"什么是HDFS(Hadoop分布式文件系统)HDFS允许以分布式和冗余方式存储大量数据。HDFS组件• NameNode• DataNodeNameNode：NameNode可以被视为系统的管理者。它维护系统文件树以及系统中存在的所有文件和目录的元数据。其中“命名空间镜像(Namespace image)”和“编辑日志”用于存储元数据信息。 Namenode包含所有数据节点的数据块信息，但是，它不会持久存储数据节点数据块位置信息。系统启动时，每次从数据节点重建此信息。DataNode:是集群中的从属者，提供实际存储。它主要负责为客户提供读写请求服务。 什么是HbaseHbase是一个可以运行在Hadoop集群上的NoSQL数据库。Hbase组件• Hbase Master• Region Server• Region• ZookeeperHbase的架构图如下图所示： Hbase与HDFS对比总结一下：什么时候选用Hbase，什么场景使用HDFS进行存储？1. 对于经常需要修改原有的数据的场景使用Hbase进行存储；2. 对于性能要求不高且只需要支持单条数据查询或者小批量数据进行查询，两者均可；3. 对于需要经常进行全表扫描进行大批量的查询的选择HDFS； 那么有没有一种存储方式既能满足实时的更新，又能满足大量的数据分析工作，这时候可以考虑一下使用kudu。","categories":[],"tags":[{"name":"HBase","slug":"HBase","permalink":"https://chengtong.me/tags/HBase/"},{"name":"HDFS","slug":"HDFS","permalink":"https://chengtong.me/tags/HDFS/"}]},{"title":"springboot过滤器禁止ip频繁访问","slug":"springboot过滤器禁止ip频繁访问","date":"2018-08-14T02:28:26.000Z","updated":"2021-06-08T02:20:56.539Z","comments":true,"path":"posts/a44ad48d.html","link":"","permalink":"https://chengtong.me/posts/a44ad48d.html","excerpt":"","text":"在 Web 中最经常发生的就是利用恶性 URL 访问刷爆服务器之类的攻击，建议对高频ip做限制，防止不法ip攻击，去网上看了很多方法，最多的就是自定义注解，然后定义一个注解的实现类利用aop去验证该限制接口的请求ip是否符合，但是缺点就是我们不可能每一个接口都要去加注解。还有一种方法就是利用过滤器去验证每一个请求的ip 过滤器：统计用户访问次数，记录访问时间、封禁时间监听器：工程运行时初始化IP存储器（此处用的Map） 编写一个过滤器： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167package com.lk.hm.security;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import javax.servlet.*;import javax.servlet.annotation.WebFilter;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;import java.io.IOException;import java.util.Iterator;import java.util.Map;import java.util.Set;/** * 自定义过滤器，用来判断IP访问次数是否超限 * 如果前台用户访问网站的频率过快（达到超过50次/秒），则判定该ip恶意刷新操作， * 限制该IP的访问，1小时后自己解除限制 */@WebFilter(urlPatterns = \"/*\")public class IpFilter implements Filter &#123; private final static Logger logger = LoggerFactory.getLogger(IpFilter.class); /** * 默认限制时间（单位：ms） */ private static final long LIMITED_TIME_MILLIS = 60 * 60 * 1000; /** * 用户连续访问最高阀值，超过该值则认定为恶意操作的IP，进行限制 */ private static final int LIMIT_NUMBER = 50; /** * 用户访问最小安全时间，在该时间内如果访问次数大于阀值，则记录为恶意IP，否则视为正常访问 */ private static final int MIN_SAFE_TIME = 5000; private FilterConfig config; @Override public void init(FilterConfig filterConfig) throws ServletException &#123; this.config = filterConfig; //设置属性filterConfig &#125; /* (non-Javadoc) * @see javax.servlet.Filter#doFilter(javax.servlet.ServletRequest, javax.servlet.ServletResponse, javax.servlet.FilterChain) */ @SuppressWarnings(\"unchecked\") @Override public void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain chain) throws IOException, ServletException &#123; HttpServletRequest request = (HttpServletRequest) servletRequest; HttpServletResponse response = (HttpServletResponse) servletResponse; ServletContext context = config.getServletContext(); // 获取限制IP存储器：存储被限制的IP信息 Map&lt;String, Long&gt; limitedIpMap = (Map&lt;String, Long&gt;) context.getAttribute(\"limitedIpMap\"); // 过滤受限的IP filterLimitedIpMap(limitedIpMap); // 获取用户IP String ip = request.getRemoteHost(); logger.info(\"ip:\" + ip); // 判断是否是被限制的IP，如果是则跳到异常页面 if (isLimitedIP(limitedIpMap, ip)) &#123; long limitedTime = limitedIpMap.get(ip) - System.currentTimeMillis(); // 剩余限制时间(用为从毫秒到秒转化的一定会存在些许误差，但基本可以忽略不计) request.setAttribute(\"remainingTime\", ((limitedTime / 1000) + (limitedTime % 1000 &gt; 0 ? 1 : 0))); //request.getRequestDispatcher(\"/error/overLimitIP\").forward(request, response); logger.info(\"ip访问过于频繁：\" + ip); //response.setCharacterEncoding(\"gb2312\"); //设置输出内容编码格式// response.reset();// response.setCharacterEncoding(\"utf-8\"); //设置输出内容编码格式// PrintWriter out = response.getWriter();// out.println(\"&lt;b&gt;由于您访问过于频繁，被系统自动认定为机器人。1个小时自动解除&lt;/b&gt;\");、 return; &#125; // 获取IP存储器 Map&lt;String, Long[]&gt; ipMap = (Map&lt;String, Long[]&gt;) context.getAttribute(\"ipMap\"); // 判断存储器中是否存在当前IP，如果没有则为初次访问，初始化该ip // 如果存在当前ip，则验证当前ip的访问次数 // 如果大于限制阀值，判断达到阀值的时间，如果不大于[用户访问最小安全时间]则视为恶意访问，跳转到异常页面 if (ipMap.containsKey(ip)) &#123; Long[] ipInfo = ipMap.get(ip); ipInfo[0] = ipInfo[0] + 1; System.out.println(\"当前第[\" + (ipInfo[0]) + \"]次访问\"); if (ipInfo[0] &gt; LIMIT_NUMBER) &#123; Long ipAccessTime = ipInfo[1]; Long currentTimeMillis = System.currentTimeMillis(); if (currentTimeMillis - ipAccessTime &lt;= MIN_SAFE_TIME) &#123; limitedIpMap.put(ip, currentTimeMillis + LIMITED_TIME_MILLIS); request.setAttribute(\"remainingTime\", LIMITED_TIME_MILLIS); logger.info(\"ip访问过于频繁：\" + ip); request.getRequestDispatcher(\"/error/overLimitIP\").forward(request, response); return; &#125; else &#123; initIpVisitsNumber(ipMap, ip); &#125; &#125; &#125; else &#123; initIpVisitsNumber(ipMap, ip); System.out.println(\"您首次访问该网站\"); &#125; context.setAttribute(\"ipMap\", ipMap); chain.doFilter(request, response); &#125; @Override public void destroy() &#123; // TODO Auto-generated method stub &#125; /** * @param limitedIpMap * @Description 过滤受限的IP，剔除已经到期的限制IP */ private void filterLimitedIpMap(Map&lt;String, Long&gt; limitedIpMap) &#123; if (limitedIpMap == null) &#123; return; &#125; Set&lt;String&gt; keys = limitedIpMap.keySet(); Iterator&lt;String&gt; keyIt = keys.iterator(); long currentTimeMillis = System.currentTimeMillis(); while (keyIt.hasNext()) &#123; long expireTimeMillis = limitedIpMap.get(keyIt.next()); if (expireTimeMillis &lt;= currentTimeMillis) &#123; keyIt.remove(); &#125; &#125; &#125; /** * @param limitedIpMap * @param ip * @return true : 被限制 | false : 正常 * @Description 是否是被限制的IP */ private boolean isLimitedIP(Map&lt;String, Long&gt; limitedIpMap, String ip) &#123; if (limitedIpMap == null || ip == null) &#123; // 没有被限制 return false; &#125; Set&lt;String&gt; keys = limitedIpMap.keySet(); Iterator&lt;String&gt; keyIt = keys.iterator(); while (keyIt.hasNext()) &#123; String key = keyIt.next(); if (key.equals(ip)) &#123; // 被限制的IP return true; &#125; &#125; return false; &#125; /** * 初始化用户访问次数和访问时间 * * @param ipMap * @param ip */ private void initIpVisitsNumber(Map&lt;String, Long[]&gt; ipMap, String ip) &#123; Long[] ipInfo = new Long[2]; ipInfo[0] = 0L;// 访问次数 ipInfo[1] = System.currentTimeMillis();// 初次访问时间 ipMap.put(ip, ipInfo); &#125;&#125; 创建一个监听器：需要初始化俩个容器： 1234567891011121314151617181920212223242526272829303132333435package com.lk.hm.security;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import javax.servlet.ServletContext;import javax.servlet.ServletContextEvent;import javax.servlet.ServletContextListener;import javax.servlet.annotation.WebListener;import java.util.HashMap;import java.util.Map;@WebListenerpublic class MyApplicationListener implements ServletContextListener &#123; private final static Logger logger = LoggerFactory.getLogger(MyApplicationListener.class); @Override public void contextInitialized(ServletContextEvent sce) &#123; logger.info(\"liting: contextInitialized\"); System.err.println(\"MyApplicationListener初始化成功\"); ServletContext context = sce.getServletContext(); // IP存储器 Map&lt;String, Long[]&gt; ipMap = new HashMap&lt;String, Long[]&gt;(); context.setAttribute(\"ipMap\", ipMap); // 限制IP存储器：存储被限制的IP信息 Map&lt;String, Long&gt; limitedIpMap = new HashMap&lt;String, Long&gt;(); context.setAttribute(\"limitedIpMap\", limitedIpMap); logger.info(\"ipmap：\" + ipMap.toString() + \";limitedIpMap:\" + limitedIpMap.toString() + \"初始化成功。。。。。\"); &#125; @Override public void contextDestroyed(ServletContextEvent sce) &#123; // TODO Auto-generated method stub &#125;&#125; 需要在springboot启动类里面添加以上监听器和过滤器的扫描包路径： 1@ServletComponentScan(basePackages=\"com.lk.hm.security\")","categories":[{"name":"JAVA","slug":"JAVA","permalink":"https://chengtong.me/categories/JAVA/"}],"tags":[{"name":"Spring Boot","slug":"Spring-Boot","permalink":"https://chengtong.me/tags/Spring-Boot/"}]},{"title":"Java常见的线程安全的类","slug":"Java常见的线程安全的类","date":"2018-07-31T03:56:36.000Z","updated":"2020-05-23T12:43:23.982Z","comments":true,"path":"posts/9db5de4.html","link":"","permalink":"https://chengtong.me/posts/9db5de4.html","excerpt":"","text":"通过synchronized 关键字给方法加上内置锁来实现线程安全Timer，TimerTask，Vector，Stack，HashTable，StringBuffer 原子类Atomicxxx—包装类的线程安全类如AtomicLong，AtomicInteger等等Atomicxxx 是通过Unsafe 类的native方法实现线程安全的 BlockingQueue 和BlockingDequeBlockingDeque接口继承了BlockingQueue接口，BlockingQueue 接口的实现类有ArrayBlockingQueue ，LinkedBlockingQueue ，PriorityBlockingQueue 而BlockingDeque接口的实现类有LinkedBlockingDequeBlockingQueue和BlockingDeque 都是通过使用定义为final的ReentrantLock作为类属性显式加锁实现同步的 CopyOnWriteArrayList和 CopyOnWriteArraySetCopyOnWriteArraySet的内部实现是在其类内部声明一个final的CopyOnWriteArrayList属性，并在调用其构造函数时实例化该CopyOnWriteArrayList，CopyOnWriteArrayList采用的是显式地加上ReentrantLock实现同步，而CopyOnWriteArrayList容器的线程安全性在于在每次修改时都会创建并重新发布一个新的容器副本，从而实现可变性。 Concurrentxxx最常用的就是ConcurrentHashMap，当然还有ConcurrentSkipListSet和ConcurrentSkipListMap等等。ConcurrentHashMap使用了一种完全不同的加锁策略来提供更高的并发性和伸缩性。ConcurrentHashMap并不是将每个方法都在同一个锁上同步并使得每次只能有一个线程访问容器，而是使用一种粒度更细的加锁机制——分段锁来实现更大程度的共享 在这种机制中，任意数量的读取线程可以并发访问Map，执行读取操作的线程和执行写入操作的线程可以并发地访问Map，并且一定数量的写入线程可以并发地修改Map，这使得在并发环境下吞吐量更高，而在单线程环境中只损失非常小的性能 ThreadPoolExecutorThreadPoolExecutor也是使用了ReentrantLock显式加锁同步 Collections中的synchronizedCollection(Collection c)方法可将一个集合变为线程安全，其内部通过synchronized关键字加锁同步 一、概念：线程安全：就是当多线程访问时，采用了加锁的机制；即当一个线程访问该类的某个数据时，会对这个数据进行保护，其他线程不能对其访问，直到该线程读取完之后，其他线程才可以使用。防止出现数据不一致或者数据被污染的情况。线程不安全：就是不提供数据访问时的数据保护，多个线程能够同时操作某个数据，从而出现数据不一致或者数据污染的情况。对于线程不安全的问题，一般会使用synchronized关键字加锁同步控制。线程安全 工作原理： jvm中有一个main memory对象，每一个线程也有自己的working memory，一个线程对于一个变量variable进行操作的时候， 都需要在自己的working memory里创建一个copy,操作完之后再写入main memory。当多个线程操作同一个变量variable，就可能出现不可预知的结果。而用synchronized的关键是建立一个监控monitor，这个monitor可以是要修改的变量，也可以是其他自己认为合适的对象(方法)，然后通过给这个monitor加锁来实现线程安全，每个线程在获得这个锁之后，要执行完加载load到working memory 到 use &amp;&amp; 指派assign 到 存储store 再到 main memory的过程。才会释放它得到的锁。这样就实现了所谓的线程安全。 二、线程安全(Thread-safe)的集合对象：VectorHashTableStringBuffer 三、非线程安全的集合对象： ArrayList ： LinkedList： HashMap： HashSet： TreeMap： TreeSet： StringBulider： 四、相关集合对象比较：Vector、ArrayList、LinkedList：1、Vector：Vector与ArrayList一样，也是通过数组实现的，不同的是它支持线程的同步，即某一时刻只有一个线程能够写Vector，避免多线程同时写而引起的不一致性，但实现同步需要很高的花费，因此，访问它比访问ArrayList慢。2、ArrayList：a. 当操作是在一列数据的后面添加数据而不是在前面或者中间，并需要随机地访问其中的元素时，使用ArrayList性能比较好。b. ArrayList是最常用的List实现类，内部是通过数组实现的，它允许对元素进行快速随机访问。数组的缺点是每个元素之间不能有间隔，当数组大小不满足时需要增加存储能力，就要讲已经有数组的数据复制到新的存储空间中。当从ArrayList的中间位置插入或者删除元素时，需要对数组进行复制、移动、代价比较高。因此，它适合随机查找和遍历，不适合插入和删除。3、LinkedList：a. 当对一列数据的前面或者中间执行添加或者删除操作时，并且按照顺序访问其中的元素时，要使用LinkedList。b. LinkedList是用链表结构存储数据的，很适合数据的动态插入和删除，随机访问和遍历速度比较慢。另外，他还提供了List接口中没有定义的方法，专门用于操作表头和表尾元素，可以当作堆栈、队列和双向队列使用。 Vector和ArrayList在使用上非常相似，都可以用来表示一组数量可变的对象应用的集合，并且可以随机的访问其中的元素。 HashTable、HashMap、HashSet：HashTable和HashMap采用的存储机制是一样的，不同的是：1、HashMap：a. 采用数组方式存储key-value构成的Entry对象，无容量限制；b. 基于key hash查找Entry对象存放到数组的位置，对于hash冲突采用链表的方式去解决；c. 在插入元素时，可能会扩大数组的容量，在扩大容量时须要重新计算hash，并复制对象到新的数组中；d. 是非线程安全的；e. 遍历使用的是Iterator迭代器； 2、HashTable：a. 是线程安全的；b. 无论是key还是value都不允许有null值的存在；在HashTable中调用Put方法时，如果key为null，直接抛出NullPointerException异常；c. 遍历使用的是Enumeration列举； 3、HashSet：a. 基于HashMap实现，无容量限制；b. 是非线程安全的；c. 不保证数据的有序； TreeSet、TreeMap：TreeSet和TreeMap都是完全基于Map来实现的，并且都不支持get(index)来获取指定位置的元素，需要遍历来获取。另外，TreeSet还提供了一些排序方面的支持，例如传入Comparator实现、descendingSet以及descendingIterator等。1、TreeSet：a. 基于TreeMap实现的，支持排序；b. 是非线程安全的； 2、TreeMap：a. 典型的基于红黑树的Map实现，因此它要求一定要有key比较的方法，要么传入Comparator比较器实现，要么key对象实现Comparator接口；b. 是非线程安全的； StringBuffer和StringBulider：StringBuilder与StringBuffer都继承自AbstractStringBuilder类，在AbstractStringBuilder中也是使用字符数组保存字符串。 1、在执行速度方面的比较：StringBuilder &gt; StringBuffer ； 2、他们都是字符串变量，是可改变的对象，每当我们用它们对字符串做操作时，实际上是在一个对象上操作的，不像String一样创建一些对象进行操作，所以速度快； 3、 StringBuilder：线程非安全的； 4、StringBuffer：线程安全的； 对于String、StringBuffer和StringBulider三者使用的总结： 1.如果要操作少量的数据用 = String 2.单线程操作字符串缓冲区 下操作大量数据 = StringBuilder 3.多线程操作字符串缓冲区 下操作大量数据 = StringBuffer","categories":[],"tags":[]},{"title":"Maven插件Jib配合Harbor生成Docker镜像参考","slug":"Maven插件Jib配合Harbor生成Docker镜像参考","date":"2018-07-12T14:00:01.000Z","updated":"2021-06-02T02:45:30.227Z","comments":true,"path":"posts/d3c9e3a3.html","link":"","permalink":"https://chengtong.me/posts/d3c9e3a3.html","excerpt":"","text":"1 说明 Maven插件Jib暂不支持https的自签名，因此只能配置以Http的方式访问Harbor私有仓库 以下基于SpringBoot2.x进行配置 2 Maven配置2.1 pom.xml中配置项目的pom.xml中添加以下属性和插件内容： 12345&lt;properties&gt; &lt;app.main.class&gt;cc.anxminise.spblearn.Application&lt;/app.main.class&gt; &lt;docker.image.prefix&gt;192.168.1.112/library&lt;/docker.image.prefix&gt; &lt;docker.image.name&gt;$&#123;artifactId&#125;:$&#123;version&#125;&lt;/docker.image.name&gt;&lt;/properties&gt; 属性 说明 举例 app.main.class SpringBoot应用的启动类，即：待@SpringBootApplication注解的类 无 docker.image.prefix 生成的docker镜像的tag标签的前缀 192.168.1.112/library/spblearn:0.0.1 docker.image.name 生成的docker镜像的名称 192.168.1.112/library/spblearn:0.0.1 12345678910111213141516171819202122232425262728&lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;com.google.cloud.tools&lt;/groupId&gt; &lt;artifactId&gt;jib-maven-plugin&lt;/artifactId&gt; &lt;version&gt;0.9.11&lt;/version&gt; &lt;configuration&gt; &lt;from&gt; &lt;image&gt;192.168.1.112/library/centos7-java8u131:1.0.1&lt;/image&gt; &lt;/from&gt; &lt;to&gt; &lt;image&gt;$&#123;docker.image.prefix&#125;/$&#123;docker.image.name&#125;&lt;/image&gt; &lt;/to&gt; &lt;container&gt; &lt;jvmFlags&gt; &lt;jvmFlag&gt;-Xms512m&lt;/jvmFlag&gt; &lt;/jvmFlags&gt; &lt;environment&gt; &lt;spring.profiles.active&gt;prod&lt;/spring.profiles.active&gt; &lt;TZ&gt;Asia/Shanghai&lt;/TZ&gt; &lt;/environment&gt; &lt;mainClass&gt;$&#123;app.main.class&#125;&lt;/mainClass&gt; &lt;format&gt;OCI&lt;/format&gt; &lt;useCurrentTimestamp&gt;true&lt;/useCurrentTimestamp&gt; &lt;/container&gt; &lt;allowInsecureRegistries&gt;true&lt;/allowInsecureRegistries&gt; &lt;/configuration&gt; &lt;/plugin&gt;&lt;/plugins&gt; 属性 说明 jvmFlag 配置jvm虚拟机参数 spring.profiles.active 配置应用的启动参数，这里配置了使用application-prod.yml中的配置 TZ 配置了使用的时区 2.2 执行构建生成docker镜像1mvn jib:dockerBuild -DsendCredentialsOverHttp=true 3 本地测试镜像1docker run -it --rm -p port:port 192.168.1.112/library/镜像名称:镜像版本 4 推送镜像到仓库1docker push 192.168.1.112/library/镜像名称:镜像版本","categories":[{"name":"容器","slug":"容器","permalink":"https://chengtong.me/categories/容器/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://chengtong.me/tags/Docker/"},{"name":"Jib","slug":"Jib","permalink":"https://chengtong.me/tags/Jib/"},{"name":"Harbor","slug":"Harbor","permalink":"https://chengtong.me/tags/Harbor/"}]},{"title":"选择Kong作为你的API网关","slug":"选择Kong作为你的API网关","date":"2018-07-12T12:28:15.000Z","updated":"2020-05-22T02:03:25.159Z","comments":true,"path":"posts/c6cc21ed.html","link":"","permalink":"https://chengtong.me/posts/c6cc21ed.html","excerpt":"","text":"Kong（https://github.com/Kong/kong）是一个云原生，高效，可扩展的分布式API 网关。 自 2015 年在 github 开源后，广泛受到关注，目前已收获 1.68w+ 的 star，其核心价值在于高性能和可扩展性。 为什么需要 API 网关 img 在微服务架构之下，服务被拆的非常零散，降低了耦合度的同时也给服务的统一管理增加了难度。如上图左所示，在旧的服务治理体系之下，鉴权，限流，日志，监控等通用功能需要在每个服务中单独实现，这使得系统维护者没有一个全局的视图来统一管理这些功能。API 网关致力于解决的问题便是为微服务纳管这些通用的功能，在此基础上提高系统的可扩展性。如右图所示，微服务搭配上 API 网关，可以使得服务本身更专注于自己的领域，很好地对服务调用者和服务提供者做了隔离。 为什么是 KongSpringCloud 玩家肯定都听说过 Zuul 这个路由组件，包括 Zuul2 和 Springcloud Gateway 等框架，在国内的知名度都不低。没错，我称呼这些为组件 Or 框架，而 Kong 则更衬的上产品这个词。在此我们可以简单对比下 Zuul 和 Kong。 举例而言，如果选择使用 Zuul，当需要为应用添加限流功能，由于 Zuul 只提供了基本的路由功能，开发者需要自己研发 Zuul Filter，可能你觉得一个功能还并不麻烦，但如果在此基础上对 Zuul 提出更多的要求，很遗憾，Zuul 使用者需要自行承担这些复杂性。而对于 Kong 来说，限流功能就是一个插件，只需要简单的配置，即可开箱即用。 Kong 的插件机制是其高可扩展性的根源，Kong 可以很方便地为路由和服务提供各种插件，网关所需要的基本特性，Kong 都如数支持： 云原生 : 与平台无关，Kong可以从裸机运行到Kubernetes 动态路由 ：Kong 的背后是 OpenResty+Lua，所以从 OpenResty 继承了动态路由的特性 熔断 健康** 检查 日志 : 可以记录通过 Kong 的 HTTP，TCP，UDP 请求和响应。 鉴权 : 权限控制，IP 黑白名单，同样是 OpenResty 的特性 SSL : Setup a Specific SSL Certificate for an underlying service or API. 监控 : Kong 提供了实时监控插件 认证 : 如数支持 HMAC, JWT, Basic, OAuth2.0 等常用协议 限流 REST API : 通过 Rest API 进行配置管理，从繁琐的配置文件中解放 可用性 : 天然支持分布式 高性能 : 背靠非阻塞通信的 nginx，性能自不用说 插件机制 : 提供众多开箱即用的插件，且有易于扩展的自定义插件接口，用户可以使用 Lua 自行开发插件 上面这些特性中，反复提及了 Kong 背后的 OpenResty，实际上，使用 Kong 之后，Nginx 可以完全摒弃，Kong 的功能是 Nginx 的父集。 而 Zuul 除了基础的路由特性以及其本身和 SpringCloud 结合较为紧密之外，并无任何优势。 Kong 的架构 image-20180712184740981 从技术的角度讲，Kong 可以认为是一个 OpenResty 应用程序。 OpenResty 运行在 Nginx 之上，使用 Lua 扩展了 Nginx。 Lua 是一种非常容易使用的脚本语言，可以让你在 Nginx 中编写一些逻辑操作。之前我们提到过一个概念 Kong = OpenResty + Nginx + Lua，但想要从全局视角了解 Kong 的工作原理，还是直接看源码比较直接。我们定位到本地的 Kong 文件夹，按照上图中的目录层级来识识 Kong 的庐山真面目。 Kong 文件下包含了全部源码和必要组件，分析他们，我们便得到了 Kong 的架构。13.x 是目前 Kong 的最新版本。 从 2 号块中可以看到 nginx.conf ，这其实便是一个标准的 Nginx 目录结构，这也揭示了 Kong 其实就是运行在 Nginx 的基础之上，而进行的二次封装。由 share 文件夹向下展开下一次分析。 share 文件夹中包含了 OpenResty 的相关内容，其实背后就是一堆 Lua 脚本，例如 lapis 包含了数据库操作，Nginx 生命周期，缓存控制等必要的 Lua 脚本，logging 包含了日志相关的 Lua 脚本，resty 包含了 dns，健康检查等相关功能的 Lua 脚本…而其中的 kong 目录值得我们重点分析，他包含了 Kong 的核心对象。 api 和 core 文件夹，封装了 Kong 对 service，route，upstream，target 等核心对象的操作代码（这四个核心对象将会在下面的小节重点介绍），而 plugins 文件夹则是 Kong 高可扩展性的根源，存放了 kong 的诸多扩展功能。 plugins 文件夹包含了上一节提到的 Kong 的诸多插件功能，如权限控制插件，跨域插件，jwt 插件，auth2 插件…如果需要自定义插件，则需要将代码置于此处。 从上述文件夹浏览下来，大概可以看到它和 Nginx 的相似之处，并在此基础之上借助于 Lua 对自身的功能进行了拓展，除了 nginx.conf 中的配置，和相对固定的文件层级，Kong 还需要连接一个数据库来管理路由配置，服务配置，upstream 配置等信息，是的，由于 Kong 支持动态路由的特性，所以几乎所有动态的配置都不是配置在文件中，而是借助于 Postgres 或者 Cassandra 进行管理。 postgres Kong 对外暴露了 Restful API，最终的配置便是落地在了数据库之中。 Kong 的管理方式通过文件夹结构的分析，以及数据库中的表结构，我们已经对 Kong 的整体架构有了一个基本的认识，但肯定还存在一个疑问：我会配置 Nginx 来控制路由，但这个 Kong 应当怎么配置才能达到相同的目的呢？莫急，下面来看看 Kong 如何管理配置。 Kong 简单易用的背后，便是因为其所有的操作都是基于 HTTP Restful API 来进行的。 kong端点 其中 8000/8443 分别是 Http 和 Https 的转发端口，等价于 Nginx 默认的 80 端口，而 8001 端口便是默认的管理端口，我们可以通过 HTTP Restful API 来动态管理 Kong 的配置。 一个典型的 Nginx 配置 12345678910upstream helloUpstream &#123; server localhost:3000 weight=100;&#125;server &#123; listen 80; location /hello &#123; proxy_pass http://helloUpstream; &#125;&#125; 如上这个简单的 Nginx 配置，便可以转换为如下的 Http 请求。 对应的 Kong 配置 123456789# 配置 upstreamcurl -X POST http://localhost:8001/upstreams --data \"name=helloUpstream\"# 配置 targetcurl -X POST http://localhost:8001/upstreams/hello/targets --data \"target=localhost:3000\" --data \"weight=100\"# 配置 servicecurl -X POST http://localhost:8001/services --data \"name=hello\" --data \"host=helloUpstream\"# 配置 routecurl -X POST http://localhost:8001/routes --data \"paths[]=/hello\" --data \"service.id=8695cc65-16c1-43b1-95a1-5d30d0a50409\"curl -X POST http://localhost:8001/routes --data \"hosts[]=a.com,b.com,*.abc.com\" --data \"service.id=8695cc65-16c1-43b1-95a1-5d30d0a50409\" 这一切都是动态的，无需手动 reload nginx.conf。 我们为 Kong 新增路由信息时涉及到了 upstream，target，service，route 等概念，他们便是 Kong 最最核心的四个对象。（你可能在其他 Kong 的文章中见到了 api 这个对象，在最新版本 0.13 中已经被弃用，api 已经由 service 和 route 替代） 从上面的配置以及他们的字面含义大概能够推测出他们的职责，upstream 是对上游服务器的抽象；target 代表了一个物理服务，是 ip + port 的抽象；service 是抽象层面的服务，他可以直接映射到一个物理服务(host 指向 ip + port)，也可以指向一个 upstream 来做到负载均衡；route 是路由的抽象，他负责将实际的 request 映射到 service。 他们的关系如下 upstream 和 target ：1 对 n service 和 upstream ：1 对 1 或 1 对 0 （service 也可以直接指向具体的 target，相当于不做负载均衡） service 和 route：1 对 n 高可扩展性的背后—插件机制Kong 的另一大特色便是其插件机制，这也是我认为的 Kong 最优雅的一个设计。 文章开始时我们便提到一点，微服务架构中，网关应当承担所有服务共同需要的那部分功能，这一节我们便来介绍下，Kong 如何添加 jwt 插件，限流插件。 插件（Plugins）装在哪儿？对于部分插件，可能是全局的，影响范围是整个 Kong 服务；大多数插件都是装在 service 或者 route 之上。这使得插件的影响范围非常灵活，我们可能只需要对核心接口进行限流控制，只需要对部分接口进行权限控制，这时候，对特定的 service 和 route 进行定向的配置即可。 为 hello 服务添加50次/秒的限流 123curl -X POST http://localhost:8001/services/hello/plugins \\--data \"name=rate-limiting\" \\--data \"config.second=50\" 为 hello 服务添加 jwt 插件 12curl -X POST http://localhost:8001/services/login/plugins \\--data \"name=jwt\" 同理，插件也可以安装在 route 之上 123456curl -X POST http://localhost:8001/routes/&#123;routeId&#125;/plugins \\--data \"name=rate-limiting\" \\--data \"config.second=50\"curl -X POST http://localhost:8001/routes/&#123;routeId&#125;/plugins \\--data \"name=jwt\" 在官方文档中，我们可以获取全部的插件 https://konghq.com/plugins/，部分插件需要收费的企业版才可使用。 kong插件 总结Kong 是目前市场上相对较为成熟的开源 API 网关产品，无论是性能，扩展性，还是功能特性，都决定了它是一款优秀的产品，对 OpenResty 和 Lua 感兴趣的同学，Kong 也是一个优秀的学习参考对象。基于 OpenResty，可以在现有 Kong 的基础上进行一些扩展，从而实现更复杂的特性，比如我司内部的 ABTest 插件和定制化的认证插件，开发成本都相对较低。Kong 系列的文章将会在以后持续连载。 阅读扩展 初识 Kong 之负载均衡 https://www.cnkirito.moe/kong-loadbalance/ Kong 集成 Jwt 插件 https://www.cnkirito.moe/kong-jwt/","categories":[{"name":"API网关","slug":"API网关","permalink":"https://chengtong.me/categories/API网关/"}],"tags":[{"name":"Kong","slug":"Kong","permalink":"https://chengtong.me/tags/Kong/"}]},{"title":"Google正式开源Jib,帮助Java 应用快速容器化","slug":"Google正式开源Jib,帮助Java 应用快速容器化","date":"2018-07-11T13:21:53.000Z","updated":"2021-06-02T02:44:53.005Z","comments":true,"path":"posts/692c43b7.html","link":"","permalink":"https://chengtong.me/posts/692c43b7.html","excerpt":"","text":"一、简介Google 宣布开源一款新的 Java 工具 Jib ，旨在让开发者使用他们熟悉的工具更轻松地将 Java 应用程序容器化。 Google 软件工程师 Appu Goundan 和 Qingyang Chen 将 Jib 描述为一个容器镜像构建器，旨在处理将 Java 应用打包到容器中所涉及的所有步骤。 容器的出现让Java开发人员比以往任何时候都更接近“编写一次，到处运行”的工作流程，但要对Java应用程序进行容器化并非易事：你必须编写Dockerfile，以root身份运行Docker守护进程，等待构建完成，最后将镜像推送到远程注册中心。但并非所有的Java开发人员都是容器专家，像以前那样只需要构建一个JAR包的日子已经结束了吗？为了应对这一挑战，谷歌开源了一个Java容器化工具Jib，有了这个工具，Java开发人员可以使用他们熟悉的Java工具来构建容器。Jib是一个快速而简单的容器镜像构建工具，它负责处理将应用程序打包到容器镜像中所需的所有步骤。它不需要你编写Dockerfile或安装Docker，而且可以直接集成到Maven中，只需要将插件添加到构建中，就可以立即将 Java应用程序容器化。 二、Docker构建流程 三、Jib构建流程 四、Jib如何让开发变得更美好Jib利用了Docker镜像的分层机制，将其与构建系统集成，并通过以下方式优化 Java容器镜像的构建简单——Jib使用Java开发，并作为Maven的一部分运行。你不需要编写Dockerfile或运行Docker守护进程，甚至无需创建包含所有依赖的大JAR包。因为Jib与Java构建过程紧密集成，所以它可以访问到打包应用程序所需的所有信息。在后续的容器构建期间，它将自动选择Java构建过的任何变体。快速——Jib利用镜像分层和注册表缓存来实现快速、增量的构建。它读取你的构建配置，将你的应用程序组织到不同的层（依赖项、资源、类）中，并只重新构建和推送发生变更的层。在项目进行快速迭代时，Jib只讲发生变更的层（而不是整个应用程序）推送到注册表来节省宝贵的构建时间。可重现——Jib支持根据Maven的构建元数据进行声明式的容器镜像构建，因此，只要输入保持不变，就可以通过配置重复创建相同的镜像。 五、构建命令mvn clean compile jib:build(生成docker镜像并推送,注意镜像仓库为公网才可以，否则会失败) mvn clean compile jib:dockerBuild(生成docker镜像) 六、优缺点优点 无需编写Dockerfile，甚至无需安装docker 无需再执行docker build、push命令了 增量构建镜像，无需每次编译项目先打包jar 缺点 默认拉取的基础镜像是gcr仓库的，需要翻墙，并且jdk默认是openjdk 在拉取自定义的基础镜像和push构建的镜像这块，设计的不够友好，依赖需要第三方的加密组件(折腾了好一会)； 侵入性太强，需要每个项目都添加上maven插件。如果是现有方案，只需要添加一个Dockerfile就可以了，而且定制化高 只支持java平台","categories":[{"name":"容器","slug":"容器","permalink":"https://chengtong.me/categories/容器/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://chengtong.me/tags/Docker/"},{"name":"Jib","slug":"Jib","permalink":"https://chengtong.me/tags/Jib/"}]},{"title":"windows自启动脚本","slug":"windows自启动脚本","date":"2018-07-02T16:00:01.000Z","updated":"2020-05-23T12:43:24.032Z","comments":true,"path":"posts/b02d4ba7.html","link":"","permalink":"https://chengtong.me/posts/b02d4ba7.html","excerpt":"","text":"方法一1、 例如我们要开机自启动一个脚本：C:\\script\\script.bat。 如果直接开机启动该脚本会弹出一个黑框，我们希望能后台执行它。 此时我们需要建一个.vbs脚本来后台执行该脚本，脚本内容为：复制代码代码如下: set ws=WScript.CreateObject(“WScript.Shell”)ws.Run “C:\\script\\script.bat /start”,0 然后将该文件保存为start_list.vbs，放入“开始 –&gt; 所有程序 –&gt; 启动”内即可。 2、 打开运行对话框（win键+R），输入命令 shell:startup 会直接弹出启动项对应的目录，然后像前面方法一样把应用程序快捷方式复制到启动目录 让bat以管理员权限运行 有的电脑是非管理员登录，运行程序时，需要提示是否运行运行。解决方法如下： 1234@echo off%1 mshta vbscript:CreateObject(&quot;Shell.Application&quot;).ShellExecute(&quot;cmd.exe&quot;,&quot;/c %~s0 ::&quot;,&quot;&quot;,&quot;runas&quot;,1)(window.close)&amp;&amp;exit//在你的bat开头加上上面的命令即可//下面是你需要执行的命令 最后将用户账户控制（账户安全）调到最低 电脑——》属性——》安全和维护——》更改用户账户控制设置——》从不通知 方法二直接写一个普通批处理文件，如果是需要让它在系统启动时运行，就将它放在C:\\Windows\\System32\\GroupPolicy\\Machine\\Scripts\\Startup目录下， 如果是需要它在系统注销或关机时运行，就将它放在C:\\Windows\\System32\\Grouppolicy\\Machine\\Scripts\\Shutdown目录下。 放好之后就要进行指派。 单击“开始→运行”，在运行命令框中输入“gpedit.msc”，回车执行，打开“组策略”窗口。然后在组策略左侧的控制面板树窗格中，如图所示，依次展开“计算机配置→Windows设置→脚本（启动/关机）”节点，双击右侧详细资料窗格中的“启动”（或者“关机”）项目，在弹出的“启动属性”（“关机属性”）对话框中单击“添加”按钮，将你所写的批处理文件添加为新的计算机启动（关机）脚本。设置完成后，退出组策略窗口。以后启动（关闭）电脑时，相应命令会自动执行 开关机脚本除了支持.bat格式的批处理脚本文件以外，还支持.wsf、.vbs、.js格式的脚本文件","categories":[{"name":"Windows","slug":"Windows","permalink":"https://chengtong.me/categories/Windows/"}],"tags":[]},{"title":"Windows系统下.sh文件的运行","slug":"Windows系统下.sh文件的运行","date":"2018-07-01T16:00:01.000Z","updated":"2020-05-23T12:43:24.150Z","comments":true,"path":"posts/10802a0a.html","link":"","permalink":"https://chengtong.me/posts/10802a0a.html","excerpt":"","text":"好多的python/JAVA项目是用Linux系统下写的，为了省事就尝试了再Windows系统下运行，以下是运行的过程：1，Git的安装，下载Git并安装，我是在360软件管家中直接下载安装的，速度还不错，安装时一直点next就ok。安装成功后要对环境变量进行设置，如下图 2，在/Git/bin文件夹中，有三个exe文件 使用sh.exe出现窗口 3，文件运行使用cd 加文件名到需要运行的文件目录下（尽量文件名是英文，我有中文加英文的文件名一直显示无法识别，…\\scripts我的是然后输入`./pathfinder.sh concept_athletehomestadium或sh pathfinder.sh 运行结果就出来了 局部方式： 在idea中，打开.sh文件，会提示你安装插件，根据提示安装即可，在idea中使用即可。","categories":[{"name":"Windows","slug":"Windows","permalink":"https://chengtong.me/categories/Windows/"}],"tags":[]},{"title":"Win10设置右键以管理员方式打开cmd","slug":"Win10设置右键以管理员方式打开cmd","date":"2018-06-15T02:26:52.000Z","updated":"2020-12-07T04:37:04.882Z","comments":true,"path":"posts/72ac853a.html","link":"","permalink":"https://chengtong.me/posts/72ac853a.html","excerpt":"","text":"需求每次都要win+r-&gt;cmd然后cd到各种目录下执行命令，真是麻烦。shift+右键的powershell还没有默认管理员权限，真是够麻烦的。 这里直接想办法让右键出现以管理员方式打开的cmd窗口 效果右键效果打开后 设置步骤打开注册表12按win+r输入regedit打开注册表12 找到下面路径1HKEY_CLASSES_ROOT\\Directory\\Background\\shell\\1 我这边可以在上面快速输入这串路径，你可以试一试，不行你就一个个按目录点进去 新建项1在shell目录右键新建一个叫runas的项1 1在runas目录右键新建一个叫command的项1 更改值在runas上右键，新建一个DWORD32类型叫ShowBasedOnVelocityId的项目，填入值639bc8点到command里面，右键那个默认，填入 1cmd.exe /s /k pushd &quot;%V&quot;1 总结可以了，找个空白地方右键，就出现最开始的那个结果","categories":[{"name":"Windows","slug":"Windows","permalink":"https://chengtong.me/categories/Windows/"}],"tags":[{"name":"Windows10","slug":"Windows10","permalink":"https://chengtong.me/tags/Windows10/"}]},{"title":"CentOS7下Rsync+sersync实现数据实时同步","slug":"CentOS7下Rsync+sersync实现数据实时同步","date":"2018-06-08T15:30:00.000Z","updated":"2020-05-23T12:43:24.075Z","comments":true,"path":"posts/a15e2069.html","link":"","permalink":"https://chengtong.me/posts/a15e2069.html","excerpt":"","text":"一、为什么要用Rsync+sersync架构? sersync是基于Inotify开发的，类似于Inotify-tools的工具 sersync可以记录下被监听目录中发生变化的（包括增加、删除、修改）具体某一个文件或某一个目录的名字，然后使用rsync同步的时候，只同步发生变化的这个文件或者这个目录。 二、Rsync+Inotify-tools与Rsync+sersync这两种架构有什么区别？ Rsync+Inotify-tools （1）Inotify-tools只能记录下被监听的目录发生了变化（包括增加、删除、修改），并没有把具体是哪个文件或者哪个目录发生了变化记录下来； （2）rsync在同步的时候，并不知道具体是哪个文件或者哪个目录发生了变化，每次都是对整个目录进行同步，当数据量很大时，整个目录同步非常耗时（rsync要对整个目录遍历查找对比文件），因此，效率很低。 Rsync+sersync （1）sersync可以记录下被监听目录中发生变化的（包括增加、删除、修改）具体某一个文件或某一个目录的名字； （2）rsync在同步的时候，只同步发生变化的这个文件或者这个目录（每次发生变化的数据相对整个同步目录数据来说是很小的，rsync在遍历查找比对文件时，速度很快），因此，效率很高。 小结：当同步的目录数据量不大时，建议使用Rsync+Inotify-tools；当数据量很大（几百G甚至1T以上）、文件很多时，建议使用Rsync+sersync。 说明 操作系统：CentOS 7.0 源服务器：10.100.1.145 （Sersync+web）（Master 作为主发布服务器） 目标服务器： 10.100.1.96、10.100.1.99(Rsync+web)(此处可逐步增加集群的slave) 目的 把源服务器上/home/Sync目录实时同步到目标服务器的/home/Sync下 具体操作第一部分：分别在两台目标服务器10.100.1.96上操作在在目标服务器安装Rsync服务端1、关闭SELINUX 123456#vi /etc/selinux/config #编辑防火墙配置文件#SELINUX=enforcing#注释掉#SELINUXTYPE=targeted#注释掉SELINUX=disabled#增加:wq! #保存，退出setenforce 0 #立即生效 2、开启防火墙tcp 873端口（Rsync默认端口） 12345#vi /etc/sysconfig/iptables #编辑防火墙配置文件-A RH-Firewall-1-INPUT -m state --state NEW -m tcp -ptcp --dport 873 -j ACCEPT:wq! #保存退出#systemctl restart firewalld.service #最后重启防火墙使配置生效 3、安装Rsync服务端软件 1234567# yum install rsync xinetd #安装# vi /etc/rc.d/rc.local #设置开机启动/usr/bin/rsync --daemon --config=/etc/rsyncd.conf #同时在服务器上执行此命令:wq! #保存退出# chmod +x /etc/rc.d/rc.local #否则重启不执行 # systemctl start xinetd #启动（CentOS中是以xinetd来管理Rsync服务的） 4、创建rsyncd.conf配置文件 123456789101112131415161718192021#vi /etc/rsyncd.conf #创建配置文件，添加以下代码log file =/var/log/rsyncd.log #日志文件位置，启动rsync后自动产生这个文件，无需提前创建pidfile =/var/run/rsyncd.pid #pid文件的存放位置lock file =/var/run/rsync.lock #支持max connections参数的锁文件secretsfile = /etc/rsync.pass #用户认证配置文件，里面保存用户名称和密码，后面会创建这个文件motd file =/etc/rsyncd.Motd #rsync启动时欢迎信息页面文件位置（文件内容自定义）[Sync] #自定义名称path = /home/Sync/#rsync服务端数据目录路径comment = Sync#模块名称与[md]自定义名称相同uid = root #设置rsync运行权限为rootgid = root #设置rsync运行权限为rootport=873 #默认端口use chroot= no #默认为true，修改为no，增加对目录文件软连接的备份read only =no #设置rsync服务端文件为读写权限list = no #不显示rsync服务端资源列表maxconnections = 200 #最大连接数timeout =600 #设置超时时间auth users= Sync #执行数据同步的用户名，可以设置多个，用英文状态下逗号隔开hosts allow= 10.100.1.145 #允许进行数据同步的客户端IP地址，可以设置多个，用英文状态下逗号隔开hosts deny= 192.168.21.254 #禁止数据同步的客户端IP地址，可以设置多个，用英文状态下逗号隔开:wq! #保存,退出（贴进配置文件将中文去掉，否则可能造成无法识别模块） 5、创建用户认证文件 123#vi /etc/rsync.pass #配置文件，添加以下内容，添加允许传输用户和密码root:123456 #格式，用户名:密码，可以设置多个，每行一个用户名:密码:wq! #保存退出 6、设置文件权限 12#chmod 600 /etc/rsyncd.conf #设置文件所有者读取、写入权限#chmod 600 /etc/rsync.pass #设置文件所有者读取、写入权限 7、启动rsync 123# systemctl start xinetd #启动# systemctl stop xinetd #停止# systemctl restart xinetd #重新启动 第二部分：在源服务器10.100.1.145上操作一、安装Rsync客户端1、关闭SELINUX 123456#vi /etc/selinux/config #编辑防火墙配置文件#SELINUX=enforcing #注释掉#SELINUXTYPE=targeted #注释掉SELINUX=disabled #增加:wq! #保存退出#setenforce 0 #立即生效 2、开启防火墙tcp 873端口（Rsync默认端口，做为客户端的Rsync可以不用开启873端口） 1234#vi /etc/sysconfig/iptables #编辑防火墙配置文件-A RH-Firewall-1-INPUT -m state --state NEW -m tcp -ptcp --dport 873 -j ACCEPT:wq! #保存退出# systemctl restart firewalld.service #最后重启防火墙使配置生效 3、安装Rsync客户端端软件 12345678910111213141516171819202122232425#whereis rsync #查看系统是否已安装rsync,出现下面的提示，说明已经安装rsync:/usr/bin/rsync /usr/share/man/man1/rsync.1.gz#yum install xinetd #只安装xinetd即可，CentOS中是以xinetd来管理rsync服务的#yum install rsync xinetd #如果默认没有rsync，运行此命令进行安装rsync和xinetd# vi /etc/rc.local #设置开机启动/usr/bin/rsync --daemon #同时在服务器上启动此服务(运行此命令)# chmod +x /etc/rc.d/rc.local #否则重启不执行# vi /etc/rsyncd.conflog file = /var/log/rsyncd.logpidfile = /var/run/rsyncd.pidlock file = /var/run/rsync.lockmotd file = /etc/rsyncd.Motd[Sync]comment=Syncuid=rootgid=rootport=873path=/home/fastdfs/path0read only=nowrite only=yeslist=noauth_uses=rootsecrets file=/etc/passwd.txt:wq退出#systemctl start xinetd #启动（CentOS中是以xinetd来管理rsync服务的） 4、创建认证密码文件 1234#vi /etc/passwd.txt #编辑文件，添加以下内容，该密码应与目标服务器中的/etc/rsync.pass中的密码一致，123456 #密码:wq! #保存退出#chmod 600 /etc/passwd.txt #设置文件权限，只设置文件所有者具有读取、写入权限即可 5、测试源服务器10.100.1.145到目标服务器 10.100.1.96之间的数据同步 12#mkdir -p /home/Sync/ceshi #在源服务器上创建测试文件夹，然后在源服务器运行下面1行命令rsync -avH --port=873 --progress --delete /home/test/ root@10.100.1.145::Sync --password-file=/etc/passwd.txt 运行完成后，分别在目标服务器10.100.1.96上查看，在/home/Sync/目录下有ceshi文件夹，说明数据同步成功，命令中目录可以随意目录，传输到目标服务器目录时文件（或目录）均放到/etc/rsyncd.conf配置的服务器目录路径，如果源目录改变了，那么传输时两个目录将进行目录匹配，会有增删动作，因此需要注意。 二、安装sersync工具，实时触发rsync进行同步1、查看服务器内核是否支持inotify 1234ll /proc/sys/fs/inotify #列出文件目录，出现下面的内容，说明服务器内核支持inotify-rw-r--r-- 1 root root 0 Mar 7 02:17 max_queued_events-rw-r--r-- 1 root root 0 Mar 7 02:17 max_user_instances-rw-r--r-- 1 root root 0 Mar 7 02:17 max_user_watches 备注：Linux下支持inotify的内核最小为2.6.13，可以输入命令：#uname -a查看内核 CentOS 7.0内核为3.10.0，默认已经支持inotify 2、修改inotify默认参数（inotify默认内核参数值太小） 12345678910111213141516查看系统默认参数值：sysctl -a | grep max_queued_events结果是：fs.inotify.max_queued_events= 16384sysctl -a | grep max_user_watches结果是：fs.inotify.max_user_watches= 8192sysctl -a | grep max_user_instances结果是：fs.inotify.max_user_instances= 128修改参数：#sysctl -w fs.inotify.max_queued_events=&quot;99999999&quot;#sysctl -w fs.inotify.max_user_watches=&quot;99999999&quot;#sysctl -w fs.inotify.max_user_instances=&quot;65535&quot;#vi /etc/sysctl.conf #添加以下代码fs.inotify.max_queued_events=99999999fs.inotify.max_user_watches=99999999fs.inotify.max_user_instances=65535:wq! #保存退出 参数说明： max_queued_events： inotify队列最大长度，如果值太小，会出现” Event QueueOverflow “错误，导致监控文件不准确 max_user_watches： 要同步的文件包含多少目录，可以用：find /home/Sync-type d | wc -l 统计，必须保证max_user_watches值大于统计结果（这里/home/Sync为同步文件目录） max_user_instances： 每个用户创建inotify实例最大值 3、安装sersync sersync下载地址：https://sersync.googlecode.com/files/sersync2.5.4_64bit_binary_stable_final.tar.gz 上传sersync2.5.4_64bit_binary_stable_final.tar.gz到/usr/local/src目录下 123#cd /usr/local/src#tar -zxvf sersync2.5.4_64bit_binary_stable_final.tar.gz #解压#mv GNU-Linux-x86 /usr/local/sersync #移动目录到/usr/local/sersync 4、配置sersync 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667#cd /usr/local/sersync #进入sersync安装目录#cp confxml.xml confxml.xml-bak #备份原文件#vi confxml.xml #编辑，修改下面的代码&lt;?xmlversion=&quot;1.0&quot; encoding=&quot;ISO-8859-1&quot;?&gt;&lt;headversion=&quot;2.5&quot;&gt;&lt;host hostip=&quot;localhost&quot;port=&quot;8008&quot;&gt;&lt;/host&gt;&lt;debugstart=&quot;false&quot;/&gt;&lt;fileSystemxfs=&quot;false&quot;/&gt;&lt;filterstart=&quot;false&quot;&gt;&lt;excludeexpression=&quot;(.*)\\.svn&quot;&gt;&lt;/exclude&gt;&lt;excludeexpression=&quot;(.*)\\.gz&quot;&gt;&lt;/exclude&gt;&lt;excludeexpression=&quot;^info/*&quot;&gt;&lt;/exclude&gt;&lt;exclude expression=&quot;^static/*&quot;&gt;&lt;/exclude&gt;&lt;/filter&gt;&lt;inotify&gt;&lt;deletestart=&quot;true&quot;/&gt;&lt;createFolderstart=&quot;true&quot;/&gt;&lt;createFilestart=&quot;false&quot;/&gt;&lt;closeWritestart=&quot;true&quot;/&gt;&lt;moveFromstart=&quot;true&quot;/&gt;&lt;moveTostart=&quot;true&quot;/&gt;&lt;attribstart=&quot;false&quot;/&gt;&lt;modifystart=&quot;false&quot;/&gt;&lt;/inotify&gt;&lt;sersync&gt;&lt;localpath watch=&quot;***/home/Sync***&quot;&gt;&lt;remote ip=&quot;***10.100.1.96***&quot; name=&quot;***Sync***&quot;/&gt;&lt;!--&lt;remoteip=&quot;192.168.8.40&quot; name=&quot;tongbu&quot;/&gt;--&gt;&lt;!--&lt;remoteip=&quot;192.168.8.40&quot; name=&quot;tongbu&quot;/&gt;--&gt;&lt;/localpath&gt;&lt;rsync&gt;&lt;commonParams params=&quot;-artuz&quot;/&gt;&lt;auth start=&quot;true&quot; users=&quot;***root***&quot; passwordfile=&quot;***/etc/passwd.txt***&quot;/&gt;&lt;userDefinedPortstart=&quot;false&quot; port=&quot;874&quot;/&gt;&lt;!-- port=874 --&gt;&lt;timeoutstart=&quot;false&quot; time=&quot;100&quot;/&gt;&lt;!-- timeout=100 --&gt;&lt;sshstart=&quot;false&quot;/&gt;&lt;/rsync&gt;&lt;failLogpath=&quot;/tmp/rsync_fail_log.sh&quot; timeToExecute=&quot;60&quot;/&gt;&lt;!--defaultevery 60mins execute once--&gt;&lt;crontab start=&quot;***true***&quot; schedule=&quot;***600***&quot;&gt;&lt;!--600mins--&gt;&lt;crontabfilterstart=&quot;false&quot;&gt;&lt;excludeexpression=&quot;*.php&quot;&gt;&lt;/exclude&gt;&lt;excludeexpression=&quot;info/*&quot;&gt;&lt;/exclude&gt;&lt;/crontabfilter&gt;&lt;/crontab&gt;&lt;plugin start=&quot;false&quot;name=&quot;command&quot;/&gt;&lt;/sersync&gt;&lt;pluginname=&quot;command&quot;&gt;&lt;paramprefix=&quot;/bin/sh&quot; suffix=&quot;&quot;ignoreError=&quot;true&quot;/&gt; &lt;!--prefix /opt/tongbu/mmm.sh suffix--&gt;&lt;filterstart=&quot;false&quot;&gt;&lt;includeexpression=&quot;(.*)\\.php&quot;/&gt;&lt;includeexpression=&quot;(.*)\\.sh&quot;/&gt;&lt;/filter&gt;&lt;/plugin&gt;&lt;pluginname=&quot;socket&quot;&gt;&lt;localpathwatch=&quot;/opt/tongbu&quot;&gt;&lt;deshostip=&quot;192.168.138.20&quot; port=&quot;8009&quot;/&gt;&lt;/localpath&gt;&lt;/plugin&gt;&lt;pluginname=&quot;refreshCDN&quot;&gt;&lt;localpathwatch=&quot;/data0/htdocs/cms.xoyo.com/site/&quot;&gt;&lt;cdninfodomainname=&quot;ccms.chinacache.com&quot; port=&quot;80&quot;username=&quot;xxxx&quot; passwd=&quot;xxxx&quot;/&gt;&lt;sendurlbase=&quot;http://pic.xoyo.com/cms&quot;/&gt;&lt;regexurlregex=&quot;false&quot;match=&quot;cms.xoyo.com/site([/a-zA-Z0-9]*).xoyo.com/images&quot;/&gt;&lt;/localpath&gt;&lt;/plugin&gt;&lt;/head&gt;:wq! #保存退出 参数说明： localpath watch=”/home/Sync”：#源服务器同步目录 10.100.1.96：#目标服务器IP地址 name=”Sync”： #目标服务器rsync同步目录模块名称 users=”Sync”： #目标服务器rsync同步用户名 passwordfile=”/etc/passwd.pass”： #目标服务器rsync同步用户的密码在源服务器的存放路径 remote ip=”10.100.1.96”: #目标服务器ip，每行一个 failLogpath=”/tmp/rsync_fail_log.sh” #脚本运行失败日志记录 start=”true” #设置为true，每隔600分钟执行一次全盘同步 5、设置sersync监控开机自动执行 1234#vi /etc/rc.d/rc.local #编辑，在最后添加一行/usr/local/sersync/sersync2 -d -r -o /usr/local/sersync/confxml.xml ＃设置开机自动运行脚本:wq! #保存退出# chmod +x /etc/rc.d/rc.local #否则重启不执行 6、添加脚本监控sersync是否正常运行 12345678910111213141516171819#mkdir /home/crontab#vi /home/crontab/check_sersync.sh #编辑，添加以下代码#!/bin/shsersync=&quot;/usr/local/sersync/sersync2&quot;confxml=&quot;/usr/local/sersync/confxml.xml&quot;status=$(ps aux |grep &apos;sersync2&apos;|grep -v &apos;grep&apos;|wc -l)if [ $status -eq 0 ];then$sersync -d -r -o $confxml &amp;elseexit 0;fi:wq! #保存退出#chmod +x /home/crontab/check_sersync.sh#添加脚本执行权限#vi /etc/crontab #编辑，在最后添加下面一行*/5 * * * * root /home/crontab/check_sersync.sh &gt;/dev/null 2&gt;&amp;1 #每隔5分钟执行一次脚本*/1 * * * * root /home/crontab/check_sersync.sh &gt;/dev/null 2&gt;&amp;1#重新加载服务#systemctl restart crond.service 6、测试sersync实时触发rsync同步脚本是否正常运行 在源服务器10.100.1.145上创建文件inotify_rsync_ceshi 1# mkdir /home/Sync/inotify_rsync_ceshi 重新启动源服务器：10.100.1.145 等系统启动之后，查看两台目标服务器 10.100.1.96，10.100.1.99的/home/Sync下是否有inotify_rsync_ceshi文件夹 然后再在源服务器10.100.1.145创建文件夹inotify_rsync_ceshi_new 1# mkdir /home/Sync/inotify_rsync_ceshi_new 继续查看两台目标服务器 10.100.1.96，10.100.1.99的//home/Sync下是否有inotify_rsync_ceshi_new文件夹 如果以上测试都通过，说明inotify实时触发rsync同步脚本运行正常。 至此，Linux下Rsync+sersync实现数据实时同步完成。 扩展阅读： rsync参数 -v, –verbose 详细模式输出 -q, –quiet 精简输出模式 -c, –checksum 打开校验开关，强制对文件传输进行校验 -a, –archive 归档模式，表示以递归方式传输文件，并保持所有文件属性，等于-rlptgoD -r, –recursive 对子目录以递归模式处理 -R, –relative 使用相对路径信息 -b, –backup 创建备份，也就是对于目的已经存在有同样的文件名时，将老的文件重新命名为~filename。可以使用–suffix选项来指定不同的备份文件前缀。 –backup-dir 将备份文件(如~filename)存放在在目录下。 -suffix=SUFFIX 定义备份文件前缀 -u, –update 仅仅进行更新，也就是跳过所有已经存在于DST，并且文件时间晚于要备份的文件。(不覆盖更新的文件) -l, –links 保留软链结 -L, –copy-links 想对待常规文件一样处理软链结 –copy-unsafe-links 仅仅拷贝指向SRC路径目录树以外的链结 –safe-links 忽略指向SRC路径目录树以外的链结 -H, –hard-links 保留硬链结 -p, –perms 保持文件权限 -o, –owner 保持文件属主信息 -g, –group 保持文件属组信息 -D, –devices 保持设备文件信息 -t, –times 保持文件时间信息 -S, –sparse 对稀疏文件进行特殊处理以节省DST的空间 -n, –dry-run现实哪些文件将被传输 -W, –whole-file 拷贝文件，不进行增量检测 -x, –one-file-system 不要跨越文件系统边界 -B, –block-size=SIZE 检验算法使用的块尺寸，默认是700字节 -e, –rsh=COMMAND 指定使用rsh、ssh方式进行数据同步 –rsync-path=PATH 指定远程服务器上的rsync命令所在路径信息 -C, –cvs-exclude 使用和CVS一样的方法自动忽略文件，用来排除那些不希望传输的文件 –existing 仅仅更新那些已经存在于DST的文件，而不备份那些新创建的文件 –delete 删除那些DST中SRC没有的文件 –delete-excluded 同样删除接收端那些被该选项指定排除的文件 –delete-after 传输结束以后再删除 –ignore-errors 及时出现IO错误也进行删除 –max-delete=NUM 最多删除NUM个文件 –partial 保留那些因故没有完全传输的文件，以是加快随后的再次传输 –force 强制删除目录，即使不为空 –numeric-ids 不将数字的用户和组ID匹配为用户名和组名 –timeout=TIME IP超时时间，单位为秒 -I, –ignore-times 不跳过那些有同样的时间和长度的文件 –size-only 当决定是否要备份文件时，仅仅察看文件大小而不考虑文件时间 –modify-window=NUM 决定文件是否时间相同时使用的时间戳窗口，默认为0 -T –temp-dir=DIR 在DIR中创建临时文件 –compare-dest=DIR 同样比较DIR中的文件来决定是否需要备份 -P 等同于 –partial –progress 显示备份过程 -z, –compress 对备份的文件在传输时进行压缩处理 –exclude=PATTERN 指定排除不需要传输的文件模式 –include=PATTERN 指定不排除而需要传输的文件模式 –exclude-from=FILE 排除FILE中指定模式的文件 –include-from=FILE 不排除FILE指定模式匹配的文件 –version 打印版本信息 –address 绑定到特定的地址 –config=FILE 指定其他的配置文件，不使用默认的rsyncd.conf文件 –port=PORT 指定其他的rsync服务端口 –blocking-io 对远程shell使用阻塞IO -stats 给出某些文件的传输状态 –progress 在传输时现实传输过程 –log-format=formAT 指定日志文件格式 –password-file=FILE 从FILE中得到密码 –bwlimit=KBPS 限制I/O带宽，KBytes per second -h, –help 显示帮助信息","categories":[{"name":"Linux","slug":"Linux","permalink":"https://chengtong.me/categories/Linux/"}],"tags":[{"name":"CentOS","slug":"CentOS","permalink":"https://chengtong.me/tags/CentOS/"}]},{"title":"如何使用Lsyncd复制并实时同步到远程服务器","slug":"如何使用Lsyncd复制并实时同步到远程服务器","date":"2018-06-07T14:50:01.000Z","updated":"2020-05-23T12:43:24.053Z","comments":true,"path":"posts/9f424809.html","link":"","permalink":"https://chengtong.me/posts/9f424809.html","excerpt":"","text":"何为Lsyncd？ Lsyncd 官网 https://axkibe.github.io/ Lsyncd监视本地目录树事件监视器接口(inotify或fsevents)。它聚合并将事件组合在一起几秒钟，然后生成一个(或多个)进程来同步这些更改。默认情况下，由rsync实现同步。因此，Lsyncd是一种轻量级的实时镜像解决方案，相对容易安装，不需要新的文件系统或块设备，也不会妨碍本地文件系统的性能。 Rsync+ssh是一种高级操作配置，它使用ssh来执行文件和目录直接在目标上移动，而不是在线路上重新传输移动目标。细粒度的定制可以通过配置文件实现。自定义动作configs甚至可以从头编写，从shell脚本到Lua语言编写的代码。这种方法简单，强大，灵活的配置可以被解决。 Lsyncd 2.2.2要求在所有源和目标机器上rsync &gt;= 3.1。 系统环境： RenwoleServer：10.28.204.65 服务端RenwoleClient：10.28.204.66 客户端OS：CentOS Linux release 7.4.1708 (Core) x64 1.rsync的安装 请参阅：上一篇文章。 2.安装扩展依赖包 1$ yum install -y gcc gcc-c++ lua lua-devel cmake libxml2 libxml2-devel 3.源代码编译安装lsyncd 123456$ wget https://github.com/axkibe/lsyncd/archive/release-2.2.2.tar.gz$ tar xvf release-2.2.2.tar.gz$ cd lsyncd-release-2.2.2$ cmake -DCMAKE_INSTALL_PREFIX=/usr/local/lsyncd$ make &amp;&amp; make install$ ln -s /usr/local/lsyncd/bin/lsyncd /usr/bin/lsyncd 安装过程可能报错： 1-- Configuring incomplete, errors occurred! 安装lua-devel即可。 4.设置无密码SSH登录 因为这里使用rsyncssh进行同步，所以还需要配置root账号无密码ssh登录（略） 5.配置lsyncd 以下是三种常用配置案例 1.远程同步rsyncssh模式配置方案： 12345678910111213141516171819202122232425262728293031$ vim /etc/lsyncd.confsettings &#123; logfile = &quot;/var/log/lsyncd.log&quot;, --日志路径 statusFile = &quot;/var/log/lsyncd.status&quot;, --状态文件 pidfile = &quot;/var/run/lsyncd.pid&quot;, --pid文件路径 statusInterval = 1, --状态文件写入最短时间 nodaemon = false, --daemon运行 maxProcesses = 1, --最大进程 maxDelays = 1, --最大延迟&#125;sync &#123; default.rsyncssh, --默认rsync+ssh,rsync版本需要升级3以上版本 source = &quot;/apps/www/renwoleblog/&quot;, --源目录 delete = true, --保持完全同步 host = &quot;root@10.28.204.66&quot;, targetdir = &quot;/apps/www/renwoleblog/bak/&quot;, --目标目录 exclude=&#123; &quot;.txt&quot; --需排除的文件 &#125;,rsync = &#123; binary = &quot;/usr/bin/rsync&quot;, --需先安装好rsync archive = true, --归档 compress = false, --压缩 owner = true, --属主 perms = true, --权限 whole_file = false &#125;,ssh = &#123; port = 22 &#125;&#125; 2.本地目录同步配置方案： 12345sync &#123; default.rsync, source = &quot;/apps/www/renwoleblog/&quot;, target = &quot;/apps/www/renwoleblog/bak/&quot;,&#125; 3.远程同步rsync-daemon模式配置方案 123456789101112131415161718sync &#123; default.rsync, source = &quot;/apps/www/renwoleblog/&quot;, target = &quot;renwole@10.28.204.65::renwolecom&quot;, delete=&quot;true&quot;, exclude = &#123; &quot;.bak*&quot; &#125;, delay = 30, init = false, rsync = &#123; binary = &quot;/usr/bin/rsync&quot;, archive = true, compress = true, verbose = true, perms = true, password_file = &quot;/etc/rsync.password&quot;, _extra = &#123;&quot;--bwlimit=200&quot;&#125; &#125;&#125; 重点参数说明： 12345-- # 注释符settings # 是全局配置sync # 定义同步参数rsync # 定义同步文件参数ssh # 定义服务器远程端口 lsyncd配置文件允许多个sync互不影响。 说明：如果是一对多，请参阅本地同步，修改目标目录即可。 6.创建systemctl系统单元文件 为了实现systemctl进行管理，请创建配置文件以及脚本启动文件，命令如下： 1$ vim /etc/sysconfig/lsyncd 添加如下内容： 1LSYNCD_OPTIONS=&quot;/etc/lsyncd.conf&quot; 创建启动文件： 1$ vim /usr/lib/systemd/system/lsyncd.service 添加如下内容： 1234567891011[Unit]Description=Live Syncing (Mirror) DaemonAfter=network.target[Service]Type=simpleEnvironmentFile=-/etc/sysconfig/lsyncdExecStart=/usr/local/lsyncd/bin/lsyncd -nodaemon $LSYNCD_OPTIONS[Install]WantedBy=multi-user.target 7.启动lsyncd并加入开机自启动 12$ systemctl start lsyncd$ systemctl enable lsyncd 接下来你就可以往源服务器/apps/www/renwoleblog/内上传任意文件，完成后立刻就会同步到客户端 10.28.204.66 /apps/www/renwoleblog/bak/目录内，也可以查看服务端的lsyncd日志文件分析是否同步成功。例如： 1234567891011121314[root@RenwoleServer ~] $ cat /var/log/lsyncd.log...Fri Dec 22 01:19:22 2017 Normal: Calling rsync with filter-list of new/modified files/dirs/PCHunter_renwole.com.tar.gz/Fri Dec 22 01:19:24 2017 Normal: Finished (list): 0Fri Dec 22 01:19:32 2017 Normal: Calling rsync with filter-list of new/modified files/dirs/PCHunter_renwole.com.tar.gz/Fri Dec 22 01:19:34 2017 Normal: Finished (list): 0Fri Dec 22 01:19:34 2017 Normal: Calling rsync with filter-list of new/modified files/dirs/PCHunter_renwole.com.tar.gz/Fri Dec 22 01:19:36 2017 Normal: Finished (list): 0 日志内容显示PCHunter_renwole.com.rar文件成功同步。 另外lsyncd是基于inotify + rsync的开源同步软件，相对于其他同步软件更加安全可靠，占用资源更少，但配置略麻烦。lsyncd 还支持当监控到某个指定事件时就执行什么样的命令，由于是通过时间延迟和累计事件命中次数来触发同步，在设计上要优于inotify，另外他的同步速度完全取决于你的网络质量。","categories":[{"name":"Linux","slug":"Linux","permalink":"https://chengtong.me/categories/Linux/"}],"tags":[{"name":"CentOS","slug":"CentOS","permalink":"https://chengtong.me/tags/CentOS/"}]},{"title":"CentOS7配置Rsync数据文件同步服务器","slug":"CentOS7配置Rsync数据文件同步服务器","date":"2018-06-06T14:45:01.000Z","updated":"2020-05-23T12:43:23.929Z","comments":true,"path":"posts/a2a9a394.html","link":"","permalink":"https://chengtong.me/posts/a2a9a394.html","excerpt":"","text":"何为Rsync？ Rsync是一个非常灵活的命令行网络同步工具，由于它在Linux和类unix系统上的普及，使它被默认包含在大多数Linux发行版中。它在同步文件或文件夹的同时，可以保持原来文件的权限、时间、软硬链接等附加信息, 它可以快速安全的传输数据，并且支持增量更新，传输数据的过程中可以实行压缩及解压缩操作，因此可以使用更少的带宽，不仅如此它还是开源软件。 环境： RenwoleServer：10.28.204.65 服务端RenwoleClient：10.28.204.66 客户端OS：CentOS Linux release 7.4.1708 (Core) x64 1.分别在服务器端和客户端安装rsync 由于部分Linux发行版默认已安装rsync，但使用的版本 rsync 3.0.9-18.el7 有些旧，所以需手动安装最新版，请看以下具体操作： 2.安装rsync 如已默认安装，请卸载旧版本： 1$ yum remove rsync -y 安装rsync有2种方式： RPM方式的好处，快速、方便、节时，具体安装如下： 1234$ yum -y install epel-release$ wget http://mirror.ghettoforge.org/distributions/gf/gf-release-latest.gf.el7.noarch.rpm$ rpm -Uvh gf-release*rpm$ yum --enablerepo=gf-plus install rsync -y rsync文件： 123456/etc/rsyncd.conf/etc/sysconfig/rsyncd/etc/xinetd.d/rsync/usr/bin/rsync/usr/share/doc/rsync-3.1.2/COPYING...... 源码安装（推荐）： 此种安装方法的好处不但自定义方便，还可使用最新安装包。 安装依赖并下载源码包，编译安装： 12345678$ cd /tmp$ yum install gcc c++ -y$ wget https://download.samba.org/pub/rsync/rsync-3.1.2.tar.gz$ tar zxvf rsync-3.1.2.tar.gz$ cd rsync-3.1.2$ ./configure --prefix=/usr/local/rsync$ make -j8 &amp;&amp; make install$ ln -s /usr/local/rsync/bin/rsync /usr/bin/rsync 设置rsync自启动脚本 源码安装需手动将rsync默认提供的脚本拷贝到系统目录，这样才能使用systemctl管理： 1$ cp /tmp/rsync-3.1.2/packaging/systemd/* /usr/lib/systemd/system 说明：源代码编译安装，没有/etc/rsyncd.conf主配置文件，需要手动创建，RPM安装方式会自动生成，但都需要根据需求重新配置。 两种安装方式不管使用哪种方法都可以安装成功。 下面将介绍rsync配置篇（以源代码编译安装配置为例）。 3.关于rsync认证方式 rsync有2种常用的认证方式，一种是rsync-daemon，另一种是SSH。在生产环境中，通常使用rsync-daemon认证模式。 认证模式说明： 1.rsync-daemon认证：默认监听TCP的873端口。前提是双方都需要安装rsync，客户端可不启动rsync服务，但需要简单的配置。服务器端需要启动且需在服务器端配置rsync。 2.SSH认证：通过系统用户认证，即在rsync上通过SSH隧道进行传输，前提是需要服务器端与客户端建立无密码登录(略)。无需服务器与客户端配置rsync，也无需启动rsync服务，只需双方都安装rsync即可。 4.设置rsync服务端密码 10.28.204.65 本教程使用rsync-daemon认证方式。创建访问密码，格式为 用户名:密码，一行一个，明文。 12$ echo &quot;renwole:renwolecom&quot; &gt;&gt;/etc/rsync.password$ chmod 600 /etc/rsync.password 5.配置rsync服务端 10.28.204.65 配置完成后的内容如下： 12345678910111213141516171819202122232425262728293031$ cat /etc/rsyncd.confuid = root # 运行RSYNC守护进程的用户gid = root # 运行RSYNC守护进程的组port = 873 # 默认端口#address = 10.28.204.65 # 服务器IP地址# pid file = /var/run/rsyncd.pid # 进程启动后，进程号存放路径lock file = /var/run/rsync.lock # 设置锁文件名称log file = /var/log/rsyncd.log # 指定rsync的日志文件use chroot = no # 不使用chrootread only = yes # 只读,不让客户端上传文件到服务器transfer logging = yes # 将传输操作记录到传输日志文件hosts allow=10.28.204.66 # 允许哪些主机访问（多个以空格隔开）hosts deny=* # 拒绝哪些主机访问max connections = 3 # 最大连接数# motd file = /etc/rsyncd.motd # 登陆欢迎信息（生产环境不建议)log format = %t %a %m %f %b # 指定日志记录的格式syslog facility = local3 # 消息级别timeout = 600 # 会话超时时间。[renwolecom] # 模块的名称，可以自定义path = /apps/www # 需要同步的目录list=yes # 是否允许用户列出文件,默认为trueignore errors # 忽略错误信息# exclude = myrenwole/ # 不同步的目录（多个以空格隔开）comment = RenwoleCombak # 注释内容，任意auth users = renwole # 那些用户才允许连接该模块，多个以,隔开secrets file = /etc/rsyncs.pass # 认证时所需的密码文件 更多配置请参阅：http://www.gsp.com/cgi-bin/man.cgi?topic=rsyncd.conf 两个注意说明： 注意：如果你拷贝以上配置项，请去掉注释说明，否则可能会出现未知问题。注意：全局配置中的选项对所有模块有效；模块下定义的仅对当前模块有效；另外，模块中定义选项值优先于全局配置。 6.设置firewall防火墙 123$ firewall-cmd --add-port=873/tcp --permanent$ firewall-cmd --add-port=873/udp --permanent$ firewall-cmd --reload 7.配置rsync客户端 10.28.204.66 客户端无需配置模块，也无需启动服务，配置文件只需简单配置即可，例如： 1234567891011$ vim /etc/rsyncd.confuid = nobodygid = nobodyuse chroot = nomax connections = 10pid file = /var/run/rsyncd.pidlock file = /var/run/rsyncd.locklog file = /var/log/rsyncd.logport = 873secrets file = /etc/client.pass 8.在客户端设置密码 10.28.204.66 添加密码并设置权限： 12$ echo &quot;renwolecom&quot; &gt;&gt;/etc/client.pass$ chmod 600 /etc/client.pass 说明：只需添加服务端的密码即可，无需用户。 9.启动并加入开机自启动 123$ systemctl start rsync$ systemctl enable rsync$ systemctl list-unit-files 10.测试rsync文件同步 rsync客户端 10.28.204.66 连接服务端测试 1$ /usr/bin/rsync -avzrtopg --progress --delete --password-file=/etc/client.pass renwole@10.28.204.65::renwolecom /apps/www 客户端连接参数说明： -avzrtopg 拆分讲解： 12345678a # 归档模式，表示以递归方式传输文件，并保持所有文件属性，等于-rlptgoD;v # 详细模式输出;z # 对备份的文件在传输时进行压缩处理;r # 对子目录以递归模式处理;topg # 保持原文件属性如属主、时间的参数。--progress # 显示详细的同步进度情况。--delete # 若服务端端删除了这一文件，客户端也相应删除，保持文件一致。 更多参数请查看rsync帮助： 1$ /usr/bin/rsync -h 最后是问题总结 可能的报错信息： 1@ERROR: auth failed on module renwole 此报错有两种原因导致： 1.要么在服务端配置的用户密码不正确导致。2.要么就是服务器和客户端的密码文件不是600权限所致。 12rsync: failed to connect to 10.28.204.65 (10.28.204.65): No route to host (113)rsync error: error in socket IO (code 10) at clientserver.c(125) [Receiver=3.1.2] 此种无法连接到rsync服务端报错只有一种情况： 1.防火墙并未放行873端口或服务未启动，解决：关闭防火墙或放行端口即可。 启动如果报错，多看看日志，就知道解决的方法了。 如果你觉得配置比较麻烦，建议您使用lsyncd，此工具更好用，请参考下一篇。","categories":[{"name":"Linux","slug":"Linux","permalink":"https://chengtong.me/categories/Linux/"}],"tags":[{"name":"CentOS","slug":"CentOS","permalink":"https://chengtong.me/tags/CentOS/"}]},{"title":"Rsync文件同步","slug":"Rsync文件同步","date":"2018-06-05T14:30:01.000Z","updated":"2020-05-23T12:43:24.139Z","comments":true,"path":"posts/3871497a.html","link":"","permalink":"https://chengtong.me/posts/3871497a.html","excerpt":"","text":"一、本章结构 二、关于rsync1、介绍一款增量备份工具，remote sync,远程同步，支持本地复制或者与其他SSH、rsync主机同步，官方网站:http://rsync.samba.org/。 Rsync（remote synchronize）是一个远程数据同步工具，可通过LAN/WAN快速同步多台主机间的文件，也可以使用rsync同步本地硬盘中的不同目录。 Rsync是用户取代rcp的一个工具，Rsync使用所谓的”Rsync算法”来使本地和远程两个主机之间的文件达到同步，这个算法只传送两个文件的不同部分，而不是每次都整份传送，因此速度相当快，可以参考How Rsync A Practical Overview进一步了解Rsync的运作机制。 Rsync支持大多数的类Unix系统，无论是linux、solaris还是BSD上都经过了良好的测试，此外，它在windows平台下也有相应的版本，比较知名的有cwRsync和Sync2NAS。 2、特点（1）可以在不同主机间镜像同步整个目录树和文件系统 （2）可以很容易做到保持原来文件的权限、时间、软硬链接等 （3）支持增量备份 （3）无须特殊权限即可安装 （4）优化的同步算法，传输前执行压缩，文件传输效率高 （5）可以使用 rsh、ssh 方式来传输文件 （6）支持匿名传输，以方便进行网站镜象 3、同步源和发起源Rsync同步源：指备份操作的远程服务器，也称为备份源，主要包括两种：rsync源、ssh源 4、文件格式备份操作类型： 本地同步：rsync … 本地目录1 本地目录2 rsync+ssh同步： rsync … ssh源 本地目录 （下行同步即下载） rsync … 本地目录 ssh源 （上行同步即上传） rsync+rsync同步： rsync … rsync源 本地目录 （下行同步即下载） rsync … 本地目录 rsync源 （上行同步即上传） 5、rsync命令的用法基本格式：rsync [选项] 原始位置 目录位置 常用选项： -a：归档模式，递归并保留对象属性，等同于-rlptgoD -v:显示同步过程的详细(verbose)信息 -z：在传输文件时进行压缩(compress) -H：保留硬链接文件 -A：保留ACL属性信息 –delete:删除目标位置有而原始位置没有的文件 -r：递归模式，包含目录及子目录中所有文件 -l：对于符号链接文件仍然复制为符号链接文件 -p：保留文件的权限标记 -t：保留文件的时间标记 -g：保留文件的属组标记（仅超级用户使用） -o：保留文件的属主标记（仅超级用户使用） -D：保留设备文件及其他特殊文件 6、同步的优缺点①定期同步的不足 执行备份的时间固定 当同步源长期不变化时，密集的定期任务是不必要的 ②实时同步的优点 一旦出现源出现变化，立即启动备份 只要同步源无变化，则不执行备份 7、linux内核的inotify机制linux内核的inotify机制从版本2.6.13开始提供，可以监控文件系统的变动情况，并作出通知响应，辅助软件:inotify-tools 8、调整内核的参数max_queue_events:监控队列大小 max_user_instances:最多监控实例数 max_user_watches:每个实例最多监控文件数 9、安装inotify-tools辅助工具inotifywait:用于持续监控，实时输出结果 inotifywatch：用于短期监控，任务完成后再出结果 #inotifywait –mrq -e modify,create,move,delete /var/www/html 选项：-m (monitoring) 实时监控 -r (recursive) 递归 -q (quiet) 安静模式","categories":[{"name":"Linux","slug":"Linux","permalink":"https://chengtong.me/categories/Linux/"}],"tags":[{"name":"CentOS","slug":"CentOS","permalink":"https://chengtong.me/tags/CentOS/"}]},{"title":"Gogs灾备","slug":"Gogs灾备","date":"2018-06-04T13:30:01.000Z","updated":"2020-05-23T12:43:23.965Z","comments":true,"path":"posts/776caf5a.html","link":"","permalink":"https://chengtong.me/posts/776caf5a.html","excerpt":"","text":"在源代码版本管理工具的日常维护工作中，除了保证源代码仓库的正常运行以外，就是要对源代码进行备份，以免造成源代码的丢失，从而给企业带来重大经济损失。 这里，我们讲解一种全量备份的方法，来实现定时备份并压缩，并且支持过期删除。 备份： 1、服务器备份（自备）； 2、备份到另外一台服务器（远程备份） 系统环境：CentOS7.2 64位Gogs 原理与工具： putty工具 shell脚本crontab命令 服务器： Gogs服务(A主机)：10.2.12.32 另外一台服务器(B主机)：10.2.12.31 一、设置主机之间SSH免密登录。1、登录A主机，执行以下命令：ssh-keygen -t rsa #生成密钥文件过程中，遇到选择，按回车即可。可看到秘钥生成放在了/root/.ssh/目录下cd /root/.ssh/进入目录可以看到：id_rsa为私钥文件，id_rsa.pub为公钥文件2、在A主机执行以下命令，将公钥发送到B主机。（B主机也可以专门为备份创建一个bak用户）ssh-copy-id -i ~/.ssh/id_rsa.pub -p 22 root@10.2.12.31回车，输入B主机root用户的密码即可。3、在A主机输入以下命令，测试是否能免密登录B主机。ssh -p 22 root@10.2.12.31 二、备份脚本B主机 #mkdir -vp /home/bak/gogs/ A主机 vim /opt/script/bak/gogs.sh #!/bin/shSourceDirectory=/home/cd $SourceDirectoryif [ ! -d “source” ]; then mkdir sourcefitime=date +%Y%m%d%H%M%SfileName=gogs_$time.tar.gztar -czvf source/$fileName gogsfind ${SourceDirectory}/source -type f -mtime +7 -name “gogs_*.tar.gz” -exec rm -f {} \\; &gt; /dev/null 2&gt;&amp;1rsync -avz –delete $SourceDirectory/source/ root@10.2.12.31:/home/bak/gogs/ #添加执行权限 chmod +x /opt/script/bak/gogs.sh #执行脚本 sh /opt/script/bak/gogs.sh 三、定时任务：crontab -e输入你想启动的时间、脚本位置。下面命令为每天凌晨2点启动脚本00 02 * /opt/script/bak/gogs.shcrontab -l","categories":[{"name":"源代码版本管理工具","slug":"源代码版本管理工具","permalink":"https://chengtong.me/categories/源代码版本管理工具/"}],"tags":[{"name":"CentOS","slug":"CentOS","permalink":"https://chengtong.me/tags/CentOS/"},{"name":"Gogs","slug":"Gogs","permalink":"https://chengtong.me/tags/Gogs/"}]},{"title":"Centos RSync+Shell实现数据定时同步","slug":"Centos RSync+Shell实现数据定时同步","date":"2018-06-02T16:30:01.000Z","updated":"2020-05-23T12:43:24.082Z","comments":true,"path":"posts/5db798e8.html","link":"","permalink":"https://chengtong.me/posts/5db798e8.html","excerpt":"","text":"我们前面介绍了几篇关于Centos相关服务安装及配置，今天我们主要介绍如何实现本地与远程计算机的数据目录同步，在我之前bolg中有一篇通过shell实现本地与远程计算机的数据同步的文章，通过shell同步实现指定目录的复制及覆盖操作不是那么的方便，因为复制目录及覆盖目录只会增量，不会减量，比如：原来的本地有一个目录下的abc.txt被同步到了远程计算机的指定目录后，当本地目录下的abc.txt文件删除后，远程计算机同步目录下的abc.txt依然存在，所以这样导致数据信息不准确，今天了我们为了解决这样的问题，我们准备使用rsync+shell脚本进行定期数据同步。说到Rsync相信大家已经很熟悉了，但是很多文章中都介绍了，配置了Rsync server和rsync client的数据自动同步，这样结果当然好，但是对于服务配置上稍稍有点复杂，对于一个初学者来说还是有点难度，所以我们今天不准备配置rsync server 和rsync client实现自动同步，而是使用rsync client 和shell脚本定时同步数据，对于rsync server 和rsync client结合实现数据的双向同步我们下一篇文章中介绍；我们最最后再重申月一下Rsync 同步目录数据使用的SSH进行同步的；所以我们首先要将服务器之间的SSH服务互相通信，然后还需要注意一点是数据同步需要配置SSH-KEY，这样数据同步就无需输入密码了； 环境介绍：centos 7.2 + rsync + shell DB1：192.168.6.28 DB2： 192.168.6.38 环境需求：我们需要将DB1服务器上的指定目录下的文件定时同步到DB2服务器上的指定目录； 我们使用的是rsync服务进行数据同步，对于rsync有很多参数，具体见下： –help 选项 说明 -a,–archive 归档模式，表示以递归方式传输文件，并保持所有文件属性，等价于 -rlptgoD (注意不包括 -H) -r,–recursive 对子目录以递归模式处理 -l,–links 保持符号链接)文件 -H,–hard-links 保持硬链接文件 -p,–perms 保持文件权限 -t,–times 保持文件时间信息 -g,–group 保持文件属组信息 -o,–owner 保持文件属主信息 (super-user only) -D 保持设备文件和特殊文件 (super-user only) -z,–compress 在传输文件时进行压缩处理 –exclude=PATTERN 指定排除一个不需要传输的文件匹配模式 –exclude-from=FILE 从FILE中读取排除规则 –include=PATTERN 指定需要传输的文件匹配模式 –copy-unsafe-links 拷贝指向SRC路径目录树以外的链接文件 –safe-links 忽略指向SRC路径目录树以外的链接文件（默认） –existing 仅仅更新那些已经存在于接收端的文件，而不备份那些新创建的文件 –ignore-existing 忽略那些已经存在于接收端的文件，仅备份那些新创建的文件 -b,–backup 当有变化时，对目标目录中的旧版文件进行备份 –backup-dir=DIR 与-b结合使用，将备份的文件存到 DIR 目录中 –link-dest=DIR 当文件未改变时基于 DIR 创建硬链接文件 –delete 删除那些接收端还有而发送端已经不存在的文件 –delete-before 接收者在传输之前进行删除操作 (默认) –delete-during 接收者在传输过程中进行删除操作 –delete-after 接收者在传输之后进行删除操作 –delete-excluded 接收者在传输之后进行删除操作 -e,–rsh=COMMAND 指定替代 rsh 的 shell 程序 –ignore-errors 即使出现 I/O 错误也进行删除 –partial 保留那些因故没有完全传输的文件，以是加快随后的再次传输 –progress 在传输时显示传输过程 -P 等价于–partial–progress –delay-updates 将正在更新的文件先保存到一个临时目录（默认为 “.~tmp~”），待传输完毕再更新目标文件 -v,–verbose 详细输出模式 -q,–quiet 精简输出模式 -h,–human-readable 输出文件大小使用易读的单位（如，K，M等） -n,–dry-run 显示哪些文件将被传输 –list-only 仅仅列出文件而不进行复制 –rsync-path=PROGRAM 指定远程服务器上的 rsync 命令所在路径 –password-file=FILE 从 FILE 中读取口令，以避免在终端上输入口令，通常在 cron 中连接 rsync 服务器时使用 -4,–ipv4 使用 IPv4 -6,–ipv6 使用 IPv6 –version 打印版本信息 –help 显示帮助信息 一、安装rsync服务首先在DB1server上安装rsync client服务；DB1 server是源服务器 1yum install -y rsync 我们同时在DB2server也安装rsync服务； 1yum install -y rsync 二、配置key验证接下来我们需要配置key验证，因为数据同步我们不能使用密码验证后再传输同步数据，所以我们需要配置key认证，这样本地服务器与远程服务器之间同步就不需要密码验证了； 其实key验证我们前面的文章中已经有写了，为了方便在此还是说说。在源服务器上我们通过ssh-keygen生成一对验证秘钥，一个公钥，一个私钥；私钥放在远程服务器上即可，私钥需要公钥验证后才可以匹配，所以相对还是比较安全的； 1ssh-keygen -t rsa #回车； 123在/root/.ssh #目录下生成了一对密钥文件id_rsa #私钥id_rsa.pub #公钥 12ssh-copy-id ipaddressssh-copy-id 192.168.6.38 只在脚本执行的机器上或者源服务器上执行即可 会自动将公钥拷贝到目标服务器上； 到此我们就结束了key的配置； 如果提示以下错误的话，我们需要修改hosts reverse mapping checking getaddrinfo for bogon failed – POSSIBLE BREAK-IN ATTEMPT! 错误，但不影响登录。 原因：ssh 登录的时候会做一系列安全检查，其中有一项是 主机名与ip地址是否能解析，如果解析不了就会报这个错误。 解决方法：在/etc/hosts 文件加上对方的 ip地址 主机名，可以ping通主机名即可。 如果你有dns服务器 ，在服务器上做解析也行。总之，ping主机名必须解析到对应的ip地址； 三、创建数据同步目录；我们在DB1server上创建同步目录； 12mkdir SourceDirectory 创建目录cd SourceDirectory 进入目录 然后我们在SourceDirectory目录创建几个测试文件； vim 1.txt 1 然后我们在DB2server上创建target目标目录； 接下来我们就是数据同步了；我们在没有TargetDirectory目录下创建任何文件，当前目录下为空； 我们使用rsync命令实现DB1—&gt;DB2的数据同步； 执行“推”复制同步—-就是将本地/root/SourceDirectory目录下的数据远程同步到192.168.6.38服务器下的/root/TargetDirectory目录下； 注：如果目录结尾不加“/”的话，意思就成将该文件夹同步到目标目录了； 1synch -avz --delete /root/SourceDirectory/ root@192.168.6.38:/root/TargetDirectory/ 我们在目标服务器上查看同步的数据； 当然我们也可以实现拉的操作：执行“拉”复制同步—-就是将远程服务器192.168.6.38下的/root/TargetDirectory目录下的数据同步到本地/root/SourceDirectory目录下；数据远程同步到192.168.6.38服务器下的/root/TargetDirectory目录下 1rsync -avz --delete root@192.168.6.38:/root/TargetDirectory/ /root/SourceDirectory/ 我们先在DB2server上创建一个文件及编辑内容； vim 2.txt 2 接下来我们在DB1server上查看效果； 我们运行拉的操作命令 1rsync -avz --delete root@192.168.6.38:/root/TargetDirectory/ /root/SourceDirectory/ 然后我们查看执行结果；数据同步完成； 四、使用shell脚本定时同步数据；我们在创建一个sh文件，然后添加执行命令即可 123456789vim rsyncshell.sh#!/bin/shPush_Source=\"/root/SourceDirectory/\" Pull_Source=\"root@192.168.6.38:/root/TargetDirectory/\"Push_Target=\"root@192.168.6.38:/root/TargetDirectory/\" Pull_Target=\"root/SourceDirectory\"#rsync -avz --delete /root/SourceDirectory/ root@192.168.6.38:/root/TargetDirectory/ -----&gt;从本地“推”数据同步 rsync -avz --delete $Push_Source $Push_Target#rsync -avz --delete root@192.168.6.38:/root/TargetDirectory/ /root/SourceDirectory/ -----&gt;从远程“拉”数据同步 #rsync -avz --delete $Pull_Target $Pull_Sourceecho \"$(date +%Y-%m-%d_%H:%M:%S) -The Data Directoty:$Push_Source to $Push_Target had Sync Sucess\" &gt;&gt;/var/log/DataSync.log 我们给脚本赋予执行权限，再次 1chomd 700 rsyncshell.sh 我们测试一下脚本；首先我们编辑DB1Server上的数据目录 我们执行脚本 1./rsyncshell.sh 我们查看DB2serve上的目录结构 对了我们在参数中添加了一个delete参数；我们来演示一下效果； –delete参数的效果是当源目录中的文件和目标目录文件不统一时就会以源头为准，比如源目录下有1.txt\\2.txt\\3.txt，目标目录下有1.txt\\2.txt\\3.txt\\4.txt，当执行同步的时候，会以源目录为准，源目录没有4.txt，所以会删除目标目录下的4.txt文件。以达到数据统一的目的； 我们现在确认测试数据；DB1serve（源）同步目录有1.txt、2.txt、3.txt 同时更新源文件1.txt的内容； 目标服务器数据；DB2server(目标)同步目录有：1.txt、2.txt、3.txt、4.txt 同时确认目标服务器的1.txt文件内容； 所以当我们执行脚本，会将内文件内容及同步目录下的数据进行以源为准进行更新 执行结果：DB2目标服务器的4.txt文件删除，1.txt文件内容以源服务器上的1.txt文件内容为准进行更新 执行脚本；结果我们已经看见了； 具体我们查看DB2server上的目录结构及文件内容 因为脚本内定义了日志记录，所以我们可以查看log 1cat /var/log/DataSync.log 五、使用计划任务进行脚本运行； 我们前面已经介绍了linux中使用 crontab 进行定义计划任务 linux上计划任务的命令为crontab ，通过后面的参数即可配置；我们可以通过man crontab查看相关帮助。 ** -e：编辑某个用户的crontab文件内容。如果不指定用户，则表示编辑当前用户的crontab文件。 ** -l：显示某个用户的crontab文件内容，如果不指定用户，则表示显示当前用户的crontab文件内容。 ** -r：从/var/spool/cron目录中删除某个用户的crontab文件，如果不指定用户，则默认删除当前用户的crontab文件。 ** -i：在删除用户的crontab文件时给确认提示。 同样：crontal 的参数格式为 * 一个 * 一小时当中的第几分钟 0-59 第二个 * 一天当中的第几个小时 0-23 第三个 * 一个月当中的第几天 1-31 第四个 * 一年当中的第几个月 1-12 第五个 * 一周当中的星期几 1-7 我们确认脚本存放路径 1/root/shell/ 1crondtal –e 编辑计划任务 每天晚上22:30执行一次 1crontal –l 查看计划任务 因为我们脚本内添加了log记录，所以我们可以查看对应的log，查看是否执行成功 cat /var/log/DataSync.log","categories":[{"name":"Linux","slug":"Linux","permalink":"https://chengtong.me/categories/Linux/"}],"tags":[{"name":"CentOS","slug":"CentOS","permalink":"https://chengtong.me/tags/CentOS/"},{"name":"Shell","slug":"Shell","permalink":"https://chengtong.me/tags/Shell/"}]},{"title":"CentOS7 MySQL自动备份shell脚本","slug":"CentOS7 MySQL自动备份shell脚本","date":"2018-06-01T16:01:01.000Z","updated":"2020-05-23T12:43:24.130Z","comments":true,"path":"posts/ff3ad289.html","link":"","permalink":"https://chengtong.me/posts/ff3ad289.html","excerpt":"","text":"在数据库的日常维护工作中，除了保证业务的正常运行以外，就是要对数据库进行备份，以免造成数据库的丢失，从而给企业带来重大经济损失。 通常备份可以按照备份时数据库状态分为热备和冷备，按照备份数据库文件的大小分为增量备份、差异备份和全量备份。 这里，我们讲解一种全量备份的方法，来实现定时备份数据到mysql脚本文件，并且支持过期删除。 系统环境：CentOS7 64位 Minimal版（VMware）MySQL5.6 原理与工具：shell脚本mysqldump程序crontab命令 1、新建shell脚本1vi /opt/mysqlBackup.sh 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273#!/bin/bash# 以下配置信息请自己修改mysql_user=\"USER\" #MySQL备份用户mysql_password=\"PASSWORD\" #MySQL备份用户的密码mysql_host=\"localhost\"mysql_port=\"3306\"mysql_charset=\"utf8\" #MySQL编码backup_db_arr=(\"db1\" \"db2\") #要备份的数据库名称，多个用空格分开隔开 如(\"db1\" \"db2\" \"db3\")backup_location=/opt/mysql #备份数据存放位置，末尾请不要带\"/\",此项可以保持默认，程序会自动创建文件夹expire_backup_delete=\"ON\" #是否开启过期备份删除 ON为开启 OFF为关闭expire_days=3 #过期时间天数 默认为三天，此项只有在expire_backup_delete开启时有效# 本行开始以下不需要修改backup_time=`date +%Y%m%d%H%M` #定义备份详细时间backup_Ymd=`date +%Y-%m-%d` #定义备份目录中的年月日时间backup_3ago=`date -d '3 days ago' +%Y-%m-%d` #3天之前的日期backup_dir=$backup_location/$backup_Ymd #备份文件夹全路径welcome_msg=\"Welcome to use MySQL backup tools!\" #欢迎语# 判断MYSQL是否启动,mysql没有启动则备份退出mysql_ps=`ps -ef |grep mysql |wc -l`mysql_listen=`netstat -an |grep LISTEN |grep $mysql_port|wc -l`if [ [$mysql_ps == 0] -o [$mysql_listen == 0] ]; then echo \"ERROR:MySQL is not running! backup stop!\" exitelse echo $welcome_msgfi# 连接到mysql数据库，无法连接则备份退出mysql -h$mysql_host -P$mysql_port -u$mysql_user -p$mysql_password &lt;&lt;enduse mysql;select host,user from user where user='root' and host='localhost';exitendflag=`echo $?`if [ $flag != \"0\" ]; then echo \"ERROR:Can't connect mysql server! backup stop!\" exitelse echo \"MySQL connect ok! Please wait......\" # 判断有没有定义备份的数据库，如果定义则开始备份，否则退出备份 if [ \"$backup_db_arr\" != \"\" ];then #dbnames=$(cut -d ',' -f1-5 $backup_database) #echo \"arr is ($&#123;backup_db_arr[@]&#125;)\" for dbname in $&#123;backup_db_arr[@]&#125; do echo \"database $dbname backup start...\" `mkdir -p $backup_dir` `mysqldump -h$mysql_host -P$mysql_port -u$mysql_user -p$mysql_password $dbname --default-character-set=$mysql_charset | gzip &gt; $backup_dir/$dbname-$backup_time.sql.gz` flag=`echo $?` if [ $flag == \"0\" ];then echo \"database $dbname success backup to $backup_dir/$dbname-$backup_time.sql.gz\" else echo \"database $dbname backup fail!\" fi done else echo \"ERROR:No database to backup! backup stop\" exit fi # 如果开启了删除过期备份，则进行删除操作 if [ \"$expire_backup_delete\" == \"ON\" -a \"$backup_location\" != \"\" ];then #`find $backup_location/ -type d -o -type f -ctime +$expire_days -exec rm -rf &#123;&#125; \\;` `find $backup_location/ -type d -mtime +$expire_days | xargs rm -rf` echo \"Expired backup data delete complete!\" fi echo \"All database backup success! Thank you!\" exitfi 注意：如果这个sh文件是在win下编辑的，需要用编辑器转换为unix格式，否则sh会执行不成功，如图： 2、修改shell脚本属性，赋予执行权限12chmod 600 /opt/mysqlBackup.shchmod +x /opt/mysqlBackup.sh 3、定时执行脚本方式一执行crontab -e命令 1crontab -e 输入以下内容，设置每天凌晨3:00定时自动备份 100 03 * * * /opt/mysqlBackup.sh 方式二打开自动执行文件 1vi /etc/crontab 在etc中加入如下内容，让其每天凌晨3:00自动执行任务。 100 03 * * * /opt/mysqlBackup.sh crontab文件概要： 用户所建立的crontab文件中，每一行都代表一项任务，每行的每个字段代表一项设置，它的格式共分为六个字段，前五段是时间设定段，第六段是要执行的命令段，格式如下： minute hour day month week command 分 时 日 月 周 命令 其中： minute： 表示分钟，可以是从0到59之间的任何整数。（每分钟可用或者/1表示） hour：表示小时，可以是从0到23之间的任何整数。（0表示0点） day：表示日期，可以是从1到31之间的任何整数。 month：表示月份，可以是从1到12之间的任何整数。 week：表示星期几，可以是从0到7之间的任何整数，这里的0或7代表星期日。 command：要执行的命令，可以是系统命令，也可以是自己编写的脚本文件。 在以上各个字段中，还可以使用以下特殊字符： 星号（）：代表所有可能的值，例如month字段如果是星号，则表示在满足其它字段的制约条件后每月都执行该命令操作。 逗号（,）：可以用逗号隔开的值指定一个列表范围，例如，“1,2,5,7,8,9” 中杠（-）：可以用整数之间的中杠表示一个整数范围，例如“2-6”表示“2,3,4,5,6” 正斜线（/）：可以用正斜线指定时间的间隔频率，例如“0-23/2”表示每两小时执行一次。同时正斜线可以和星号一起使用，例如/10，如果用在minute字段，表示每十分钟执行一次。 crontab 定时执行的日志记录在/var/spool/mail/root中，可查看日志记录 1vi /var/spool/mail/root 4、MySQL恢复1mysql -u username -p databse &lt; backup.sql","categories":[{"name":"数据库","slug":"数据库","permalink":"https://chengtong.me/categories/数据库/"}],"tags":[{"name":"CentOS","slug":"CentOS","permalink":"https://chengtong.me/tags/CentOS/"},{"name":"MySQL","slug":"MySQL","permalink":"https://chengtong.me/tags/MySQL/"}]},{"title":"解决保存的csdn网页自动跳转到首页问题","slug":"解决保存的csdn网页自动跳转到首页问题","date":"2018-06-01T04:50:26.000Z","updated":"2020-07-28T09:21:27.733Z","comments":true,"path":"posts/d521c8fb.html","link":"","permalink":"https://chengtong.me/posts/d521c8fb.html","excerpt":"","text":"不知道csdn出于什么考虑，保存网页到本地打开会自动跳转到首页 步骤搜索关键词onerror，找到对应代码。 方法1(修改跳转时间)将跳转时间3000更改为更大数字即可。 方法2(删除以下代码)12&lt;IMG onerror='setTimeout(function()&#123;if(!/(csdn.net|iteye.com|baiducontent.com|googleusercontent.com|360webcache.com|sogoucdn.com|bingj.com|baidu.com)$/.test(window.location.hostname))&#123;window.location.href=\"\\x68\\x74\\x74\\x70\\x73\\x3a\\x2f\\x2f\\x77\\x77\\x77\\x2e\\x63\\x73\\x64\\x6e\\x2e\\x6e\\x65\\x74\"&#125;&#125;,3000);' src=\"\"&gt;","categories":[],"tags":[]},{"title":"CentOS7修改时区","slug":"CentOS7修改时区","date":"2018-05-31T16:00:01.000Z","updated":"2020-05-23T12:43:23.949Z","comments":true,"path":"posts/5e11aa60.html","link":"","permalink":"https://chengtong.me/posts/5e11aa60.html","excerpt":"","text":"时钟概念 （1）UTC 整个地球分为二十四时区，每个时区都有自己的本地时间。在国际无线电通信场合，为了统一起见，使用一个统一的时间，称为通用协调时(UTC,Universal Time Coordinated)。 （2）GMT 格林威治标准时间 (Greenwich Mean Time)指位于英国伦敦郊区的皇家格林尼治天文台的标准时间，因为本初子午线被定义在通过那里的经线。(UTC与GMT时间基本相同，本文中不做区分) （3）CST 中国标准时间 (China Standard Time)【GMT + 8 = UTC + 8 = CST】 （4）DST 夏令时(Daylight Saving Time) 指在夏天太阳升起的比较早时，将时钟拨快一小时，以提早日光的使用。（中国不使用） 硬件时钟： RTC(Real-Time Clock)或CMOS时钟，一般在主板上靠电池供电，服务器断电后也会继续运行。仅保存日期时间数值，无法保存时区和夏令时设置。 系统时钟： 一般在服务器启动时复制RTC时间，之后独立运行，保存了时间、时区和夏令时设置。 在CentOS 6版本，时间设置有date、hwclock命令，从CentOS 7开始，使用了一个新的命令timedatectl。 Centos7 修改系统时区timezone ，解决快、慢8小时问题 如果服务器用非 UTC 的时间，时区转换很容易不一致，而且对于有 daylight saving 的时区，每年多一小时少一小时的那两天，系统就会出现各种诡异现象。 #timedatectl set-ntp yes 方法一#mv /etc/localtime /etc/localtime.bak #ln -s /usr/share/zoneinfo/Asia/Shanghai /etc/localtime #dateTue Jun 11 10:16:01 CST 2019 方法二#timedatectl # 查看系统时间方面的各种状态 #timedatectl list-timezones # 列出所有时区 #timedatectl set-timezone Asia/Shanghai # 设置系统时区为上海 #timedatectl Local time: Tue 2019-06-11 10:20:16 CST Universal time: Tue 2019-06-11 02:20:16 UTC RTC time: Tue 2019-06-11 10:20:16 Time zone: Asia/Shanghai (CST, +0800) NTP enabled: yesNTP synchronized: yes RTC in local TZ: no DST active: n/a #date","categories":[{"name":"Linux","slug":"Linux","permalink":"https://chengtong.me/categories/Linux/"}],"tags":[{"name":"CentOS","slug":"CentOS","permalink":"https://chengtong.me/tags/CentOS/"}]},{"title":"Could not create connection to database server","slug":"Could not create connection to database server","date":"2018-05-25T16:00:01.000Z","updated":"2020-05-23T12:43:23.960Z","comments":true,"path":"posts/4874470d.html","link":"","permalink":"https://chengtong.me/posts/4874470d.html","excerpt":"","text":"MySQLNonTransientConnectionException: Could not create connection to database server. Spring整合mybatis并使用driud数据库连接池，启动测试类就报”MySQLNonTransientConnectionException: Could not create connection to database server.“，检查了一番配置文件没发现问题，而且我之前用过这些配置，按理说没问题。各种百度、谷歌没结果，想起来装了mysql 8.0，估计是这个问题。既然是这个问题，那么问题出在数据库连接驱动，看了下pom文件，发现用的是5.1.4版本，于是找了个8.0.11版本重新启动，果然报错就不一样了。 122018-05-26 16:52:53,928 [Druid-ConnectionPool-Create-1150963491] [com.alibaba.druid.pool.DruidDataSource]-[ERROR] create connection errorjava.sql.SQLException: validateConnection false 另外在控制台上还打印了”Loading class com.mysql.jdbc.Driver&#39;. This is deprecated. The new driver class iscom.mysql.cj.jdbc.Driver’. The driver is automatically registered via the SPI and manual loading of the driver class is generally unnecessary.“，意思是这个驱动类已经过时了，那只能说明MySQL 8.0使用的数据库连接字符串不一样。改完后重新启动搞定。 需要说明的是mysql 8.0版本还对时区有要求，否则启动提示”The server time zone value ‘ÖÐ¹ú±ê×¼Ê±¼ä’ is unrecognized or represents more than one time zone. You must configure either the server or JDBC driver (via the serverTimezone configuration property) to use a more specifc time zone value if you want to utilize time zone support.“ 贴一下连接字符串 12url: jdbc:mysql://localhost:3306/demo?characterEncoding=utf8&amp;useSSL=false&amp;serverTimezone=UTC&amp;rewriteBatchedStatements=truedriver: com.mysql.cj.jdbc.Driver","categories":[],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://chengtong.me/tags/MySQL/"}]},{"title":"Dubbo和Spring Cloud微服务架构比较","slug":"Dubbo和Spring Cloud微服务架构比较","date":"2018-05-25T11:56:19.000Z","updated":"2020-05-23T12:43:24.223Z","comments":true,"path":"posts/205f180b.html","link":"","permalink":"https://chengtong.me/posts/205f180b.html","excerpt":"","text":"Dubbo 出生于阿里系，是阿里巴巴服务化治理的核心框架，并被广泛应用于中国各互联网公司；只需要通过 Spring 配置的方式即可完成服务化，对于应用无入侵，设计的目的还是服务于自身的业务为主。 微服务架构是互联网很热门的话题，是互联网技术发展的必然结果。它提倡将单一应用程序划分成一组小的服务，服务之间互相协调、互相配合，为用户提供最终价值。 虽然微服务架构没有公认的技术标准和规范或者草案，但业界已经有一些很有影响力的开源微服务架构框架提供了微服务的关键思路，例如 Dubbo 和 Spring Cloud。 各大互联网公司也有自研的微服务框架，但其模式都与这二者相差不大。 微服务主要的优势 降低复杂度 将原来耦合在一起的复杂业务拆分为单个服务，规避了原本复杂度无止境的积累。 每一个微服务专注于单一功能，并通过定义良好的接口清晰表述服务边界；每个服务开发者只专注服务本身，通过使用缓存、DAL 等各种技术手段来提升系统的性能，而对于消费方来说完全透明。 可独立部署 由于微服务具备独立的运行进程，所以每个微服务可以独立部署。当业务迭代时只需要发布相关服务的迭代即可，降低了测试的工作量同时也降低了服务发布的风险。 容错 在微服务架构下，当某一组件发生故障时，故障会被隔离在单个服务中。比如通过限流、熔断等方式降低错误导致的危害，保障核心业务正常运行。 扩展 单块架构应用也可以实现横向扩展，就是将整个应用完整的复制到不同的节点。 当应用的不同组件在扩展需求上存在差异时，微服务架构便体现出其灵活性，因为每个服务可以根据实际需求独立进行扩展。 本文主要围绕微服务的技术选型、通讯协议、服务依赖模式、开始模式、运行模式等几方面来综合比较 Dubbo 和 Spring Cloud 这 2 种开发框架。 架构师可以根据公司的技术实力并结合项目的特点来选择某个合适的微服务架构平台，以此稳妥地实施项目的微服务化改造或开发进程。 核心部件 微服务的核心要素在于服务的发现、注册、路由、熔断、降级、分布式配置，基于上述几种必要条件对 Dubbo 和 Spring Cloud 做出对比。 总体架构 Dubbo 核心部件（如下图）: Provider：暴露服务的提供方，可以通过 jar 或者容器的方式启动服务。 Consumer：调用远程服务的服务消费方。 Registry：服务注册中心和发现中心。 Monitor：统计服务和调用次数，调用时间监控中心。（Dubbo 的控制台页面中可以显示，目前只有一个简单版本。） Container：服务运行的容器。 Dubbo 总体架构 Spring Cloud总体架构（如下图）： Service Provider： 暴露服务的提供方。 Service Consumer：调用远程服务的服务消费方。 EureKa Server： 服务注册中心和服务发现中心。 Spring Cloud 总体架构 点评：从整体架构上来看，二者模式接近，都需要服务提供方，注册中心，服务消费方。 微服务架构核心要素 Dubbo 只是实现了服务治理，而 Spring Cloud 子项目分别覆盖了微服务架构下的众多部件，服务治理只是其中的一个方面。 Dubbo 提供了各种 Filter，对于上述中“无”的要素，可以通过扩展 Filter 来完善。例如： 分布式配置：可以使用淘宝的 diamond、百度的 disconf 来实现分布式配置管理。 服务跟踪：可以使用京东开源的 Hydra，或者扩展 Filter 用 Zippin 来做服务跟踪。 批量任务：可以使用当当开源的 Elastic-Job、tbschedule。 点评：从核心要素来看，Spring Cloud 更胜一筹，在开发过程中只要整合 Spring Cloud 的子项目就可以顺利的完成各种组件的融合，而 Dubbo 却需要通过实现各种 Filter 来做定制，开发成本以及技术难度略高。 通讯协议 基于通讯协议层面对 2 种框架支持的协议类型以及运行效率方面进行比较。 支持协议 Dubbo Dubbo 使用 RPC 通讯协议，提供序列化方式如下： Dubbo：Dubbo 缺省协议采用单一长连接和 NIO 异步通讯，适合于小数据量大并发的服务调用，以及服务消费者机器数远大于服务提供者机器数的情况。 RMI：RMI 协议采用 JDK 标准的 java.rmi.* 实现，采用阻塞式短连接和 JDK 标准序列化方式。 Hessian：Hessian 协议用于集成 Hessian 的服务，Hessian 底层采用 HTTP 通讯，采用 Servlet 暴露服务，Dubbo 缺省内嵌 Jetty 作为服务器实现。 HTTP：采用 Spring 的 Http Invoker 实现。 Webservice：基于 CXF 的 frontend-simple 和 transports-http 实现。 Spring Cloud Spring Cloud 使用 HTTP 协议的 REST API。 性能比较 使用一个 Pojo 对象包含 10 个属性，请求 10 万次，Dubbo 和 Spring Cloud 在不同的线程数量下，每次请求耗时（ms）如下： 说明：客户端和服务端配置均采用阿里云的 ECS 服务器，4 核 8G 配置，Dubbo 采用默认的 Dubbo 协议。 点评：Dubbo 支持各种通信协议，而且消费方和服务方使用长链接方式交互，通信速度上略胜 Spring Cloud，如果对于系统的响应时间有严格要求，长链接更合适。 服务依赖方式 Dubbo 服务提供方与消费方通过接口的方式依赖，服务调用设计如下： Interface 层：服务接口层，定义了服务对外提供的所有接口。 Molel 层：服务的 DTO 对象层。 Business层：业务实现层，实现 Interface 接口并且和 DB 交互。 因此需要为每个微服务定义各自的 Interface 接口，并通过持续集成发布到私有仓库中。调用方应用对微服务提供的抽象接口存在强依赖关系，开发、测试、集成环境都需要严格的管理版本依赖。 通过 maven 的 install &amp; deploy 命令把 Interface 和 Model 层发布到仓库中，服务调用方只需要依赖 Interface 和 Model 层即可。 在开发调试阶段只发布 Snapshot 版本，等到服务调试完成再发布 Release 版本，通过版本号来区分每次迭代的版本。通过 xml 配置方式即可接入 Dubbo，对程序无入侵。 Dubbo 接口依赖方式 Spring Cloud 服务提供方和服务消费方通过 Json 方式交互，因此只需要定义好相关 Json 字段即可，消费方和提供方无接口依赖。通过注解方式来实现服务配置，对于程序有一定入侵。 点评：Dubbo 服务依赖略重，需要有完善的版本管理机制，但是程序入侵少。 而 Spring Cloud 通过 Json 交互，省略了版本管理的问题，但是具体字段含义需要统一管理，自身 Rest API 方式交互，为跨平台调用奠定了基础。 组件运行流程 Dubbo 下图中的每个组件都是需要部署在单独的服务器上，Gateway 用来接受前端请求、聚合服务，并批量调用后台原子服务。每个 Service 层和单独的 DB 交互。 Dubbo 组件运行流程 Dubbo 组件运行： Gateway：前置网关，具体业务操作，Gateway 通过 Dubbo 提供的负载均衡机制自动完成。 Service：原子服务，只提供该业务相关的原子服务。 Zookeeper：原子服务注册到 ZK 上。 Spring Cloud 组件运行 Spring Cloud Spring Cloud组件运行： 所有请求都统一通过 API 网关（Zuul）来访问内部服务。 网关接收到请求后，从注册中心（Eureka）获取可用服务。 由 Ribbon 进行均衡负载后，分发到后端的具体实例。 微服务之间通过 Feign 进行通信处理业务。 点评：业务部署方式相同，都需要前置一个网关来隔绝外部直接调用原子服务的风险。 Dubbo 需要自己开发一套 API 网关，而 Spring Cloud 则可以通过 Zuul 配置即可完成网关定制。使用方式上 Spring Cloud 略胜一筹。 微服务架构组成以及注意事项 到底使用是 Dubbo 还是 Spring Cloud 并不重要，重点在于如何合理的利用微服务。 下面是一张互联网通用的架构图，其中每个环节都是微服务的核心部分。 架构分解： 网关集群：数据的聚合、实现对接入客户端的身份认证、防报文重放与防数据篡改、功能调用的业务鉴权、响应数据的脱敏、流量与并发控制等。 业务集群：一般情况下移动端访问和浏览器访问的网关需要隔离，防止业务耦合。 Local Cache：由于客户端访问业务可能需要调用多个服务聚合，所以本地缓存有效的降低了服务调用的频次，同时也提示了访问速度。本地缓存一般使用自动过期方式，业务场景中允许有一定的数据延时。 服务层：原子服务层，实现基础的增删改查功能，如果需要依赖其他服务需要在 Service 层主动调用。 Remote Cache：访问 DB 前置一层分布式缓存，减少 DB 交互次数，提升系统的TPS。 DAL：数据访问层，如果单表数据量过大则需要通过 DAL 层做数据的分库分表处理。 MQ：消息队列用来解耦服务之间的依赖，异步调用可以通过 MQ 的方式来执行。 数据库主从：服务化过程中必经的阶段，用来提升系统的 TPS。 注意事项： 服务启动方式建议使用jar方式启动，启动速度快，更容易监控。 缓存、缓存、缓存，系统中能使用缓存的地方尽量使用缓存，通过合理的使用缓存可以有效的提高系统的TPS。 服务拆分要合理，尽量避免因服务拆分而导致的服务循环依赖。 合理的设置线程池，避免设置过大或者过小导致系统异常。 总结 Dubbo 出生于阿里系，是阿里巴巴服务化治理的核心框架，并被广泛应用于中国各互联网公司；只需要通过 Spring 配置的方式即可完成服务化，对于应用无入侵，设计的目的还是服务于自身的业务为主。 虽然阿里内部原因 Dubbo 曾经一度暂停维护版本，但是框架本身的成熟度以及文档的完善程度，完全能满足各大互联网公司的业务需求。 如果我们使用配置中心、分布式跟踪这些内容都需要自己去集成，这样无形中增加了使用 Dubbo 的难度。 Spring Cloud 是大名鼎鼎的 Spring 家族的产品， 专注于企业级开源框架的研发。 Spring Cloud 自从发布到现在，仍然在不断的高速发展，几乎考虑了服务治理的方方面面，开发起来非常的便利和简单。 Dubbo 于 2017 年开始又重启维护，发布了更新后的 2.5.7 版本，而 Spring Cloud 更新的非常快，目前已经更新到 Finchley.M2。 因此，企业需要根据自身的研发水平和所处阶段选择合适的架构来解决业务问题，不管是 Dubbo 还是 Spring Cloud 都是实现微服务有效的工具。","categories":[{"name":"Spring-Cloud","slug":"Spring-Cloud","permalink":"https://chengtong.me/categories/Spring-Cloud/"}],"tags":[]},{"title":"SpringBoot2.x配置HTTPS,并实现HTTP访问自动转向HTTPS","slug":"SpringBoot2.x配置HTTPS,并实现HTTP访问自动转向HTTPS","date":"2018-05-25T07:56:01.000Z","updated":"2021-06-08T02:20:34.852Z","comments":true,"path":"posts/359a2f9d.html","link":"","permalink":"https://chengtong.me/posts/359a2f9d.html","excerpt":"","text":"1.证书生成如果对HTTPS不太了解，可以自行搜索资料，这里重点不在说https。 使用SSL需要我们先生成一个证书，这个证书我们可以自己生成，也可以从SSL证书授权中心获得，自己生成的不被客户端认可，从授权中心获得的可以被客户端认可，提供SSL授权证书的服务商有很多，小伙伴们有兴趣可以自行查找，我这里以自己生成的证书为例。 生成方式也很简单，直接使用java自带的命令keytool来生成，生成命令如下： -storetype PKCS12 -keyalg RSA -keysize 2048 -keystore keystore.p12 -validity 3650 这里涉及到几个参数的含义我简单说一下： 1.-storetype 指定密钥仓库类型 2.-keyalg 生证书的算法名称，RSA是一种非对称加密算法 3.-keysize 证书大小 4.-keystore 生成的证书文件的存储路径 5.-validity 证书的有效期 执行完上面一行命令后，按照提示进行操作，创建完成后,可在用户根目录查看生成的keystore文件。 建议使用阿里云、腾讯云免费https证书 2.生成的keystone文件复制到我们springboot项目的根目录生成证书后，我们将keystone文件拷贝到我们项目的根目录下，然后修改application.properties文件，添加HTTPS支持。在application.properties中添加如下代码： server.ssl.key-store=keystore.p12 server.ssl.key-store-password=123456 server.ssl.key-store-type=PKCS12 server.ssl.key-alias=tomcat 第一行指定签名文件，第二行指定签名密码，第三行指定密钥仓库类型，第四个是别名。OK，这样配置完成之后我们就可以通过HTTPS来访问我们的Web了。 3.HTTP自动转向HTTPS光有HTTPS肯定还不够，很多用户可能并不知道，用户有可能继续使用HTTP来访问你的网站，这个时候我们需要添加HTTP自动转向HTTPS的功能，当用户使用HTTP来进行访问的时候自动转为HTTPS的方式。这个配置很简单，在入口类中添加相应的转向Bean就行了。 在springboot1.x这样配置配置文件application.properties 1234server.port=8443server.ssl.key-store=classpath:214390839680457.pfxserver.ssl.key-store-password=214390839680457server.ssl.keyStoreType=PKCS12 Application.java代码如下： 1234567891011121314151617181920212223242526@Beanpublic EmbeddedServletContainerFactory servletContainerFactory() &#123; TomcatEmbeddedServletContainerFactory tomcat = new TomcatEmbeddedServletContainerFactory() &#123; @Override protected void postProcessContext(Context context) &#123; SecurityConstraint securityConstraint = new SecurityConstraint(); securityConstraint.setUserConstraint(\"CONFIDENTIAL\"); SecurityCollection collection = new SecurityCollection(); collection.addPattern(\"/*\"); securityConstraint.addCollection(collection); context.addConstraint(securityConstraint); &#125; &#125;; tomcat.addAdditionalTomcatConnectors(httpConnector()); return tomcat;&#125;@Beanpublic Connector httpConnector() &#123; Connector connector=new Connector(\"org.apache.coyote.http11.Http11NioProtocol\"); connector.setScheme(\"http\"); connector.setPort(8080); connector.setSecure(false); connector.setRedirectPort(8443); return connector;&#125; 这个时候当我们访问http://localhost:8080的时候系统会自动重定向到https://localhost:8443这个地址上。 首先 这里需要使用 EmbeddedServletContainerFactory 这个类,但是在springboot2.x版本已经找不到这个类了。但是在网上大部分还都是根据1.x来实现的，这也是我为什么写这篇文章的初衷，所以需要下边代码实现springboot2.x版本HTTP自动转向HTTPS。 在springboot2.x这样配置配置文件application.yml 123456server: port: 8443 ssl: key-store: classpath:camp.xxxx.net.jks key-store-password: i7mmxxxxxxxl005 key-store-type: JKS Application.java代码如下： 12345678910111213141516171819202122232425262728@Bean public TomcatServletWebServerFactory servletContainer() &#123; TomcatServletWebServerFactory tomcat = new TomcatServletWebServerFactory() &#123; @Override protected void postProcessContext(Context context) &#123; SecurityConstraint constraint = new SecurityConstraint(); constraint.setUserConstraint(\"CONFIDENTIAL\"); SecurityCollection collection = new SecurityCollection(); collection.addPattern(\"/*\"); constraint.addCollection(collection); context.addConstraint(constraint); &#125; &#125;; tomcat.addAdditionalTomcatConnectors(httpConnector()); return tomcat; &#125; @Bean public Connector httpConnector() &#123; Connector connector = new Connector(\"org.apache.coyote.http11.Http11NioProtocol\"); connector.setScheme(\"http\"); //Connector监听的http的端口号 connector.setPort(8080); connector.setSecure(false); //监听到http的端口号后转向到的https的端口号 connector.setRedirectPort(8443); return connector; &#125; 到这，我们在springboot2.x项目中，当我们访问http://localhost:8080的时候系统会自动重定向到https://localhost:8443这个地址上。 区别就是EmbeddedServletContainerFactory 换成了TomcatServletWebServerFactory；","categories":[{"name":"JAVA","slug":"JAVA","permalink":"https://chengtong.me/categories/JAVA/"}],"tags":[{"name":"Spring Boot","slug":"Spring-Boot","permalink":"https://chengtong.me/tags/Spring-Boot/"}]},{"title":"请求https报java.io.IOException Invalid keystore format","slug":"请求https报java.io.IOException Invalid keystore format","date":"2018-05-25T07:55:01.000Z","updated":"2020-05-23T12:43:24.081Z","comments":true,"path":"posts/3584df24.html","link":"","permalink":"https://chengtong.me/posts/3584df24.html","excerpt":"","text":"spring boot配置https，访问报错 报错日志如下： 1234567891011121314151617181920212223242526java.io.IOException: Invalid keystore format at sun.security.provider.JavaKeyStore.engineLoad(JavaKeyStore.java:650) at sun.security.provider.JavaKeyStore$JKS.engineLoad(JavaKeyStore.java:55) at java.security.KeyStore.load(KeyStore.java:1445) at cfca.httpclient.connector.HttpClient.initSSL(HttpClient.java:77) at cfca.httpclient.connector.HttpConnector.init(HttpConnector.java:31)qtp418304857-24, handling exception: javax.net.ssl.SSLHandshakeException: sun.security.validator.ValidatorException: PKIX path building failed: sun.security.provider.certpath.SunCertPathBuilderException: unable to find valid certification path to requested targetjavax.net.ssl.SSLHandshakeException: sun.security.validator.ValidatorException: PKIX path building failed: sun.security.provider.certpath.SunCertPathBuilderException: unable to find valid certification path to requested target at sun.security.ssl.Alerts.getSSLException(Alerts.java:192) at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1937) at sun.security.ssl.Handshaker.fatalSE(Handshaker.java:302) at sun.security.ssl.Handshaker.fatalSE(Handshaker.java:296) at sun.security.ssl.ClientHandshaker.serverCertificate(ClientHandshaker.java:1478) at sun.security.ssl.ClientHandshaker.processMessage(ClientHandshaker.java:212) at sun.security.ssl.Handshaker.processLoop(Handshaker.java:979) at sun.security.ssl.Handshaker.process_record(Handshaker.java:914) at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:1050) at sun.security.ssl.SSLSocketImpl.performInitialHandshake(SSLSocketImpl.java:1363) at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1391) at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1375) at sun.net.www.protocol.https.HttpsClient.afterConnect(HttpsClient.java:563) at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.connect(AbstractDelegateHttpsURLConnection.java:185) at sun.net.www.protocol.https.HttpsURLConnectionImpl.connect(HttpsURLConnectionImpl.java:153) at cfca.httpclient.connector.HttpClient.send(HttpClient.java:152) at cfca.httpclient.connector.HttpConnector.deal(HttpConnector.java:74) at cfca.httpclient.connector.HttpConnector.post(HttpConnector.java:47) 在网上看到一些处理办法，说是maven-resources-plugin 在拷贝resources 文件时进行 encoding 会“误伤二进制文件”导致拷贝到classes下的文件发生了变化. 我对比了一下，果不其然，对比了下src/main/resources下的jks 文件和生产运行的classes下的文件大小不一致，classes目录下的文件大了一圈. 嗯，看看别人的处理办法， filtering=false 123456&lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;filtering&gt;false&lt;/filtering&gt; &lt;/resource&gt; &lt;/resources&gt; 赶紧去修改自己的pom.xml，打开自己的pom要修改的时候看到代码： 12345678910&lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;filtering&gt;true&lt;/filtering&gt; &lt;/resource&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources/certificate&lt;/directory&gt; &lt;filtering&gt;false&lt;/filtering&gt; &lt;/resource&gt;&lt;/resources&gt; filtering已经是false了，没毛病,但是还是不行，这是为啥？（certificate目录下是.jks文件），看到个别有的文章说配置了filtering=false 没效，估计跟我这配置应该是差不多的，参考下面的方法： 1234567891011121314&lt;resource&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;filtering&gt;true&lt;/filtering&gt; &lt;excludes&gt; &lt;exclude&gt;**/*.jks&lt;/exclude&gt; &lt;/excludes&gt;&lt;/resource&gt;&lt;resource&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;filtering&gt;false&lt;/filtering&gt; &lt;includes&gt; &lt;include&gt;**/*.jks&lt;/include&gt; &lt;/includes&gt;&lt;/resource&gt; 再用maven构建，构建后的.jks文件大小正常，没有再变大了！项目部署后，请求https地址也能正常返回了。。。 另外一种配置方式： 123456789101112131415&lt;build&gt; ... &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-resources-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;nonFilteredFileExtensions&gt; &lt;!--这里是文件后缀--&gt; &lt;nonFilteredFileExtension&gt;jks&lt;/nonFilteredFileExtension&gt; &lt;/nonFilteredFileExtensions&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt;","categories":[],"tags":[]},{"title":"apiDoc的maven插件自动生成apidoc.json","slug":"apiDoc的maven插件自动生成apidoc.json","date":"2018-05-15T16:00:01.000Z","updated":"2020-06-01T06:25:04.293Z","comments":true,"path":"posts/420296e9.html","link":"","permalink":"https://chengtong.me/posts/420296e9.html","excerpt":"","text":"插件是用apidoc插件生成文档的，具体使用方式可查看官网：http://apidocjs.com/ 该插件不会直接生成APIDOC文档，只会自动生成apidoc.json文件，需要执行apidoc命令才可以生成apidoc.json文件会生成在项目根目录apidoc文件夹下 下载依赖包可配置MAVEN仓库https://oss.sonatype.org/content/groups/public或者下载源码包进行编译打包:https://gitee.com/qianxunclub/qianxunclub-maven-plugin 12345git clone https://gitee.com/qianxunclub/qianxunclub-maven-plugin.gitcd qianxunclub-maven-pluginmvn clean install 编辑pom.xml，引入maven plugin在项目的pom文件中引入以下： 123456789101112&lt;plugin&gt; &lt;groupId&gt;com.qianxunclub&lt;/groupId&gt; &lt;artifactId&gt;qianxunclub-plugin-apidoc&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;goals&gt; &lt;goal&gt;apidoc&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt;&lt;/plugin&gt; 在properties定义API的生成规范： 123456&lt;properties&gt; &lt;apidoc.skip&gt;false/&lt;/apidoc.skip&gt; &lt;apidoc.gen&gt;false&lt;/apidoc.gen&gt; &lt;apidoc.url&gt;http://ip:port/&lt;/apidoc.url&gt; &lt;apidoc.sampleUrl&gt;http://ip:port/&lt;/apidoc.sampleUrl&gt;&lt;/properties&gt; apidoc.skip：编译代码是否跳过生成apidoc.jsonapidoc.gen：是否覆盖更新apidoc.jsonapidoc.url：实例接口前缀apidoc.sampleUrl：生成测试方法的请求地址 开始生成执行命令： 1mvn clean package 可以添加以下参数： 1mvn clean package -Dapidoc.skip=true -Dapidoc.skip=true：编译代码是否跳过生成apidoc.json-Dapidoc.gen=true：是否覆盖更新apidoc.json-Dapidoc.url=xxx：实例接口前缀-Dapidoc.sampleUrl=xxx：生成测试方法的请求地址 如果出现以下字样，说明生成完成： apidoc.json完成 生成api文档在项目跟目录执行： apidoc -i apidoc/ -o API文档存放目录/ 打开API文档存放目录中的index.html即可查看文档。","categories":[],"tags":[]},{"title":"apiDoc使用指南","slug":"apiDoc使用指南","date":"2018-05-14T16:00:01.000Z","updated":"2020-06-01T06:25:04.294Z","comments":true,"path":"posts/6cb9a624.html","link":"","permalink":"https://chengtong.me/posts/6cb9a624.html","excerpt":"","text":"官网官网：http://apidocjs.com/ 安装 安装node.js 安装apiDoc 1npm install apidoc -g 配置在你的项目根目录下新建apidoc.json文件，该文件描述了项目对外提供接口的概要信息如名称、版本、描述、文档打开时浏览器显示标题和接口缺省访问地址。 apidoc.json 1234567&#123; \"name\": \"ServiceEbikeAPIs\", \"version\": \"3.1.0\", \"description\": \"车辆服务接口文档\", \"title\": \"ServiceEbikeAPIs\", \"url\" : \"http://cjl3.rokyinfo.net:7190/api-ebike\"&#125; 使用样例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263/** * * @apiDefine RkNotFoundException * * @apiError RkNotFoundException 找不到相关数据 * * @apiErrorExample Error-Response: * HTTP/1.1 404 Not Found * &#123; * \"error\": &#123; * \"code\": 404, * \"msg\": \"\", * \"path\" \"\" * &#125; * &#125; * *//** * * @api &#123;get&#125; /v3.1/ues/:sn/rt-info 获取设备上报实时信息 * @apiVersion 3.1.0 * @apiName GetUeRealTimeInfo * @apiGroup UE * * @apiHeader &#123;String&#125; Authorization 用户授权token * @apiHeader &#123;String&#125; firm 厂商编码 * @apiHeaderExample &#123;json&#125; Header-Example: * &#123; * \"Authorization\": \"eyJhbGciOiJIUzUxMiJ9.eyJzdWIiOjM2NzgsImF1ZGllbmNlIjoid2ViIiwib3BlbkFJZCI6MTM2NywiY3JlYXRlZCI6MTUzMzg3OTM2ODA0Nywicm9sZXMiOiJVU0VSIiwiZXhwIjoxNTM0NDg0MTY4fQ.Gl5L-NpuwhjuPXFuhPax8ak5c64skjDTCBC64N_QdKQ2VT-zZeceuzXB9TqaYJuhkwNYEhrV3pUx1zhMWG7Org\", * \"firm\": \"cnE=\" * &#125; * * @apiParam &#123;String&#125; sn 设备序列号 * * @apiSuccess &#123;String&#125; sn 设备序列号 * @apiSuccess &#123;Number&#125; status 设备状态 * @apiSuccess &#123;Number&#125; soc 电池电量百分比 * @apiSuccess &#123;Number&#125; voltage 电池电压 * @apiSuccess &#123;Number&#125; current 电池电流 * @apiSuccess &#123;Number&#125; temperature 电池温度 * @apiSuccess &#123;String&#125; reportTime 上报时间(yyyy-MM-dd HH:mm:ss) * * @apiSuccessExample Success-Response: * HTTP/1.1 200 OK * &#123; * \"sn\": \"P000000000\", * \"status\": 0, * \"soc\": 80, * \"voltage\": 60.0, * \"current\": 10.0, * \"temperature\": null, * \"reportTime\": \"2018-08-13 18:11:00\" * &#125; * * @apiUse RkNotFoundException * */@RequestMapping(value = \"/&#123;sn&#125;/rt-info\", method = RequestMethod.GET)public UeRealTimeInfo getUeRealTimeInfo(@RequestHeader(Constants.HEADER_LOGIN_USER_KEY) long userId, @PathVariable(\"sn\") String sn) &#123; return ueService.getRealTimeInfo(sn);&#125; @api1@api &#123;method&#125; path [title] HTTP接口调用方法、路径及名称 @apiVersion1@apiVersion version api 版本号 @apiName1@apiName name api 名称 @apiGroup1@apiGroup name api 分组 @apiHeader1@apiHeader [(group)] [&#123;type&#125;] [field=defaultValue] [description] 请求头参数 @apiParam1@apiParam [(group)] [&#123;type&#125;] [field=defaultValue] [description] 请求参数 @apiSuccess1@apiSuccess [(group)] [&#123;type&#125;] field [description] 返回数据描述 @apiSuccessExample12@apiSuccessExample [&#123;type&#125;] [title] example 接口成功返回样例 @apiError1@apiError [(group)] [&#123;type&#125;] field [description] 接口失败描述 @apiErrorExample12@apiErrorExample [&#123;type&#125;] [title] example 接口失败返回样例 @apiDefine12@apiDefine name [title] [description] 类似于宏定义，可以被引用 @apiUse1@apiUse name 使用@apiDefine定义的描述 更详细的说明请参考官方文档http://apidocjs.com 生成文档cd到apidoc.json所在路径（即项目根目录）执行如下命令即可 1apidoc -i src/ -o apidoc/ 执行成功后会生成apidoc文件夹如下图所示 点开apidoc文件夹中index.html会发现已经生成的漂亮的api文档","categories":[],"tags":[]},{"title":"Mac使用技巧|iPic图床设置-Markdown写作必备","slug":"Mac使用技巧-iPic图床设置-Markdown写作必备","date":"2018-04-20T03:11:13.000Z","updated":"2020-05-22T02:03:24.850Z","comments":true,"path":"posts/323926de.html","link":"","permalink":"https://chengtong.me/posts/323926de.html","excerpt":"","text":"年少时，常闲逛于1024，看美图时，时常会碰到红××或？，着实扫兴啊。楼下就常有人喊道：图床挂啦，楼主换图床啦。虽游荡网络很多年，一直不知道图床是啥东东，真是那个啥…… 前不久，跟着易仁永澄老师搭建知识主题网站，在MarkEditor插入图片同步Bitcron后分享，时常看不到图片，着实郁闷啊。只能通过简书的私密文件夹上传复制出链接才得以解决，着实麻烦，繁琐累人！ 为了便利性和储存的相对安全性，就考虑设置自己的图床了。图床是什么？ 折腾图床期间入了一些坑，下面做简单安装说明，给有需要的朋友 环境说明 系统：Mac OS 软件：iPic（注：仅苹果OS系统可用）+ 阿里云 OSS（阿里云对象存储） 参考教程： 易仁永澄：7 搞定一个图床（可选） iPic - 图床神器 在 iPic 中添加阿里云 OSS 软件安装过程比较简单就不展开了，上面教程已经很详尽了，如仍旧搞不定的，欢迎来骚扰我。 下面针对关键点：图床的类型做详细的讲解。 图床 OSS（对象存储）类型选用使用 iPic 默认免费微博图床 软件安装好后，都不用设置，直接就可以用了，但老江湖易仁永澄提醒：一定要付费，付费才靠谱！建议采用付费图床，不知道哪天微博图床说关就关了，当年的新浪问问就是前车之鉴啊。- 使用阿里云OSS（对象存储），iPic网址前缀：根据Bucket名称自动生成的域名 按照易仁永澄的教程，一步一步的操作没有问题，不掉坑的话，10分钟搞定。下图是关键设置点： ① Bucket默认网址生成，细节见下图示意 ② iPic图床设置 如不清楚Access Key 和 Sectet Key ，请看易仁永澄的指导文件或付费购买 相关教程。（当然找我也可以啦，就当交个朋友啦） 官方说明需要订阅才能使用第三方 OSS，实际我没有订阅但也能使用，不知道实际是什么情况，可能是试用期使用。（APP Store经常抽风或来姨妈的） 使用阿里云OSS（对象存储），iPic 网址前缀：使用独立域名，彰显个人品牌。被永澄老大的彰显个人品牌给吸引了，于是想搞定独立域名的设置，哪知道——这是一个坑，搞了两个小时没有搞定，最终老老实实的回到了方案⑵。 入坑记如下：⑴ 按照永澄老大的教程，进行绑定域名的设置，提交后显示不能备案 ⑵ 查找 『备案』 的相关信息 阿里云指导说明很详尽，但本人缺少网站域名相关的背景知识，这些文件说明看的我云里雾里，按照说明左点右点，愣是没有搞定独立域名。 提示重点： 实名注册 不等于 备** 案** 最终回到了：到底『什么是备案』的问题上来了，官方的说明如下： 总结如下 ： 永澄老大的域名已经过备案了，且比较早，备案也很容易，所以老大可以很方便设置二级独立域名。（按照现在的网络环境，新备案估计有点难了） 没有经过备案的独立域名是不能直接访问的 我们现申请的域名可访问的原因是: 与 Bitcron 域名捆绑了，本质上访问的是 Bitcron 的服务器。（这点理解不一定对。） ⑶ 放弃备案的原因，看图不说话 可以考虑国外域名申请，不用备案 按永澄老大教程进行图床设置的注意点iPic 一键上传快捷键 永澄老大的快捷键为：Command + Shift + R（一键上传）； iPic 默认快捷键为：Command + U如果没开iPic 的官方指导说明，你会发现图片怎么也不能一键上传。可以根据使用习惯设置自己的快捷键。 iPic 图床 - 网站前缀的设置 如果自己独立域名没有备案，在这里应该填根据Bucket名称默认生成的网址。 网站前缀不能留空 网址前缀不能留空，留空无法通过验证 插图要更换位置：四、高阶准备 - Step1：绑定自己的独立域名 如果独立域名已有备案，可以自行研究一下，按照提示操作就可以了 如果独立域名 没有 备案，请直接忽略，不用往下看了，看了也白看。 OK，iPic图床设置介绍结束，用苹果OS系统的本身比较小众，给有需要的人吧。","categories":[{"name":"图床","slug":"图床","permalink":"https://chengtong.me/categories/图床/"}],"tags":[{"name":"iPic","slug":"iPic","permalink":"https://chengtong.me/tags/iPic/"}]},{"title":"BaiduPCS-Go | 百度网盘命令行工具（基于 Go）","slug":"BaiduPCS-Go-百度网盘命令行工具（基于-Go）","date":"2018-02-08T04:01:18.000Z","updated":"2020-05-22T02:03:24.777Z","comments":true,"path":"posts/f44f6d37.html","link":"","permalink":"https://chengtong.me/posts/f44f6d37.html","excerpt":"","text":"提到百度网盘，想必大家都很熟悉吧。 百度网盘自 2012 年上线运行以来，迅速积累了大量用户。但是狗改不了吃屎，作为百度的产品，百度网盘现在是越来越恶心了，不给充钱就限速，官方居然还不承认（百度网盘 - 维基百科 ）其实给免费账号限速也是可以理解的（毕竟别人也是要吃饭的，没有利润的产品肯定是走不远的）但百度居然给我限速到 20 KB/s！这还能用？！！ 但人们的力量是强大的，被百度恶心到的用户们很快就找到了破解百度网盘限速的方法—— 多线程下载 。你不是只给我 20 KB/s 吗？我开TM 500 个线程，一样把 10 M/s 的带宽占满。于是乎一大批第三方网盘拔地而起，例如：&lt;del&gt;PanDownload&lt;/del&gt;（已停止运营）、Village（Android）、油猴脚本 等。 今天介绍的 BaiduPCS-Go 也是其中一个，相比于其他第三方网盘，具有以下特点： 不需要 Aria2、IDM 等第三方软件 自定义线程数（建议将最大线程数设置为50 ~ 500，线程开太多会造成搞负载） 支持通配符匹配路径 通配符-维基百科 命(bi)令(ge)行(gao) BaiduPCS-Go 的 Github 安装得益于 Go 的跨平台编译的特性，BaiduPCS-Go 几乎可以支持所有操作系统，只需要在 Releases 中选取合适的版本下载、运行就可以了 下载BaiduPCS-Go 以 Windows 为例，根据我的电脑 CPU 下载并解压 BaiduPCS-Go-v3.2.1-windows-x86.zip 可以直接双击运行（进入 console 模式） 也可以在命令行中运行 在Android与iOS上安装在 Android 上安装与在桌面上安装的思路差不多，都是 下载 -\\&gt; 解压 -\\&gt; (在命令行中)运行 不同的是 Android 上没有原生的命令行，需要借助 Termux 或 NeoTerm 或 终端模拟器等 APP，以提供终端环境。 详情请参考：Android 运行本 BaiduPCS-Go 程序参考示例 iOS 就比较特殊了，因为 iOS 系统的特殊性，需要越狱后才能提供相应的运行环境。 越狱后,，在 Cydia 搜索下载并安装 MobileTerminal，以提供终端环境。 命令列表在命令行中，在 BaiduPCS-Go.exe 所在的目录下，使用以下格式输入命令1BaiduPCS-Go [global options] command [command options] [arguments...] 简单的说就是以 BaiduPCS-Go 开头，后面跟具体的命令（参数）。 未带任何其他参数运行程序,，则程序进入 console 模式。（光标前有 BaiduPCS-Go \\&gt; 的前缀）console 模式下直接输入命令，不需要加 BaiduPCS-Go 的前缀。 登录既然是第三方百度网盘，肯定要登录百度账号才能使用。 有两种方法可以登录， 常规登录 和 BDUSS 登录 常规登录直接键入以下命令1BaiduPCS-Go login 然后依次输入 用户名 和 密码 登录成功！ BDUSS登录获取百度 BDUSS 获得 BDUSS 后，用以下命令登录（[BDUSS] = 你取得的 BDUSS）1BaiduPCS-Go login -bduss=[BDUSS] 获取当前账号&amp;已有的账号1BaiduPCS-Go loglist 切换已登录的百度帐号1BaiduPCS-Go su -uid=[uid] 12BaiduPCS-Go su请输入要切换帐号的 index 值 \\&amp;gt;[index 值] 退出已登录的百度帐号1BaiduPCS-Go logout -uid=[uid] 12BaiduPCS-Go logout请输入要退出帐号的 index 值 &gt; [index 值] 因为我只有一个百度账号，就不演示第二种退出方式了 获取配额（获取网盘总空间和已使用空间）1BaiduPCS-Go quota 文件/目录操作对 目录、文件的操作与 Linux 命令行相似。 目录、文件名可以使用通配符（*） 切换工作目录1BaiduPCS-Go cd [目录] 输出当前所在目录1BaiduPCS-Go pwd 列出当前工作目录的文件和目录或指定目录1BaiduPCS-Go ls 1BaiduPCS-Go ls [目录] 获取单个文件/目录的元信息(详细信息)1BaiduPCS-Go meta [文件/目录] 如果没有指定的目录则默认为 获取根目录的元信息 创建目录1BaiduPCS-Go mkdir [目录] 删除文件/目录1BaiduPCS-Go rm [文件或目录1] [文件或目录2] [文件或目录3] ... 复制文件/目录12BaiduPCS-Go cp [文件/目录] [目标 文件/目录]BaiduPCS-Go cp [文件/目录1] [文件/目录2] [文件/目录3] ... [目标目录] 复制文件/目录时，需确保每个文件/目录的有效性 移动/重命名文件/目录复制文件/目录1234移动: BaiduPCS-Go mv &lt;文件/目录1&gt; &lt;文件/目录2&gt; &lt;文件/目录3&gt; ... &lt;目标目录&gt;重命名: BaiduPCS-Go mv &lt;文件/目录&gt; &lt;重命名的文件/目录&gt; 下载文件12BaiduPCS-Go download [文件或目录1] [文件或目录2] [文件或目录3]...BaiduPCS-Go d [文件或目录1] [文件或目录2] [文件或目录3]... 支持同时下载多个文件/目录 下载的文件默认保存到程序所在目录的download目录下，你可以自定义储存目录 上传文件12BaiduPCS-Go upload [本地文件或目录1] [文件或目录2] ... [网盘的目标目录]BaiduPCS-Go u [本地文件或目录1] [文件或目录2] ... [网盘的目标目录] 注意： 本地的目录要使用\\转义（两个反斜杠\\） 区别反斜杠 \\ 和 斜杠 / 例如：12345678910将本地的 C:\\Users\\Administrator\\Desktop\\1.mp4 上传到网盘 /视频 目录本地的目录要使用 &amp;quot;\\&amp;quot; 转义（两个反斜杠 &amp;quot;\\&amp;quot;）注意区别反斜杠 &amp;quot;\\&amp;quot; 和 斜杠 &amp;quot;/&amp;quot;BaiduPCS-Go upload C:\\\\Users\\\\Administrator\\\\Desktop\\\\1.mp4 /视频将本地的 C:\\Users\\Administrator\\Desktop\\1.mp4 和 C:\\Users\\Administrator\\Desktop\\2.mp4 上传到网盘 /视频 目录BaiduPCS-Go upload C:\\\\Users\\\\Administrator\\\\Desktop\\\\1.mp4 C:\\\\Users\\\\Administrator\\\\Desktop\\\\2.mp4 /视频将本地的 C:\\Users\\Administrator\\Desktop 整个目录上传到网盘 /视频 目录BaiduPCS-Go upload C:\\\\Users\\\\Administrator\\\\Desktop /视频 设置在 BaiduPCS-Go 中，使用以下格式的命令进行设置1BaiduPCS-Go set OptionName Value 翻译一下就是1BaiduPCS-Go set [被设置的项目] [你设置的值] 让我们先来看一下有哪些项目可以被设置1BaiduPCS-Go set -h 简单介绍一下 appid BaiduPCS-Go 的应用ID，一般没必要改 user_agent浏览器标识，用来伪装成正版&quot;百度云管家&quot;的（如果能下载且速度不慢就没必要改） cache_size下载缓存大小，一般没必要改 max_parallel最大线程数 -\\&gt; 设置最大线程数 savedir下载文件的储存目录 -\\&gt; 设置自定义储存目录 自定义储存目录下载文件默认保存在程序所在目录的download目录下，使用以下命令自定义储存目录1BaiduPCS-Go set savedir [储存目录的路径] 例如：12# 设置保存目录, 保存到 D:\\Downloads (注意两个反斜杠 &amp;quot;\\&amp;quot; )BaiduPCS-Go set savedir D:\\\\Downloads 设置最大线程数理论上（在没有占满带宽的情况下），线程开得越多下得越快，同时占用资源越多； 建议开到50 ~ 500（下载速度不仅仅取决于线程数，也取决于带宽大小；如果增加带宽却没有提速，说明瓶颈在带宽上）；如果觉得下载文件时电脑运行卡顿，就开小一点。 设置方法 BaiduPCS-Go set max_parallel [最大并发数] 例如： 设置下载最大并发数为 150BaiduPCS-Go set max_parallel 150 退出程序运行命令 quit 或 exit 或 组合键 Ctrl+C 或 组合键 Ctrl+D 已知问题 下载进度到最后的时候,，下载速度会降低。 程序的 console 模式在 windows 下部分中文无法正常输入。 参考本文章参考了： GitHub - iikira/BaiduPCS-Go:百度网盘工具箱- Go语言编写 使用第三方百度网盘是有风险的，如果你因为使用第三方百度网盘导致账号被封，本博客概不负责","categories":[],"tags":[]},{"title":"MarkDown添加图片的三种方式","slug":"MarkDown添加图片的三种方式","date":"2018-02-07T16:09:00.000Z","updated":"2020-05-22T02:03:24.851Z","comments":true,"path":"posts/2ef33b20.html","link":"","permalink":"https://chengtong.me/posts/2ef33b20.html","excerpt":"","text":"插图最基础的格式就是：![Alt text](图片链接 “optional title”) Alt text：图片的Alt标签，用来描述图片的关键词，可以不写。最初的本意是当图片因为某种原因不能被显示时而出现的替代文字，后来又被用于SEO，可以方便搜索引擎根据Alt text里面的关键词搜索到图片。 图片链接：可以是图片的本地地址或者是网址。”optional title”：鼠标悬置于图片上会出现的标题文字，可以不写。 插入本地图片只需要在基础语法的括号中填入图片的位置路径即可，支持绝对路径和相对路径。例如： ![avatar](/home/picture/1.png) 不灵活不好分享，本地图片的路径更改或丢失都会造成markdown文件调不出图。 插入网络图片只需要在基础语法的括号中填入图片的网络链接即可，现在已经有很多免费/收费图床和方便传图的小工具可选。例如： ![avatar](https://www.baidu.com/img/bd_logo1.png) 将图片存在网络服务器上，非常依赖网络。 把图片存入markdown文件用base64转码工具把图片转成一段字符串，然后把字符串填到基础格式中链接的那个位置。 基础用法：![avatar](data:image/png;base64,iVBORw0……)这个时候会发现插入的这一长串字符串会把整个文章分割开，非常影响编写文章时的体验。如果能够把大段的base64字符串放在文章末尾，然后在文章中通过一个id来调用，文章就不会被分割的这么乱了。 高级用法比如：![avatar][base64str][base64str]:data:image/png;base64,iVBORw0……","categories":[],"tags":[]},{"title":"拦截器（Interceptor）和过滤器（Filter）的执行顺序和区别","slug":"拦截器（Interceptor）和过滤器（Filter）的执行顺序和区别","date":"2018-01-20T05:31:00.000Z","updated":"2020-05-23T12:43:24.200Z","comments":true,"path":"posts/e94c3a32.html","link":"","permalink":"https://chengtong.me/posts/e94c3a32.html","excerpt":"","text":"一、引言本来想记录一下关于用户登陆和登陆之后的权限管理、菜单管理的问题，想到解决这个问题用到Interceptor，但想到了Interceptor，就想到了Filter，于是就想说一下它们的执行顺序和区别。关于Interceptor解决权限和菜单管理的问题，在放在下一篇写吧，就酱紫。 二、区别1、过滤器（Filter）首先说一下Filter的使用地方，我们在配置web.xml时，总会配置下面一段设置字符编码，不然会导致乱码问题： 1234567891011121314151617&lt;filter&gt; &lt;filter-name&gt;encoding&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.CharacterEncodingFilter&lt;/filter-class&gt; &lt;init-param&gt; &lt;param-name&gt;encoding&lt;/param-name&gt; &lt;param-value&gt;UTF-8&lt;/param-value&gt; &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;forceEncoding&lt;/param-name&gt; &lt;param-value&gt;true&lt;/param-value&gt; &lt;/init-param&gt;&lt;/filter&gt;&lt;filter-mapping&gt; &lt;filter-name&gt;encoding&lt;/filter-name&gt; &lt;servlet-name&gt;/*&lt;/servlet-name&gt;&lt;/filter-mapping&gt; 配置这个地方的目的，是让所有的请求都需要进行字符编码的设置，下面来介绍一下Filter。 （1）过滤器(Filter)：它依赖于servlet容器。在实现上，基于函数回调，它可以对几乎所有请求进行过滤，但是缺点是一个过滤器实例只能在容器初始化时调用一次。使用过滤器的目的，是用来做一些过滤操作，获取我们想要获取的数据，比如：在Javaweb中，对传入的request、response提前过滤掉一些信息，或者提前设置一些参数，然后再传入servlet或者Controller进行业务逻辑操作。通常用的场景是：在过滤器中修改字符编码（CharacterEncodingFilter）、在过滤器中修改HttpServletRequest的一些参数（XSSFilter(自定义过滤器)），如：过滤低俗文字、危险字符等。 2、拦截器（Interceptor）拦截器的配置一般在SpringMVC的配置文件中，使用Interceptors标签，具体配置如下： 12345678910&lt;mvc:interceptors&gt; &lt;mvc:interceptor&gt; &lt;mvc:mapping path=\"/**\" /&gt; &lt;bean class=\"com.scorpios.atcrowdfunding.web.LoginInterceptor\"&gt;&lt;/bean&gt; &lt;/mvc:interceptor&gt; &lt;mvc:interceptor&gt; &lt;mvc:mapping path=\"/**\" /&gt; &lt;bean class=\"com.scorpios.atcrowdfunding.web.AuthInterceptor\"&gt;&lt;/bean&gt; &lt;/mvc:interceptor&gt;&lt;/mvc:interceptors&gt; （2）拦截器（Interceptor）：它依赖于web框架，在SpringMVC中就是依赖于SpringMVC框架。在实现上,基于Java的反射机制，属于面向切面编程（AOP）的一种运用，就是在service或者一个方法前，调用一个方法，或者在方法后，调用一个方法，比如动态代理就是拦截器的简单实现，在调用方法前打印出字符串（或者做其它业务逻辑的操作），也可以在调用方法后打印出字符串，甚至在抛出异常的时候做业务逻辑的操作。由于拦截器是基于web框架的调用，因此可以使用Spring的依赖注入（DI）进行一些业务操作，同时一个拦截器实例在一个controller生命周期之内可以多次调用。但是缺点是只能对controller请求进行拦截，对其他的一些比如直接访问静态资源的请求则没办法进行拦截处理。 三、代码 下面在一个项目中我们使用既有多个过滤器，又有多个拦截器，并观察它们的执行顺序：（1）第一个过滤器： 1234567891011public class TestFilter1 extends Filter &#123; @Override protected void doFilter(HttpServletRequest request, HttpServletResponse response, FilterChain filterChain) throws ServletException, IOException &#123; //在DispatcherServlet之前执行 System.out.println(\"############TestFilter1 doFilterInternal executed############\"); filterChain.doFilter(request, response); //在视图页面返回给客户端之前执行，但是执行顺序在Interceptor之后 System.out.println(\"############TestFilter1 doFilter after############\"); &#125;&#125; （2）第二个过滤器： 1234567891011public class TestFilter2 extends Filter &#123; @Override protected void doFilter(HttpServletRequest request, HttpServletResponse response, FilterChain filterChain) throws ServletException, IOException &#123; //在DispatcherServlet之前执行 System.out.println(\"############TestFilter2 doFilterInternal executed############\"); filterChain.doFilter(request, response); //在视图页面返回给客户端之前执行，但是执行顺序在Interceptor之后 System.out.println(\"############TestFilter2 doFilter after############\"); &#125; &#125; （3）在web.xml中注册这两个过滤器： 123456789101112131415161718&lt;!-- 自定义过滤器：testFilter1 --&gt; &lt;filter&gt; &lt;filter-name&gt;testFilter1&lt;/filter-name&gt; &lt;filter-class&gt;com.scorpios.filter.TestFilter1&lt;/filter-class&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;testFilter1&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/filter-mapping&gt; &lt;!-- 自定义过滤器：testFilter2 --&gt; &lt;filter&gt; &lt;filter-name&gt;testFilter2&lt;/filter-name&gt; &lt;filter-class&gt;com.scorpios.filter.TestFilter2&lt;/filter-class&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;testFilter2&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/filter-mapping&gt; 再定义两个拦截器：（4）第一个拦截器： 12345678910111213141516171819202122232425public class BaseInterceptor implements HandlerInterceptor&#123; /** * 在DispatcherServlet之前执行 * */ public boolean preHandle(HttpServletRequest arg0, HttpServletResponse arg1, Object arg2) throws Exception &#123; System.out.println(\"************BaseInterceptor preHandle executed**********\"); return true; &#125; /** * 在controller执行之后的DispatcherServlet之后执行 * */ public void postHandle(HttpServletRequest arg0, HttpServletResponse arg1, Object arg2, ModelAndView arg3) throws Exception &#123; System.out.println(\"************BaseInterceptor postHandle executed**********\"); &#125; /** * 在页面渲染完成返回给客户端之前执行 * */ public void afterCompletion(HttpServletRequest arg0, HttpServletResponse arg1, Object arg2, Exception arg3) throws Exception &#123; System.out.println(\"************BaseInterceptor afterCompletion executed**********\"); &#125; &#125; （5）第二个拦截器： 123456789101112131415public class TestInterceptor implements HandlerInterceptor &#123; public boolean preHandle(HttpServletRequest arg0, HttpServletResponse arg1, Object arg2) throws Exception &#123; System.out.println(\"************TestInterceptor preHandle executed**********\"); return true; &#125; public void postHandle(HttpServletRequest arg0, HttpServletResponse arg1, Object arg2, ModelAndView arg3) throws Exception &#123; System.out.println(\"************TestInterceptor postHandle executed**********\"); &#125; public void afterCompletion(HttpServletRequest arg0, HttpServletResponse arg1, Object arg2, Exception arg3) throws Exception &#123; System.out.println(\"************TestInterceptor afterCompletion executed**********\"); &#125; &#125; （6）、在SpringMVC的配置文件中，加上拦截器的配置： 123456789101112&lt;!-- 拦截器 --&gt; &lt;mvc:interceptors&gt; &lt;!-- 对所有请求都拦截，公共拦截器可以有多个 --&gt; &lt;bean name=\"baseInterceptor\" class=\"com.scorpios.interceptor.BaseInterceptor\" /&gt; &lt;mvc:interceptor&gt; &lt;!-- 对/test.html进行拦截 --&gt; &lt;mvc:mapping path=\"/test.html\"/&gt; &lt;!-- 特定请求的拦截器只能有一个 --&gt; &lt;bean class=\"com.scorpios.interceptor.TestInterceptor\" /&gt; &lt;/mvc:interceptor&gt; &lt;/mvc:interceptors&gt; （7）、定义一个Controller控制器： 12345678910111213package com.scorpios.controller; import org.springframework.stereotype.Controller; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.servlet.ModelAndView; @Controller public class TestController &#123; @RequestMapping(\"/test\") public ModelAndView handleRequest()&#123; System.out.println(\"---------TestController executed--------\"); return new ModelAndView(\"test\"); &#125; &#125; （8）、测试结果：启动测试项目，地址如下：http://www.localhost:8080/demo，可以看到控制台中输出如下： 这就说明了过滤器的运行是依赖于servlet容器，跟springmvc等框架并没有关系。并且，多个过滤器的执行顺序跟xml文件中定义的先后关系有关。 接着清空控制台，并访问：http://www.localhost:8080/demo/test，再次看控制台的输出： 从这个控制台打印输出，就可以很清晰地看到有多个拦截器和过滤器存在时的整个执行顺序了。当然，对于多个拦截器它们之间的执行顺序跟在SpringMVC的配置文件中定义的先后顺序有关。 四、总结 对于上述过滤器和拦截器的测试，可以得到如下结论：（1）、Filter需要在web.xml中配置，依赖于Servlet；（2）、Interceptor需要在SpringMVC中配置，依赖于框架；（3）、Filter的执行顺序在Interceptor之前，具体的流程见下图； （4）、两者的本质区别：拦截器（Interceptor）是基于Java的反射机制，而过滤器（Filter）是基于函数回调。从灵活性上说拦截器功能更强大些，Filter能做的事情，都能做，而且可以在请求前，请求后执行，比较灵活。Filter主要是针对URL地址做一个编码的事情、过滤掉没用的参数、安全校验（比较泛的，比如登录不登录之类），太细的话，还是建议用interceptor。不过还是根据不同情况选择合适的。","categories":[],"tags":[]},{"title":"IDEA编辑器提升效率的操作","slug":"IDEA编辑器提升效率的操作","date":"2018-01-19T10:16:01.000Z","updated":"2020-05-23T12:43:24.341Z","comments":true,"path":"posts/74a917bd.html","link":"","permalink":"https://chengtong.me/posts/74a917bd.html","excerpt":"","text":"阅读本文大概需要 3 分钟。 IDEA 有个很牛逼的功能，那就是后缀补全（不是自动补全），很多人竟然不知道这个操作，还在手动敲代码。 这个功能可以使用代码补全来模板式地补全语句，如遍历循环语句（for、foreach）、使用 String.format() 包裹一个字符串、使用类型转化包裹一个表达式、根据判（非）空或者其它判别语句生成 if 语句、用 instanceOf 生成分支判断语句等。 使用的方式也很简单，就是在一个表达式后按下点号 . ，然后输入一些提示或者在列表中选择一个候选项，常见的候选项下面会给出 GIF 演示。 1. var 声明 2. null 判空 3. notnull 判非空 4. nn 判非空 5. for 遍历 6. fori 带索引的遍历 7. not 取反 8. if 条件判断 9. cast 强转 10. return 返回值","categories":[],"tags":[]},{"title":"拦截器和过滤器的区别","slug":"拦截器和过滤器的区别","date":"2018-01-19T10:16:01.000Z","updated":"2020-05-23T12:43:24.118Z","comments":true,"path":"posts/88d2b72a.html","link":"","permalink":"https://chengtong.me/posts/88d2b72a.html","excerpt":"","text":"1.过滤器： 依赖于servlet容器。在实现上基于函数回调，可以对几乎所有请求进行过滤，但是缺点是一个过滤器实例只能在容器初始化时调用一次。使用过滤器的目的是用来做一些过滤操作，获取我们想要获取的数据，比如：在过滤器中修改字符编码；在过滤器中修改HttpServletRequest的一些参数，包括：过滤低俗文字、危险字符等 2.拦截器： 依赖于web框架，在SpringMVC中就是依赖于SpringMVC框架。在实现上基于Java的反射机制，属于面向切面编程（AOP）的一种运用。由于拦截器是基于web框架的调用，因此可以使用Spring的依赖注入（DI）进行一些业务操作，同时一个拦截器实例在一个controller生命周期之内可以多次调用。但是缺点是只能对controller请求进行拦截，对其他的一些比如直接访问静态资源的请求则没办法进行拦截处理 3.过滤器和拦截器的区别： ①拦截器是基于java的反射机制的，而过滤器是基于函数回调。 ②拦截器不依赖与servlet容器，过滤器依赖与servlet容器。 ③拦截器只能对action请求起作用，而过滤器则可以对几乎所有的请求起作用。 ④拦截器可以访问action上下文、值栈里的对象，而过滤器不能访问。 ⑤在action的生命周期中，拦截器可以多次被调用，而过滤器只能在容器初始化时被调用一次。 ⑥拦截器可以获取IOC容器中的各个bean，而过滤器就不行，这点很重要，在拦截器里注入一个service，可以调用业务逻辑。 过滤器 123456@Override public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain)throws IOException, ServletException &#123; System.out.println(\"before...\"); chain.doFilter(request, response); System.out.println(\"after...\"); &#125; chain.doFilter(request, response);这个方法的调用作为分水岭。事实上调用Servlet的doService()方法是在chain.doFilter(request, response);这个方法中进行的。 拦截器 拦截器是被包裹在过滤器之中的。 12345678910111213@Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler)throws Exception &#123; System.out.println(\"preHandle\"); returntrue; &#125; @Override public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView)throws Exception &#123; System.out.println(\"postHandle\"); &#125; @Override public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex)throws Exception &#123; System.out.println(\"afterCompletion\"); &#125; a.preHandle()这个方法是在过滤器的chain.doFilter(request, response)方法的前一步执行，也就是在 [System.out.println(“before…”)][chain.doFilter(request, response)]之间执行。 b.preHandle()方法之后，在return ModelAndView之前进行，可以操控Controller的ModelAndView内容。 c.afterCompletion()方法是在过滤器返回给前端前一步执行，也就是在[chain.doFilter(request, response)][System.out.println(“after…”)]之间执行。 SpringMVC的机制是由同一个Servlet来分发请求给不同的Controller，其实这一步是在Servlet的service()方法中执行的。所以过滤器、拦截器、service()方法，dispatc()方法的执行顺序应该是这样的，大致画了个图：其实非常好测试，自己写一个过滤器，一个拦截器，然后在这些方法中都加个断点，一路F8下去就得出了结论。","categories":[],"tags":[]},{"title":"eclipse-idea","slug":"eclipse-idea","date":"2018-01-18T14:12:28.000Z","updated":"2020-05-23T12:43:24.236Z","comments":true,"path":"posts/27ec56c.html","link":"","permalink":"https://chengtong.me/posts/27ec56c.html","excerpt":"","text":"激活http://idea.lanyus.com/ 配置 sudo vim /etc/hosts 0.0.0.0 account.jetbrains.com 0.0.0.0 www.jetbrains.com 2019.1.2以后版本 第一步将：0.0.0.0 https://account.jetbrains.com:443 加入hosts，不需要0.0.0.0 www.jetbrains.com，不然会影响idea的某些功能 第二步打开cmd终端，输入ipconfig /flushdns，然后回车刷新dns缓存 Eclipse风格修改使用Eclipse风格的快捷键 目的是习惯了使用eclipse的快捷键，在使用IDEA时不想重头记一套新的快捷键。 按照下面的顺序操作 File –\\&gt; settings –\\&gt; keymap –\\&gt; 在下来框中选中Eclipse 辅助代码提示进入Keymap –\\&gt; Main menu –\\&gt; Code –\\&gt; Completion Basic改成：Alt + / SmartType改成：Ctrl + Shift + Space 字体设置菜单的字体和大小推荐设置为14 编辑器字体和大小推荐设置为16 Settings –\\&gt; Editor –\\&gt; Colors &amp; Fonts –\\&gt; Font调大代码显示字体 Auto ImportAuto Import：自动优化导包（自动删除、导入包） Auto Import的功能是可以帮助我们自动删除无用的包Import(未被引用)，以及自动Import填充尚未导入的包。完全智能化地帮助我们在开发程序时，省略了导包的操作，大大优化了开发的效率。 并且，当你移动某个类改变其路径的时候，这个功能会相应的改变关联的文件中包的路径。 堪称神器。 下面是Auto Import设置步骤详解。 Settings→Editor→General→Auto Import然后勾选Add unambiguous imports on the fly以及Optimize imports on the fly Add unambiguous imports on the fly：快速添加明确的导入。 Optimize imports on the fly：快速优化导入，优化的意思即自动帮助删除无用的导入。 取消勾选自动升级 技巧进入implemented方法时，使用快捷键Ctrl + T即可，不能采用以前在Eclipse的方式：按住Ctrl再点鼠标左键，选择要进入的implemented方法 使用Ctrl + Shift + V，可以从多个之前已经复制的内容列表中，选择要粘贴的内容，可以完成类似于Ditto剪贴板增强软件的功能，非常方便好用","categories":[],"tags":[]},{"title":"nginx设置X-Frame-Options的两种方法","slug":"nginx设置X-Frame-Options的两种方法","date":"2018-01-18T08:32:00.000Z","updated":"2020-05-23T12:43:24.101Z","comments":true,"path":"posts/24d6d861.html","link":"","permalink":"https://chengtong.me/posts/24d6d861.html","excerpt":"","text":"本文介绍nginx分别通过http和server设置 X-Frame-Options ，防止网站被别人用iframe嵌入使用。需要说明的是，只需用其中一个方法即可，在http配置代码块或server配置代码块里设置。 在http配置里设置X-Frame-Options 在server配置里设置X-Frame-Options 在http配置里设置X-Frame-Options打开nginx.conf，文件位置一般在安装目录 /usr/local/nginx/conf 里。 然后在http配置代码块里某一行添加如下语句即可： add_header X-Frame-Options SAMEORIGIN; 如图所示： 在http配置里设置X-Frame-Options 添加后，重启nginx，命令是： /usr/local/nginx/sbin/nginx -s reload 即可生效。 在server配置里设置X-Frame-Options在server配置里设置X-Frame-Options跟在http配置里设置X-Frame-Options方法是一样的，同样是在server的配置代码块里添加如下语句即可： add_header X-Frame-Options SAMEORIGIN; 如图所示： 在server配置里设置X-Frame-Options 添加后，重启nginx，命令是： /usr/local/nginx/sbin/nginx -s reload 即可生效。 知识扩展X-Frame-Options 响应头 X-Frame-Options HTTP 响应头是用来给浏览器指示允许一个页面可否在 , 或者 中展现的标记。网站可以使用此功能，来确保自己网站的内容没有被嵌到别人的网站中去，也从而避免了点击劫持 (clickjacking) 的攻击。 X-Frame-Options 有三个值: DENY表示该页面不允许在 frame 中展示，即便是在相同域名的页面中嵌套也不允许。 SAMEORIGIN表示该页面可以在相同域名页面的 frame 中展示。 ALLOW-FROM uri表示该页面可以在指定来源的 frame 中展示。 换一句话说，如果设置为 DENY，不光在别人的网站 frame 嵌入时会无法加载，在同域名页面中同样会无法加载。另一方面，如果设置为 SAMEORIGIN，那么页面就可以在同域名页面的 frame 中嵌套。","categories":[],"tags":[]},{"title":"用IDEA反向生成javabean","slug":"用IDEA反向生成javabean","date":"2018-01-17T13:27:43.000Z","updated":"2020-05-23T12:43:24.279Z","comments":true,"path":"posts/a2547652.html","link":"","permalink":"https://chengtong.me/posts/a2547652.html","excerpt":"","text":"1.首先用idea创建一个新项目，选择java=》java EE Persistence 2.创建完成后，点击IDEA右边Database,点击+，新建Data source 3.选择要建立的数据库，填写连接信息，点击测试按钮，如果变绿色则测试通过。 4.然后点击左下角Persistence标签，右键项目选择Generate Persistence Mapping=\\&gt;By Data Scheme 5.然后选择刚刚新建的数据源，选中要生产的数据库表，下面有两个不同选项，一个生成xml形式，另一个生成注解形式。 6.点击确定javabean就生成了，需要注意的是，有些类型会识别的不太好，需要自行修改。","categories":[],"tags":[]},{"title":"Seafile和Nextcloud相比较哪个好用","slug":"Seafile和Nextcloud相比较哪个好用","date":"2018-01-08T16:00:01.000Z","updated":"2020-05-23T12:43:24.166Z","comments":true,"path":"posts/ef57a426.html","link":"","permalink":"https://chengtong.me/posts/ef57a426.html","excerpt":"","text":"面对大量的照片视频，备份资料成了很多网友的刚需。但现在各大免费网盘，关闭地关闭，收费的收费，自建网盘成了一个不得已的选择。可以自建私有网盘的网盘程序最出名的要数Seafile和Nextcloud，一款国产、一款外国产，那么怎么选择呢，很多人可能陷入了纠结。正好我最近拿这两款程序试了下，把我的体会写下来，以作参考。 一、PC网页端1.Seafile 2.Nextcloud 每个人的审美不一样，我个人觉得Nextcloud要好看一点。 二、客户端两款程序都比较齐全，全平台支持，最常用的手机端差距主要有以下几点：1.Nextcloud的ios客户端收费。2.Nextcloud手机端自动同步功能缺失，虽然有设置项，但是无法正常使用，只能手动上传。而Seafile这个功能正常。3.Nextcloud手机端无法在线播放视频，Seafile可以播放，虽然有点问题（在有的视频进度条显示不正常，无法拖动）。总的来讲，Seafile手机客户端要强不少。 三、服务端部署便捷性Seafile是由Python开发，有一键部署脚本，无论是windows还是linux平台部署都比较简单，但是linux的一键脚本还不够自动化，开机启动，webdav等功能需要手动配置脚本，好在国产程序文档比较清楚，有点基础的一般不难配置成功。Nextcloud是PHP开发，所以部署必须依赖PHP环境，一般安装LAMP或者LNMP环境，一键安装脚本也比较多。但是这个程序对环境要求较高，最新版本的程序要求PHP版本至少7.0，并依赖很多PHP组建，都需要手动安装配置，比如缓存。并且LNMP环境部署起来问题多多，颇为费劲。所以建议还是选择LAMP环境部署。环境部署好后，程序的安装比较简单，配置好数据库就行。总体上，Seafile部署相对容易一点，并且耗时较短，半个小时以内部署完一般没有问题。Nextcloud部署比较费时，光PHP环境就费时不少。 四、性能这个也是大家比较关心的问题。从我使用的感受来讲，Seafile的性能要高Nextcloud不少，尤其是首次打开页面速度，Seafile快很多。此外上传稳定性Seafile也要好不少，尤其是大文件的上传，Nextcloud经常中断，Seafile虽然也会有，但是比较少。 五、功能基本上两款程序大部分基本的功能都是提供的，Seafile有的功能要收费版才有，但对大部分人来说免费版应该也够了。Nextcloud最大的亮点是有APPStore，提供了大量的扩展插件，为功能扩展提供了广阔的空间，比如外挂网盘这个插件功能非常实用，能外挂Webdav空间、Google网盘、FTP等等。而Seafile就没有提供插件扩展。此外，Nextcloud的文件是完整存储在服务器上，如果网盘挂了，直接把存储文件复制出来就可以了。而Seafile的文件是分块存储在服务器上，主要是为了大文件上传的稳定性，和断点续传，但也为备份文件带来了一些不便，虽然官方提供了备份工具，但也有好处，就是保密性会好一点，直接复制的文件没法直接用。两款网盘各有特色亮点，我选择了Seafile作为我的私人存储，主要考虑还是稳定性。","categories":[],"tags":[]},{"title":"centos7仅安装mysql客户端","slug":"centos7仅安装mysql客户端","date":"2017-12-19T08:21:53.000Z","updated":"2020-05-23T12:43:24.005Z","comments":true,"path":"posts/ef7a7f28.html","link":"","permalink":"https://chengtong.me/posts/ef7a7f28.html","excerpt":"","text":"安装 rpm源 1rpm -ivh https://repo.mysql.com//mysql57-community-release-el7-11.noarch.rpm 安装 1234#可以通过yum搜索yum search mysql-community#笔者安装的是64位yum install -y mysql-community-client.x86_64","categories":[{"name":"数据库","slug":"数据库","permalink":"https://chengtong.me/categories/数据库/"}],"tags":[{"name":"CentOS","slug":"CentOS","permalink":"https://chengtong.me/tags/CentOS/"},{"name":"MySQL","slug":"MySQL","permalink":"https://chengtong.me/tags/MySQL/"}]},{"title":"CentOS7.4使用yum源安装MySQL 5.7.20","slug":"CentOS7.4使用yum源安装MySQL 5.7.20","date":"2017-12-19T05:04:54.000Z","updated":"2020-05-23T12:43:23.936Z","comments":true,"path":"posts/a9414c3.html","link":"","permalink":"https://chengtong.me/posts/a9414c3.html","excerpt":"","text":"从CentOS 7.0发布以来，yum源中开始使用Mariadb来代替MySQL的安装。即使你输入的是yum install -y mysql , 显示的也是Mariadb的安装内容。使用源代码进行编译安装又太麻烦。因此，如果想使用yum安装MySQL的话，就需要去下载官方指定的yum源，网址为：https://dev.mysql.com/downloads/repo/yum/找到Red Hat Enterprise Linux 7 / Oracle Linux 7 (Architecture Independent), RPM Package，单击后面的Download，在新的页面中单击最下面的No thanks, just start my download.就可以下载到yum源了。下面将进行MySQL的安装： 1. 首先进入本机的源文件目录12mkdir -p /opt/srccd /opt/src 2. 使用wget下载官方yum源的rpm包：1wget https://dev.mysql.com/get/mysql57-community-release-el7-11.noarch.rpm 3. 安装rpm包：1rpm -ivh mysql57-community-release-el7-11.noarch.rpm 4. 再次使用yum来安装mysql-server:1yum install -y mysql-server 可以看到这次不再提示安装Mariadb了 5. 安装完成后，启动mysqld服务：1systemctl start mysqld 查看是否成功启动： 1ps aux|grep mysqld 6. 设置mysqld服务开机自启动：1systemctl enable mysqld 7. 使用初始密码登录由于MySQL从5.7开始不允许首次安装后，使用空密码进行登录，系统会随机生成一个密码以供管理员首次登录使用，这个密码记录在/var/log/mysqld.log文件中，使用下面的命令可以查看此密码： 12cat /var/log/mysqld.log|grep 'A temporary password'2017-11-12T13:35:37.013617Z 1 [Note] A temporary password is generated for root@localhost: bkv,dy,)o7Ss 最后一行冒号后面的部分bkv,dy,)o7Ss就是初始密码。使用此密码登录MySQL: 1mysql -u root -p 8. 更改默认密码：切换数据库： 1use mysql; 修改root密码： 1alter user &apos;root&apos;@&apos;localhost&apos; identified by &apos;your_password&apos;; 将your_password替换成你自己的密码就可以了，当然，这个密码是强密码，要求密码包含大小写字母、数字及标点符号，长度应该在6位以上。重新使用新的密码登录，如果可以正常登录说明你的MySQL已经成功安装在CentOS 7.4上了","categories":[{"name":"数据库","slug":"数据库","permalink":"https://chengtong.me/categories/数据库/"}],"tags":[{"name":"CentOS","slug":"CentOS","permalink":"https://chengtong.me/tags/CentOS/"},{"name":"MySQL","slug":"MySQL","permalink":"https://chengtong.me/tags/MySQL/"}]},{"title":"Shell在文本第一行和最后一行添加字符串","slug":"shell在文本第一行和最后一行添加字符串","date":"2017-12-16T05:04:54.000Z","updated":"2020-05-22T02:03:24.975Z","comments":true,"path":"posts/17657829.html","link":"","permalink":"https://chengtong.me/posts/17657829.html","excerpt":"","text":"1234sed -i '1i 添加的内容' file #这是在第一行前添加字符串sed -i '$i 添加的内容' file #这是在最后一行行前添加字符串sed -i '$a添加的内容' file #这是在最后一行行后添加字符串echo \"添加的内容\" &gt;&gt; file #这是在最后一行行后添加字符串","categories":[{"name":"Linux","slug":"Linux","permalink":"https://chengtong.me/categories/Linux/"}],"tags":[{"name":"Shell","slug":"Shell","permalink":"https://chengtong.me/tags/Shell/"}]},{"title":"iPic-Markdown Mac图床、文件上传工具","slug":"iPic-Markdown-Mac图床、文件上传工具","date":"2017-11-28T02:26:15.000Z","updated":"2020-05-22T02:03:24.970Z","comments":true,"path":"posts/6ca1c9fd.html","link":"","permalink":"https://chengtong.me/posts/6ca1c9fd.html","excerpt":"","text":"有了图床神器 iPic，不论屏幕截图、还是复制图片，都可以自动上传、保存 Markdown 格式的链接，直接粘贴插入，够懒人吧？ 使用 Hexo | Heroku 或 WordPress 写博客、在公众号发文章、在知乎讨论、在豆瓣灌水、在论坛发帖、跨境做外贸电商 … iPic 带给你从未有过的插图体验。 当然，除了图片，你可以 上传普通文件 ，上传方式与图片完全相同。 上传方式图床工具 iPic 支持多种图片上传方式。下面我们来简单看下各个上传方式、以及分别适合在什么场景下使用。 1.拖拽图片上传拖动是比较好玩的一种上传方式。只要将图片拖到菜单栏的 iPic 图标上，松手后就可以自动上传。 可以注意到，上传时菜单栏图标也会显示上传的进度。很简洁、却很实用，不再盲目等待。 使用这种方式，还可以一次性上传多张图片。图片上传后的顺序，和上传前选择的顺序一致。 2.使用服务上传图片在 Finder 中使用 服务 上传也是很高效的方式。只要在图片上右击、然后选择服务中的 使用 iPic 上传 即可。 除了使用菜单，更高效的方式是使用快捷键。只要选中图片，然后按下 Command + U 快捷键，即可自动上传。 如果你觉得默认快捷键 Command + U 不方便，也可以在 系统偏好设置 \\&gt; 键盘 \\&gt; 快捷键 \\&gt; 服务中修改 使用 iPic 上传 对应的快捷键。同样，如果你的 Mac 中安装了很多程序、菜单中有很多你不需要的服务，也可以在这里进行关闭。 使用服务上传还有其他便利之处： 可以一次性上传多张图片 即使 iPic 并未运行，系统也会启动 iPic、并自动上传 注意：由于 macOS 系统更新机制的缘故，新安装 iPic 后上传服务可能未出现、或未翻译，可以等几分钟、甚至几小时后再试，iPic 上传服务就会正常显示；也可以在 终端 手动更新服务菜单： /System/Library/CoreServices/pbs -update 3.复制图片后上传iPic 会自动监测剪切板的变化，当复制图片后，该图片会出现在 iPic 菜单中 待上传 区域。如果需要上传，点击菜单中该图片即可。手动上传比较适合临时上传少量图片。 除了手动点击菜单，还可以使用快捷键 Command + Shift + U 上传。当然，可以在偏好设置中修改此快捷键。 4.上传其他App中的图片上述示例中主要介绍了图片文件的上传。另外，iPic 还支持支持其他程序中图片的上传。例如： 其中，对于图片格式，常见的 jpg、png、gif 等格式都是支持。 上传图片相关设置上传前压缩图片可以在 iPic 的 偏好设置 中开启「上传前压缩图片」选项，目前支持压缩的图片格式：jpg、png、gif 采用有损压缩，压缩后肉眼几乎无法看出区别，却可明显降低图片尺寸。使用压缩后的图片，既可以节省图片的存储空间，还可以加快图片加载速度、节省流量。 上传后不播放声音iPic 上传后会使用系统通知来提示。如果不喜欢该通知的声音，可进入 系统偏好设置 \\&gt; 通知，在左侧列表选择 iPic，然后在右侧取消「播放通知的声音」。 图床图床也即你选择存放图片的云服务。可以在 iPic 的 偏好设置 中添加你的图床： 添加后，可以在 iPic 的菜单中选择当前使用的图床： 目前 iPic 支持下列图床：微博图床（即默认图床）、七牛云 、又拍云、阿里云 OSS 、腾讯云 COS、Imgur 、Flickr 、Amazon S3 iPic菜单Markdown链接 这里有个很贴心的功能：切换普通链接、Markdown 格式链接时，如果粘贴板中有上一格式的内容，会转换后重新保存到粘贴板中。 图片上传记录iPic 会保存最近上传的 15 张图片，其中最后上传的 3 张图片会出现在一级菜单中，其他的则在 更多已上传图片 中。 点击已上传图片，则会复制该图片的链接。 当然，可以在 更多 菜单中清空图片上传记录。 iPic MoveriPic Mover 可以一键将已有 Markdown 文件中所有图片迁移至新图床。批量上传图片、图床搬家，从未如此简单。 下载 iPic 下载配合默认图床，可免费使用所有功能。如需使用其他图床，订阅 iPic 高级版即可。暂不支持 Windows.","categories":[{"name":"图床","slug":"图床","permalink":"https://chengtong.me/categories/图床/"}],"tags":[{"name":"iPic","slug":"iPic","permalink":"https://chengtong.me/tags/iPic/"}]},{"title":"基于docker-compose搭建分布式消息队列Kafka","slug":"基于docker-compose搭建分布式消息队列Kafka","date":"2017-11-24T14:33:34.000Z","updated":"2020-05-22T02:03:24.985Z","comments":true,"path":"posts/7fb66013.html","link":"","permalink":"https://chengtong.me/posts/7fb66013.html","excerpt":"","text":"本文基于Docker Compose搭建一套单节点的Kafka消息队列，Kafka依赖Zookeeper为其管理集群信息，虽然本例不涉及集群，但是该有的组件都还是会有，典型的kafka分布式架构如下图所示。本例搭建的示例包含Zookeeper + Kafka + Kafka-manger Kafka官网： http://kafka.apache.org/ 重要概念生产者(Producer)消费者(Consumer)消费消息。每个consumer属于一个特定的consumer group。使用consumer high level API时，同一个topic的一条消息只能被同一个consumer group内的一个consumer消费，但多个consumer group可同时消费这一消息。 集群(Cluster)宏观来看，Kafka主体包含的就是三部分: 生产者、消费者和集群，一个集群就是多个Broker的集合。 Broker已经发布的消息就会保存在集群中的某个Broker中去。 Topic用来区别message的种类，比如很多时候，与A相关的日志统一的topic定义为A，B相关的日志统一的topic定义为B，这样就不用一个一个单独地订阅了。物理上不通topic的消息分开存储，逻辑上一个topic的消息虽然保存于一个或多个broker上，但是用户只需指定消息的topic即可生产或消费数据而不必关心数据在哪里。 PartitionKafka中每个Topic都会有一个或多个Partition，他是Kafaka数据存储的基本单元，每个Partition对应一个文件夹，文件夹下存储这个Partition的所有消息和索引。Kafka内部会根据算法得出一个值，根据这个值放入对应的partition目录中。所以读取时间复杂度为O(1)。分区的每一个消息都有一个连续的序列号叫做offset，用来在分区中唯一标识这个消息。一个topic可以保存在多个partition。 Segment一个partition由多个Segment组成，一个Partition代表一个文件夹，一个Segment则代表该文件夹下的文件。Segment有大小限制，由log.segment.bytes 定义。 安装Docker Compose方式安装docker-compose.yml文件:123456789101112131415161718192021222324252627282930313233version: '2'services: zookeeper: image: wurstmeister/zookeeper environment: JMX: 9000 ports: - \"2181:2181\" kafka: image: wurstmeister/kafka #这个镜像使用文档见https://github.com/wurstmeister/kafka-docker ports: - \"9092:9092\" expose: - \"9092\" environment: KAFKA_ADVERTISED_HOST_NAME: 10.19.131.157 #docker宿主机的IP，直接ifconfig获取，这是重点，否则，在容器内部启动生产者消费者都会失败的 KAFKA_CREATE_TOPICS: \"test:1:1\" #自动创建一个默认的topic KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181 KAFKA_AUTO_CREATE_TOPICS_ENABLE: \"false\" #禁用掉自动创建topic的功能，使用上面的镜像，kafka的参数设置都可以以这样的方式进行设置 volumes: - /var/run/docker.sock:/var/run/docker.sock kafka-manager: image: sheepkiller/kafka-manager #如果要安装web管理工具可以同时安装这个，最后通过宿主机IP的9000端口进行访问，例如http://127.0.0.1:9000/ links: - kafka - zookeeper environment: ZK_HOSTS: zookeeper:2181 APPLICATION_SECRET: \"letmein\" ports: - \"9000:9000\" expose: - \"9000\" 安装命令:12345678910111213#默认只会有一个kafka实例docker-compose up -d/* 运行kafka集群模式 *//* 由于指定了kafka对外暴露的端口号，增加集群节点会报端口冲突的错误，请将kafka暴露的端口号删掉后再执行如下命令 动态端口：将- \"9092:9092\"更改为- \"9092\"，去掉expose:- \"9092\"，这种会生成动态端口；非动态端口，就是自己指定端口和对应实例个数即可 *//* 自己指定kafka的节点数量 */#将kafka实例增加到n个，推荐使用3个，就能直接建立一个集群docker-compose scale kafka=3# 暂停所有容器docker-compose stop# 开启所有容器docker-compose start# 删除所有容器docker-compose rm -f webKafka Managerhttp://127.0.0.1:9000/ Cluster——》addCluster——》Cluster Name——》my-kafka Cluster Zookeeper Hosts——》zookeeper:2181其他默认即可，Save kafka命令1docker exec -it data_kafka_1 bash kafka-console-consumer.sh12#启动一个消费者，监听test这个topickafka-console-consumer.sh --bootstrap-server 10.19.131.157:9092 --from-beginning --topic test kafka-console-producer.sh12#启动一个生产者，直接输入消息回车即可发送消息了kafka-console-producer.sh --broker-list 10.19.131.157:9092 --topic test kafka-consumer-groups.sh1234#查看新消费者列表kafka-consumer-groups.sh --new-consumer --bootstrap-server 10.19.131.157:9092 --list#查看某消费者的消费详情，这里的消费者名称就是kafka-python-default-groupkafka-consumer-groups.sh --new-consumer --bootstrap-server 10.19.131.157:9092 --describe --group kafka-python-default-group kafka-producer-perf-test.sh自带的压测工具12#总共100条数据，每条大小是1kafka-producer-perf-test.sh --topic test --num-records 10000 --record-size 1 --throughput 100 --producer-props bootstrap.servers=10.19.131.157:9092 kafka-topics.sh1234#列出所有的topickafka-topics.sh --list --zookeeper zookeeper:2181#查看集群描述kafka-topics.sh --describe --zookeeper zookeeper:2181 安全认证Kafka可以配合SSL+ACL来进行安全认证: http://orchome.com/185 TroubleShooting容器内部启动生产者出现错误:log[2016-12-26 03:03:39,983] WARN Error while fetching metadata with correlation id 0 : {test=UNKNOWN_TOPIC_OR_PARTITION} (org.apache.kafka.clients.NetworkClient) 是因为docker-compose文件里面的宿主讥IP设置出错，如果是动态IP的话就没办法了，只能删除重新创建了","categories":[{"name":"消息队列","slug":"消息队列","permalink":"https://chengtong.me/categories/消息队列/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://chengtong.me/tags/Docker/"},{"name":"Docker Compose","slug":"Docker-Compose","permalink":"https://chengtong.me/tags/Docker-Compose/"},{"name":"Kafka","slug":"Kafka","permalink":"https://chengtong.me/tags/Kafka/"}]},{"title":"基于Docker搭建分布式消息队列Kafka","slug":"基于Docker搭建分布式消息队列Kafka","date":"2017-11-23T14:33:34.000Z","updated":"2020-05-22T02:03:24.984Z","comments":true,"path":"posts/4d1930e3.html","link":"","permalink":"https://chengtong.me/posts/4d1930e3.html","excerpt":"","text":"本文基于Docker搭建一套单节点的Kafka消息队列，Kafka依赖Zookeeper为其管理集群信息，虽然本例不涉及集群，但是该有的组件都还是会有，典型的kafka分布式架构如下图所示。本例搭建的示例包含Zookeeper + Kafka + Kafka-manger Kafka官网： http://kafka.apache.org/ 重要概念 生产者(Producer) 消费者(Consumer) 消费消息。每个consumer属于一个特定的consumer group。使用consumer high level API时，同一个topic的一条消息只能被同一个consumer group内的一个consumer消费，但多个consumer group可同时消费这一消息。 集群(Cluster) 宏观来看，Kafka主体包含的就是三部分: 生产者、消费者和集群，一个集群就是多个Broker的集合。 Broker 已经发布的消息就会保存在集群中的某个Broker中去。 Topic 用来区别message的种类，比如很多时候，与A相关的日志统一的topic定义为A，B相关的日志统一的topic定义为B，这样就不用一个一个单独地订阅了。物理上不通topic的消息分开存储，逻辑上一个topic的消息虽然保存于一个或多个broker上，但是用户只需指定消息的topic即可生产或消费数据而不必关心数据在哪里。 Partition Kafka中每个Topic都会有一个或多个Partition，他是Kafaka数据存储的基本单元，每个Partition对应一个文件夹，文件夹下存储这个Partition的所有消息和索引。Kafka内部会根据算法得出一个值，根据这个值放入对应的partition目录中。所以读取时间复杂度为O(1)。分区的每一个消息都有一个连续的序列号叫做offset，用来在分区中唯一标识这个消息。一个topic可以保存在多个partition。 Segment 一个partition由多个Segment组成，一个Partition代表一个文件夹，一个Segment则代表该文件夹下的文件。Segment有大小限制，由log.segment.bytes 定义。 #获取镜像 zookeeper镜像：zookeeper:3.4.9 kafka镜像：wurstmeister/kafka:0.10.2.0 kafka-manager镜像：kafka-manager:latest 建立Zookeeper容器这里我们用最简单的方式创建一个独立的Zookeeper节点，如果要考虑zookeeper的高可用，可以将其做成一个集群，最好是能有多台机器。1234docker run --name some-zookeeper \\--restart always \\-p 2181:2181 \\-d zookeeper 默认的，容器内配置文件在，/conf/zoo.cfg，数据和日志目录默认在/data 和 /datalog，需要的话可以将上述目录映射到宿主机的可靠文件目录下。详情参考Zookeeper官方镜像 建立kafka节点这里同样只做一个简单的单点kafka123456docker run --name kafka \\-p 9092:9092 \\-e KAFKA_ADVERTISED_HOST_NAME=kafka01 \\-e KAFKA_CREATE_TOPICS=\"test:1:1\" \\-e KAFKA_ZOOKEEPER_CONNECT=10.19.131.157:2181 \\-d wurstmeister/kafka 详情参考Kafka官方镜像 创建Kafka管理节点kafka-manager有图形化UI，可以方便的监控集群状态，调整队列配置123456docker run -itd \\--restart=always \\--name=kafka-manager \\-p 9000:9000 \\-e ZK_HOSTS=\"10.19.131.157:2181\" \\sheepkiller/kafka-manager 容器启动以后访问主机的9000端口，http://127.0.0.1:9000 读写验证读写验证的方法有很多，这里我们用kafka容器自带的工具来验证，首先进入到kafka容器的交互模式：1docker exec -it kafka /bin/bash 创建一个主题： 1/opt/kafka/bin/kafka-topics.sh --create --zookeeper 10.19.131.157:2181 --replication-factor 1 --partitions 1 --topic my-test 查看刚创建的主题： 1/opt/kafka/bin/kafka-topics.sh --list --zookeeper 10.19.131.157:2181 发送消息： 1/opt/kafka/bin/kafka-console-producer.sh --broker-list 10.19.131.157:9092 --topic my-test 读取消息： 1/opt/kafka/bin/kafka-console-consumer.sh --bootstrap-server 10.19.131.157:9092 --topic my-test --from-beginning 参考：https://kafka.apache.org/quickstart","categories":[{"name":"消息队列","slug":"消息队列","permalink":"https://chengtong.me/categories/消息队列/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://chengtong.me/tags/Docker/"},{"name":"Kafka","slug":"Kafka","permalink":"https://chengtong.me/tags/Kafka/"}]},{"title":"安装Python及环境变量配置","slug":"安装Python及环境变量配置","date":"2017-11-01T14:05:30.000Z","updated":"2020-05-23T12:43:24.293Z","comments":true,"path":"posts/f66662b8.html","link":"","permalink":"https://chengtong.me/posts/f66662b8.html","excerpt":"","text":"一、Windows系统很多童鞋问之前的教程怎么没有介绍安装python3.5的，现予以补充更新一下。 （一）安装python3.51、下载进入Python官网www.python.org，在“Downloads”下拉菜单中的右半部分直接点击python3.5.2版本即可下载，它会自动下载32位的。 如果需要64位，点击左半部分“Windows”，选择第二项“Latest Python 3 Release - Python 3.5.2”。 在“Files”里选择倒数第五个“Windows x86-64 executable installer”下载。 2、安装安装刚才已经下载下来的安装包， 安装过程下图所示，使用默认配置，选择“Install Now”,勾选下面的Add Python3.5 to PATH。 （二）安装python2.71、下载进入Python官网www.python.org，在“Downloads”下拉菜单中的右半部分直接点击即可下载，从兼容方面考虑建议下载Python 2.7版本。 如果想要下载64位的，点击左半部分“Windows”，选择第一项“Latest Python 2 Release - Python 2.7.11”， 在“Files”里选择倒数第二个“Windows x86-64 MSI installer”下载。 2、安装安装刚才已经下载下来的安装包， 安装过程下图所示，一路默认操作。 3、配置右击桌面上的“此电脑”—&gt;“属性”—&gt;“高级系统设置”—&gt;右下角“环境变量”—&gt;双击“系统变量”里的“Path”—&gt;点击“新建”—&gt;输入刚才的安装位置“C:\\Python27;”，得到新建后的结果，然后一步步确定回去。 win+R，cmd调出命令行，输入命令“python”，就可以有相关显示。 二、Ubuntu系统如果计算机的操作系统是Linux的某个发行版，比如Ubuntu 等，我这里是用elementary OS亲测的，其实都大同小异，因为它们都已经安装好了Python的编程环境，只需要打开终端Shell，输入python，回车之后就会出现跟上文windows中类似的结果。如果没有该编程环境，就需要另外安装了，最简单的方法是在终端输入sudo apt-get install python 那么如何升级自带的初始2.7版本到3.5呢，步骤如下：sudo apt-get install python3.5由于默认使用的是Python2，据了解，版本2和3并不兼容，但底层又使用的是2，故不能卸载2，只需要将默认的Python指向到3即可。sudo rm /usr/bin/pythonsudo ln -s /usr/bin/python3.5 /usr/bin/python 【引申】python现在主要使用的有2个版本：2.x和3.x，而这2个版本的语法却有很多的不同，python3.x并不是向下兼容2.x的。虽然说3.x是未来python的主流，但是很多工具和个人还是倾向于python2.x，所以有时可能同时用到这两个版本，这时在同一台电脑上安装2个python版本就很有必要了。","categories":[{"name":"Python","slug":"Python","permalink":"https://chengtong.me/categories/Python/"}],"tags":[]},{"title":"支付宝红包码","slug":"支付宝红包码","date":"2017-10-31T16:12:31.000Z","updated":"2020-05-22T02:03:25.135Z","comments":true,"path":"posts/6a3c93e4.html","link":"","permalink":"https://chengtong.me/posts/6a3c93e4.html","excerpt":"","text":"发红包、领红包、支付宝红包码","categories":[],"tags":[]},{"title":"WebP在减少图片体积和流量上的效果如何？MIP技术实践分享","slug":"WebP在减少图片体积和流量上的效果如何？MIP技术实践分享","date":"2017-10-23T11:30:50.000Z","updated":"2020-05-22T02:03:24.897Z","comments":true,"path":"posts/7109808e.html","link":"","permalink":"https://chengtong.me/posts/7109808e.html","excerpt":"","text":"作者 | Jackson编辑 | 尾尾 不论是 PC 还是移动端，图片一直占据着页面流量的大头，在图片的大小和质量之间如何权衡，成为了长期困扰开发者们的问题。而 WebP 技术的出现，为解决该问题提供了好的方案。本文将为大家详细介绍 WebP 技术，同时也会分享该技术在 MIP 项目中的实践。 什么是WebP？WebP 是由 Google 收购 On2 Technologies 后发展出来的图片格式，以 BSD 授权条款发布。目前已经在不同厂商之间进行了尝试，如 Google、Facebook、ebay、百度、腾讯、淘宝等。 为什么选择WebP？WebP的优势WebP 在支持有损、无损、透明图片压缩的同时，大大减少了图片的体积。据统计，WebP 无损压缩后比 PNG 图片体积减少了 26%，有损图片比同类 JPEG 图像体积减少了 25%~34%，下面总结 WebP 在不同指标上所能获得的提升对比。 体积和流量方面根据业界给出的改造数据可知，改造 WebP 之后图片体积会降低很多，具体可参照 WebP 体积测试，同时也可参照下图。 在 MIP 项目中，通过我们的本地测试获得的数据如下图所示。 从以上测试可知，如果将体积换算成带宽，WebP 不同模式下都会节省大量流量。科技博客 Gig‍‍‍aOM 曾报道，谷歌的 Chrome 网上应用商店采用 WebP 格式图片后，每天可以节省几 TB 的带宽；Google+ 移动应用采用 WebP 图片格式后，每天节省了 50TB 数据存储空间。 速度方面图片的加载速度还要取决于网络时间，所以我们没有测试确定的数据，不过可以参考业界的数据：科技博客 Gig‍‍‍aOM 曾报道，YouTube 的视频略缩图采用 WebP 格式后，网页加载速度提升了 10%；谷歌的 Chrome 网上应用商店采用 WebP 格式图片后，页面平均加载时间大约减少 1/3。 兼容性目前来说，WebP 的支持程度也在不断上升，据 2017 年 10 月 12 日在 can i use 上的查询显示，全球 WebP 的支持程度已经达到 73.64%，如下图所示。 而也正是因为这种天然的图片体积优势和发展趋势，MIP 团队也决定进行初步的实践尝试，以提升页面用户体验。 WebP实践经验如何判断浏览器支持程度？WebP 的判断方法在 官方文档 中进行了总结，大致分为 HTML5 picture、嗅探和 Request Header 三种方式，下面展开介绍这三种方式。 HTML5 picture这种方法不进行 WebP 支持程度的判断，而是利用 html5 picture 元素的特性，允许开发者列举出多个图片地址，浏览器根据顺序展示出第一个能够展现的图片元素，如 1234&lt;picture&gt; &lt;source type=\"image/webp\" srcset=\"images/webp.webp\"&gt; &lt;img src=\"images/webp.jpg\" alt=\"webp image\"&gt;&lt;/picture&gt; 上面的示例在浏览器不支持 WebP 图片的情况下自动回退到 jpg 格式进行展示，但 picture 的支持程度还不是很完善，开发者可以根据需求决定是否进行使用。 嗅探嗅探的方式是指直接向浏览器中插入一段 base64 的 WebP 图片，检测图片是否能够正常加载，依据该方法进而判断支持程度，如官方给出的嗅探函数： 1234567891011121314151617181920// check_webp_feature:// 'feature' can be one of 'lossy', 'lossless', 'alpha' or 'animation'.// 'callback(feature, result)' will be passed back the detection result (in an asynchronous way!)function check_webp_feature(feature, callback) &#123; var kTestImages = &#123; lossy: \"UklGRiIAAABXRUJQVlA4IBYAAAAwAQCdASoBAAEADsD+JaQAA3AAAAAA\", lossless: \"UklGRhoAAABXRUJQVlA4TA0AAAAvAAAAEAcQERGIiP4HAA==\", alpha: \"UklGRkoAAABXRUJQVlA4WAoAAAAQAAAAAAAAAAAAQUxQSAwAAAARBxAR/Q9ERP8DAABWUDggGAAAABQBAJ0BKgEAAQAAAP4AAA3AAP7mtQAAAA==\", animation: \"UklGRlIAAABXRUJQVlA4WAoAAAASAAAAAAAAAAAAQU5JTQYAAAD/////AABBTk1GJgAAAAAAAAAAAAAAAAAAAGQAAABWUDhMDQAAAC8AAAAQBxAREYiI/gcA\" &#125;; var img = new Image(); img.onload = function () &#123; var result = (img.width &gt; 0) &amp;&amp; (img.height &gt; 0); callback(feature, result); &#125;; img.onerror = function () &#123; callback(feature, false); &#125;; img.src = \"data:image/webp;base64,\" + kTestImages[feature];&#125; 其中包含了对有损、无损、透明图、动图等 WebP 图片的嗅探，这是一种最为保险的方法。不过缺点也很明显，在图片类型不一且量级较大的情况下，前端并不能知道哪些图片是有损，无损，亦或是透明的，也没有办法对其中一种特定类型做特定策略，所以即使知道不支持该类型的 WebP，然而我们也没有办法主观的去做容错。所以 ** 这种方法只适合于图片类型单一 ** 的情况，如开发者知道所有图片都是有损的，或是动图等，有针对性的去处理。 同时在处理的过程中，为了提高嗅探效率，嗅探之后可以将结果以本地存储的方式进行保存，如 cookie ，方便下次直接进行调用。 Request Header这种方式是较为符合标准的解决方案，浏览器在支持 WebP 图片格式的情况下，会在请求的 http header accept 中携带 webp/image 的字段，后端接收到请求之后可以按照该形式来判断是否返回 WebP 图片内容。 MIP 在实践中采用的是该方法，当用户访问 MIP Cache 上的页面时，不需要开发者替换图片，MIP Cache 根据 http header 自动决定是否返回 WebP 图片内容。 不过这个过程也依然有坑——国内浏览器层出不群，大部分都向标准化的方向靠近，但仍然需要一定的时间来跟进。所以，在实践过程中我们就发现了这样的问题：虽然 http header accept 中包含了 webp/image 的字段，但实际上是不支持 WebP 格式的（华为 MT7 自带浏览器），具体体现在动图（animation）的 feature 上。而相应的解决方案其实也很简单，就是在 WebP 图片加载失败后发起原图请求，让图片能够正确的展示在页面上，具体方式是通过 img onerror 函数执行对应逻辑。 WebP转换工具WebP 的转换工具很多，主要包含了命令行和可视化界面两种： 命令行官方对于每一种 WebP 格式也分别提供了对应的 转换工具，主要包含了 cwebp、dwebp、vwebp、webpmux、gif2webp 等几种，开发者可以择优选择。 可视化页面也提供了不同可视化的软件进行 WebP 格式图片转换，如：iSparta。 总结WebP 作为一种新型图片格式，不但能够节省流量，减少图片体积，一定程度上也可以优化用户体验。MIP 项目对于 WebP 支持目前已上线，大家可以浏览 MIP 页面进行体验。同时作为关注速度优化的 MIP 团队，我们将不断迭代前行，致力于打造极致的用户体验。","categories":[{"name":"图片格式","slug":"图片格式","permalink":"https://chengtong.me/categories/图片格式/"}],"tags":[{"name":"WebP","slug":"WebP","permalink":"https://chengtong.me/tags/WebP/"}]},{"title":"Centos7/Ubuntu初始化硬盘分区、挂载","slug":"Centos7 Ubuntu 初始化硬盘分区、挂载","date":"2017-09-29T03:07:00.000Z","updated":"2020-05-23T12:43:24.182Z","comments":true,"path":"posts/f65d6fec.html","link":"","permalink":"https://chengtong.me/posts/f65d6fec.html","excerpt":"","text":"一、查看信息1、查看硬盘信息1fdisk -l 可以看到有两块硬盘/dev/vda和/dev/vdb，启动vda是系统盘vdb是我们新增的数据盘。 2、查看磁盘格式1df -T 二、分区执行以下命令，进入fdisk模式，开始对新增数据盘执行分区操作。 fdisk 新增数据盘 以新挂载的数据盘“/dev/vdb”为例：1fdisk /dev/vdb 提示：然后根据提示，依次输入：”n“、”p“、”1“、两次回车，”pw“，分区也就开始了并很快就可完成。 回显类似如下信息： 1、输入“n”，按“Enter”，开始新建分区。 回显类似如下信息： 表示磁盘有两种分区类型： “p”表示主要分区。 “e”表示延伸分区。 2、以创建一个主要分区为例，输入“p”，按“Enter”，开始创建一个主分区。回显类似如下信息： “Partition number”表示主分区编号，可以选择1-4。 3、以分区编号选择“1”为例，输入主分区编号“1”，按“Enter”。回显类似如下信息 “First sector”表示初始磁柱区域，可以选择2048-20971519，默认为2048。 4、以选择默认初始磁柱编号2048为例，按“Enter”。回显类似如下信息： Last sector”表示截止磁柱区域，可以选择2048-104857599，默认为104857599。 5、以选择默认截止磁柱编号2104857599为例，按“Enter”。回显类似如下信息： 表示分区完成，即为50GB的数据盘新建了1个分区。 6、输入“p”，按“Enter”，查看新建分区的详细信息。回显类似如下信息： 表示新建分区“/dev/vdb1”的详细信息。 7、输入“w”，按“Enter”，将分区结果写入分区表中。回显类似如下信息： 表示分区创建完成。 8、执行以下命令，将新的分区表变更同步至操作系统。1partprobe 执行以下命令，将新建分区文件系统设为系统所需格式。mkfs -t 文件系统格式 /dev/vdb1 以设置文件系统为“ext4”为例：1mkfs -t ext4 /dev/vdb1 回显类似如下信息： 格式化需要等待一段时间，请观察系统运行状态，不要退出。 三、挂载1、新建挂载点执行以下命令，新建挂载点。 mkdir 挂载点 以新建挂载点“/data”为例：( 先创建一个data的文件夹)1mkdir /data 2、挂载执行以下命令，将新建分区挂载到/data新建的挂载点下。 mount /dev/vdb1 挂载点 以挂载新建分区至“/data”为例：1mount /dev/vdb1 /data 执行以下命令，查看挂载结果。 1df -TH 表示新建分区“/dev/vdb1”已挂载至“/data”。 四、设置开机自动挂载磁盘参数说明 1vim /etc/fstab UUID=8a9e725a-7c6f-4e67-a160-669c343e1e62 / ext4 defaults 1 1 第一字段:分区设备文件名或UUID(硬盘通用唯一识别码 可通过dumpe2fs 分区设备文件名 查看)第二字段:挂载点第三字段:文件系统名称第四字段:挂载参数第五字段:指定分区是否被dump备份,0代表不备份,1代表每天备份,2代表不定期备份第六字段:指定分区是否被fsck检测,0代表不检测,其它数字代表检测的优先级,1的优先级比2高 1、传统主机 修改系统挂载硬盘的文件，其中0 0 表示在在开机时不对分区进行检查 123vim /etc/fstab//在末尾增加一行/dev/vdb1 /data ext4 defaults 0 0 2、云主机(推荐) 如果您需要在云服务器系统启动时自动挂载磁盘，不能采用在 /etc/fstab直接指定 /dev/xvdb1的方法，因为云中设备的顺序编码在关闭或者开启云服务器过程中可能发生改变，例如/dev/xvdb1可能会变成/dev/xvdb2。推荐使用UUID来配置自动挂载数据盘。 说明：磁盘的UUID（universally unique identifier）是Linux系统为存储设备提供的唯一的标识字符串。 执行如下命令，查询磁盘分区的UUID。 blkid 磁盘分区 以查询磁盘分区“/dev/vdb1”的UUID为例：1blkid /dev/vdb1 回显类似如下信息： 表示“/dev/vdb1”的UUID。 123vim /etc/fstab//在末尾增加一行UUID=98e18e94-b268-436f-8d76-315a8d4d5d81 /data ext4 defaults 0 2 五、重启/验证重启服务器( 重启之前记得开启22端口 ) 通过命令df -TH查看磁盘信息 可以看出已经自动挂载了。 六、问题开机自动挂载磁盘错误，将会造成无法开机，解决方法，通过单用户模式进入系统，修改挂载配置 vnc单用户模式进入 https://www.west.cn/faq/list.asp?unid=756更改开机自动挂载磁盘配置 https://wenku.baidu.com/view/58c7e1f0f61fb7360b4c6503.html","categories":[{"name":"Linux","slug":"Linux","permalink":"https://chengtong.me/categories/Linux/"}],"tags":[{"name":"CentOS","slug":"CentOS","permalink":"https://chengtong.me/tags/CentOS/"}]},{"title":"【转】Mysql8.0&Mysql5.7&Mysql5.6&Mysql5.5特性对比","slug":"【转】Mysql8.0&Mysql5.7&Mysql5.6&Mysql5.5特性对比","date":"2017-08-17T08:36:59.000Z","updated":"2021-04-09T15:55:39.882Z","comments":true,"path":"posts/d2a1fddb.html","link":"","permalink":"https://chengtong.me/posts/d2a1fddb.html","excerpt":"","text":"Mysql5.5 特性，相对于Mysql5.1性能提升 默认InnoDB plugin引擎。具有提交、回滚和crash恢复功能、ACID兼容。 行级锁(一致性的非锁定读 MVCC)。 表与索引存储在表空间、表大小无限制。 支持dynamic(primary key缓存内存 避免主键查询引起的IO )与compressed(支持数据及索引压缩)行格式。 InnoDB plugin文件格式Barracuda、支持表压缩、节约存储、提供内存命中率、truncate table速度更快。 原InnoDB只有一个UndoSegment，最多支持1023的并发；现在有128个Segments，支持128K个并发（同样，解决高并发带来的事务回滚）。 Innodb_thread_concurrency默认为0，线程并发数无限制，可根据具体应用设置最佳值。 Innodb_io_capacity可以动态调整刷新脏页的数量，改善大批量更新时刷新脏页跟不上导致的性能下降问题。Default：200，跟硬盘的IOPS有关。 充分利用CPU多核处理能力innodb_read_io_threads阈值：1-64innodb_write_io_threads 阈值：1-64根据数据库的读写比灵活设置，充分发挥多CPU、高性能存储设备的性能，不支持动态加载 。 自适应刷新脏页 热数据存活更久 buffer pool多实例 ：innodb_buffer_pool_instances 参数增加innodb_buffer_pool实例个数，大大降低buffer pool的mutex争抢过热情况。 Linux上实现异步IO 重新支持组提交 稳定性提升 支持半同步Replication。 增加Relay Log 自我修复功能。 Crash recovery。 引入红-黑树做插入排序的中间数据结构，时间复杂度大大降低，减少恢复时间。 Thread Pool 分组排队 限流 Mysql5.6 特性,相比5.5 默认参数的改变 Back_log 排队队列 支持全文索引 支持online DDL create,alter,drop 可以在建表时指定表空间位置 create table external (x int unsigned not null primary key)data directory = ‘/volumes/external1/data’; 新增参数innodb_page_size可以设置page大小 整合了memcached API，可以使用API来直接访问innodb表，并非SQL（减少SQL解析、查询优化代价） innodb只读事务，不需要设置TRX_ID字段， 减少内部数据结构开销，减少read view 仅仅非只读事务依然需要TRX_ID innodb改进点 innodb表空间在线迁移(TransportableTablespaces) undo log可独立出系统表空间 redo log最大可增长到512G innodb后台线程独立出来 优化器改进 ICP ​ 可以在引擎层直接过滤数据，避免二次回表 ​ 节省BP空间，提高查询性能 BKA ​ 全称Batch Key Access： ​ SQL通过辅助索引要访问表数据时候，将大量的随机访问放入缓存，交给MRR接口合并为顺序访问。 MRR ​ 全称Multi Range Read： ​ 在BKA算法应用之后，通过MRR接口合并随机访问为顺序访问，再去检索表数据。 ​ 变大量随机为顺序访问。在通过辅助索引检索大量数据时，性能提升明显 ​ 磁头无需来回寻道，page只需读取一次，且较好利用了innodb线性预读功能（每次预读64个连续page）。 统计信息持久化，mysqld重启后不丢失 explain语句支持insert，update，delete，replace语句，并且支持JSON格式 子查询优化提升。 Mysql5.7 特性，相比5.5 5.6安全性 用户表 mysql.user 的 plugin字段不允许为空， 默认值是 mysql_native_password，而不是 mysql_old_password，不再支持旧密码格式； 增加密码过期机制，过期后需要修改密码，否则可能会被禁用，或者进入沙箱模式； 增加密码过期机制，过期后需要修改密码，否则可能会被禁用，或者进入沙箱模式； 提供了更为简单SSL安全访问配置，并且默认连接就采用SSL的加密方式。 灵活性 MySQL数据库从5.7.8版本开始，也提供了对JSON的支持。 可以混合存储结构化数据和非结构化数据，同时拥有关系型数据库和非关系型数据库的优点 能够提供完整的事务支持 generated column是MySQL 5.7引入的新特性，所谓generated column，就是数据库中这一列由其他列计算而得 易用性 在MySQL 5.7 之前，如果用户输入了错误的SQL语句，按下 ctrl+c ，虽然能够”结束”SQL语句的运行，但是，也会退出当前会话，MySQL 5.7对这一违反直觉的地方进行了改进，不再退出会话。 MySQL 5.7可以explain一个正在运行的SQL，这对于DBA分析运行时间较长的语句将会非常有用。 sys schema是MySQL 5.7.7中引入的一个系统库，包含了一系列视图、函数和存储过程， 该项目专注于MySQL的易用性。 例如：如何查看数据库中的冗余索引；如何获取未使用的索引；如何查看使用全表扫描的SQL语句。 可用性 在线设置 复制的过滤规则 不再需要重启MySQL，只需要停止SQLthread，修改完成以后，启动SQLthread。 在线修改buffer pool的大小。 Online DDL MySQL 5.7支持重命名索引和修改varchar的大小，这两项操作在之前的版本中，都需要重建索引或表。 在线开启GTID ，在之前的版本中，由于不支持在线开启GTID，用户如果希望将低版本的数据库升级到支持GTID的数据库版本，需要先关闭数据库，再以GTID模式启动，所以导致升级起来特别麻烦。 性能 临时表的性能改进。 临时表只在当前会话中可见 临时表的生命周期是当前连接（MySQL宕机或重启，则当前连接结束） 只读事务性能改进。 MySQL 5.7通过 避免为只读事务分配事务ID ，不为只读事务分配回滚段，减少锁竞争等多种方式，优化了只读事务的开销，提高了数据库的整体性能。 加速连接处理。 在MySQL 5.7之前，变量的初始化操作（THD、VIO）都是在连接接收线程里面完成的，现在将这些工作下发给工作线程，以减少连接接收线程的工作量，提高连接的处理速度。这个优化对那些频繁建立短连接的应用，将会非常有用。 复制性能的改进 （支持多线程复制（Multi-Threaded Slaves, 简称MTS） MySQL的默认配置是库级别的并行复制，为了充分发挥MySQL 5.7的并行复制的功能，我们需要将slave-parallel-type配置成LOGICAL_CLOCK。 支持多源复制（Multi-source replication） 严格性改变 默认启用 STRICT_TRANS_TABLES 模式。 对 ONLY_FULL_GROUP_BY 模式实现了更复杂的特性支持，并且也被默认启用。 其他被默认启用的sql mode还有 NO_ENGINE_SUBSTITUTION。 默认参数的改变 默认binlog格式调整为ROW格式 默认binlog错误后的操作调整为ABORT_SERVER 在先前的选项下（binlog_error_action=IGNORE_ERROR），如果一个错误发生，导致无法写入binlog，mysql-server会在错误日志中记录错误并强制关闭binlog功能。这会使mysql-server在不记录binlog的模式下继续运行，导致从库无法继续获取到主库的binlog。 默认开启mysql崩溃时的binlog安全。 默认调低slave_net_timeout。 安装不同 mysql_install_db已经不再推荐使用了，建议改成mysqld –initialize 完成实例初始化。如果 datadir 指向的目标目录下已经有数据文件，则会有[ERROR] Aborting； 在初始化时如果加上 –initial-insecure，则会创建空密码的 root@localhost 账号，否则会创建带密码的 root@localhost 账号，密码直接写在 log-error 日志文件中；新用户登入后需要立刻修改密码，否则无法继续后续的工作。 Mysql8.0 特性，相比5.7新的系统字典表 整合了存储有关数据库对象信息的事务数据字典，所有的元数据都用InnoDB引擎进行存储 安全和用户管理 新增caching_sha2_password认证插件，并且是默认的身份认证插件。性能和安全方面加强 权限支持role 新增密码历史记录功能，限制重复使用以前的密码 innodb 增强 新增INFORMATION_SCHEMA.INNODB_CACHED_INDEXES，查看每个索引缓存在InnoDB缓冲池中的索引页数 InnoDB临时表都将在共享临时表空间ibtmp1中创建 对于SELECT … FOR SHARE和SELECT … FOR UPDATE语句，InnoDB支持NOWAIT和SKIP LOCKED innodb_undo_tablespaces的最小值为2，并且不再允许将innodb_undo_tablespaces设置为0。 最小值2确保回滚段始终在撤消表空间中创建，而不是在系统表空间中创建 支持 ALTER TABLESPACE … RENAME TO 语法 新增INFORMATION_SCHEMA.INNODB_TABLESPACES_BRIEF视图 新增了动态配置项 innodb_deadlock_detect，用来禁用死锁检查，因为在高并发系统中，当大量线程等待同一个锁时，死锁检查会大大拖慢数据库 支持使用innodb_directories选项在服务器脱机时将表空间文件移动或恢复到新位置 新增innodb_dedicated_server，让InnoDB根据服务器上检测到的内存量自动配置innodb_buffer_pool_size，innodb_log_file_size，innodb_flush_method。当innodb_dedicated_server启用时，InnoDB根据服务器上检测到的内存量自动配置以下选项： innodb_dedicated_server：自动配置缓冲池大小 innodb_log_file_size：自动配置的日志文件大小 innodb_flush_method：O_DIRECT_NO_FSYNC MySQL 8.0更好支持文档型数据库和JSON 不可见索引，开始支持invisible index，在优化SQL的过程中可以设置索引为不可见，优化器不会利用不可见索引 支持降序索引，可以对索引定义 DESC，之前，索引可以被反序扫描，但影响性能，而降序索引就可以高效的完成 支持RANK(), LAG()、NTILE()等函数 正则表达式增强，提供了REGEXP_LIKE()，EGEXP_INSTR(), REGEXP_REPLACE(), REGEXP_SUBSTR()等函数 新增备份锁，允许在线备份期间的DML，同时防止可能导致快照不一致的操作。 备份锁由LOCK INSTANCE FOR BACKUP和UNLOCK INSTANCE语法支持 默认字符集由latin1变为utf8mb4 配置文件增强 MySQL 8.0版本支持在线修改全局参数持久化，通过加上PERSIST关键字，可以将调整持久化到新的配置文件中，再次重启db还可以应用到最新的参数。对于加上 PERSIST 关键字修改参数命令，MySQL系统会生成一个包含json格式数据的 mysqld-auto.cnf 文件，比如执行： set PERSIST binlog_expire_logs_seconds = 604800 ; #内存和json文件都修改，重启还生效 set GLOBAL binlog_expire_logs_seconds = 604800 ; #只修改内存，重启丢失 系统会在数据目录下生成一个包含如下内容的 mysqld-auto.cnf 的文件：{ “mysql_server”: {“ binlog_expire_logs_seconds “: “604800” } } 当 my.cnf 和 mysqld-auto.cnf 同时存在时，后者具有高优先级。 直方图 MySQL 8.0 版本开始支持期待已久直方图。优化器会利用column_statistics的数据，判断字段的值的分布，得到更准确的执行计划。 可以使用 ANALYZE TABLE table_name [UPDATE HISTOGRAM on col_name with N BUCKETS |DROP HISTOGRAM ON clo_name] 来收集或者删除直方图信息 支持会话级别SET_VAR 动态调整部分参数，有利于提升语句性能。 select /+ SET_VAR(sort_buffer_size = 16M) / id from test order id ; insert /+ SET_VAR(foreign_key_checks=OFF) / into test(name) values(1); InnoDB性能提升 废除buffer pool mutex, 将原来一个mutex拆分成多个，提高并发拆分LOCK_thd_list 和 LOCK_thd_remove 这两个mutex，大约可提高线程链接效率5%。 行缓存 MySQL8.0的优化器可以估算将要读取的行数，因此可以提供给存储引擎一个合适大小的row buffer来存储需要的数据。大批量的连续数据扫描的性能将受益于更大的record buffer。 改进扫描性能 改进InnoDB范围查询的性能，可提升全表查询和范围查询 5-20%的性能。 成本模型 InnoDB缓冲区可以估算缓存区中的有多少表和索引，这可以让优化器选择访问方式时知道数据是否可以存储在内存中还是必须存储到磁盘上。","categories":[{"name":"数据库","slug":"数据库","permalink":"https://chengtong.me/categories/数据库/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://chengtong.me/tags/MySQL/"}]},{"title":"使用Lombok让JavaBean变得更加简洁","slug":"使用Lombok让JavaBean变得更加简洁","date":"2017-07-31T15:54:00.000Z","updated":"2020-12-07T07:36:06.129Z","comments":true,"path":"posts/8f3460a5.html","link":"","permalink":"https://chengtong.me/posts/8f3460a5.html","excerpt":"","text":"Lombok - 工具简介：Lombok是一个编译时注释预处理器，有助于在编译时注入一些代码。Lombok提供了一组在开发时处理的注释，以将代码注入到Java应用程序中，注入的代码在开发环境中立即可用。在详细介绍之前，可以去其官网看一下作者提供的视频，视频中阐述了Lombok 的简单用法。https://projectlombok.org/ Lombok - 安装过程：基于 Maven：示例代码： 12345678&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;version&gt;1.16.18&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 添加好 Maven 依赖之后，就可以在代码中使用 Lombok 的注解来简化代码了。 基于IntelliJ IDEA：安装 Lombok IntelliJ plugin:Jetbrains IntelliJ IDEA Editor完全兼容 Lombok，要在 IDEA 中使用 Lombok，那就需要在IntelliJ IDEA 中安装 Lombok IntelliJ plugin 插件，以下为安装步骤： Go to File &gt; Settings &gt; Plugins Click on Browse repositories... Search for Lombok Plugin Click on Install plugin Restart IntelliJ IDEA 具体安装过程可参考官网或者插件 Github 主页。 在IntelliJ IDEA使用Lombok: Go to Refactor &gt; Lombok 在打开的 JavaBean 文件中按照需求添加相应的注解即可。 Lombok - 常用注解：你如果是使用IDEA的话，在当前文件上按command+F12，或者长按command在左侧找到Structure，就能够看到 lombok 为当前类生成的方法。 @Data ：注解在类上；提供类所有属性的 getting 和 setting 方法，此外还提供了equals、canEqual、hashCode、toString 方法 示例代码： 12345678import lombok.Data;@Datapublic class Person &#123; private String firstName; private String lastName; private String job;&#125; @Setter/@Getter：注解在属性或类上；为属性提供 Setter/Getter 方法 示例代码： 1234567891011import lombok.Getter;import lombok.Setter;// 只为 firstName 生成Getter、Setter 方法public class Person &#123; @Getter @Setter private String firstName; private String lastName; private String job;&#125; 123456789101112import lombok.Getter;import lombok.Setter;@Getter@Setterpublic class Person &#123;// 为所有字段生成Getter、Setter 方法 private String firstName; private String lastName; private String job;&#125; @Log4j ：注解在类上；为类提供一个 属性名为log 的 log4j 日志对象 @Value：此注解集@equals()、@hashCode()、@toString()、@Getter()于一身。 示例代码： 123456789101112131415import lombok.Value;import lombok.experimental.NonFinal;@Valuepublic class Person &#123; /** 类本身以及类中所有的字段都是private final类型的，不会生成Setter方法。 * 可以通过显式指定某个注解覆盖掉默认的属性。 * 通过@NonFinal注解修饰的字段，不是final类型的。 */ String firstName; String lastName; @NonFinal String job;&#125; @NoArgsConstructor/@AllArgsConstructor: 自动生成无参数构造函数/全参构造函数。 示例代码： 123456789101112import lombok.AllArgsConstructor;import lombok.NoArgsConstructor;@NoArgsConstructor@AllArgsConstructorpublic class Person &#123; private String firstName; private String lastName; private String job;&#125; @NonNull :修饰方法、构造函数的参数或者类字段，Lombok自动生成一个非空检测语句。 示例代码： 12345678import lombok.NonNull;public class Person&#123; public String Example(@NonNull String sum)&#123; return null; &#125;&#125; @Synchronized 将方法变成同步方法 @SneakyThrows：将受检异常转换为非受检异常，避免抛出或尝试语句。 lombok 项目官网上还有一些其他注解的用法，此处就不列举了，附链接：https://projectlombok.org/features/all 参考资料： Lombok Official Website Lombok Github Lombok IntelliJ plugin","categories":[{"name":"JAVA","slug":"JAVA","permalink":"https://chengtong.me/categories/JAVA/"}],"tags":[{"name":"Lombok","slug":"Lombok","permalink":"https://chengtong.me/tags/Lombok/"}]},{"title":"Tomcat的Https设置及Http自动跳转Https","slug":"Tomcat的Https设置及Http自动跳转Https","date":"2017-06-01T01:13:41.000Z","updated":"2020-05-23T12:43:24.176Z","comments":true,"path":"posts/ff0a6fc5.html","link":"","permalink":"https://chengtong.me/posts/ff0a6fc5.html","excerpt":"","text":"1.场景还原​ 近期项目中要对信息传输过程中进行安全加密，那么第一时间浮现笔者脑海的当然是https,接下来笔者将介绍如何在web服务器Tomcat中配置Https及Http自动跳转Https 2.Https相关介绍​ Https是由NetScape公司设计的一个基于Http的加密传输协议，可以这样理解Https = Http +SSL(安全套接层),Https的端口为443，而且还需要申请CA数字证书认证。 3.Https的设置①申明CA数字证书 这里推荐一个免费的阿里平台的CA数字证书（阿里云、腾讯云） 点击免费型DV SSL 购买，跳转到阿里云主界面，找到证书服务相关项，点击进去 输入个人或企业信息进行申请 证书签发成功后，下载相关文档，内容如下： 第一个红框是密钥文件，第二个是密码。 ②将生成的密钥文件上传至云服务器 /usr/local/tomcat/conf ③编辑conf/server.xml文件 1&gt;将8443端口处去除注释并改为 密钥文件与密码对号入座； 2&gt;将8080端口改为80，8443改为443 这个设置后，请求地址也就无需连接端口号8080； 3&gt;将8009处的8443改为443 这样https请求时就不用自动附带8443端口了； ok,这样Https的设置就大功告成了。 4.Http自动跳转Https①编辑conf/web.xml文件 ②在web.xml末尾加上如下配置：1234567891011121314151617&lt;security-constraint&gt;&lt;web-resource-collection &gt; &lt;web-resource-name &gt;SSL&lt;/web-resource-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/web-resource-collection&gt; &lt;user-data-constraint&gt; &lt;transport-guarantee&gt;CONFIDENTIAL&lt;/transport-guarantee&gt; &lt;/user-data-constraint&gt;&lt;/security-constraint&gt; 然后 ：wq保存并退出。 ③重启Tomcat服务 输入 ./startup.sh 验证效果： 当然地址栏输入http://app.3xzg.com 自动跳转到 https://app.3xzg.com","categories":[],"tags":[]},{"title":"Java依赖注入的三种方式","slug":"Java依赖注入的三种方式","date":"2017-05-14T13:55:00.000Z","updated":"2020-12-07T07:36:06.121Z","comments":true,"path":"posts/e6c10dfb.html","link":"","permalink":"https://chengtong.me/posts/e6c10dfb.html","excerpt":"","text":"Spring通过DI（依赖注入）实现IOC（控制反转），常用的注入方式主要有三种：构造方法注入，setter注入，基于注解的注入。 构造方法注入构造器注入:保证了一些必要的属性在Bean实例化时就设置,并且确保了bean实例在实例化后就可以使用. 1.在类中,不用为属性设置setter方法,只需提供构造方法即可2.在构造文件中配置该类bean,并配置构造器,在配置构造器中用 1234//ApplicationContext.xml&lt;bean id=\"action\" class=\"com.action.UserAction\"&gt; &lt;constructor-arg index =\"0\" name=\"name\" value=\"Murphy\"&gt;&lt;/constructor-arg&gt;&lt;/bean&gt; 提供构造方法 123456public class UserAction &#123; private String name; public UserAction(String name) &#123; this.name = name; &#125;&#125; setter注入 1.根据property标签的name属性的值去找对应的setter方法. 例如: name= “aa” 对应的就是setAa方法. 2.由于属性注入具有可选性和灵活性高的优点,是实际上最常用的注入方式. 3.属性注入要求bean提供一个默认的构造函数,并为需要注入的属性提供对应的setter方法.spring先调用bean默认的构造函数实例化bean对象,然后通过反射机制的方法调用setter方法注入属性值. 4.还有一点需要注意：如果通过set方法注入属性，那么spring会通过默认的空参构造方法来实例化对象，所以如果在类中写了一个带有参数的构造方法，一定要把空参数的构造方法写上，否则spring没有办法实例化对象，导致报错。 1234//ApplicationContext.xml&lt;bean id=\"action\" class=\"com.action.UserAction\"&gt; &lt;property name=\"name\" value=\"Murphy\"/&gt;&lt;/bean&gt; 提供setting方法 123456789public class UserAction &#123; private String name; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; &#125; 注解注入 @Autowired（构造，接口，方法）自动装配，默认根据类型注入—属性Required 1.@Autowired(required=true)：当使用@Autowired注解的时候，其实默认就是@Autowired(required=true)，表示注入的时候，该bean必须存在，否则就会注入失败 2.@Autowired(required=false)：表示忽略当前要注入的bean，如果有直接注入，没有跳过，不会报错。 3.required属性含义和@Required一样，只是@Required只适用于基于XML配置的setter注入方式,只能打在setting方法上。 1234567891011121314151617181920212223242526public class AutowiredAction &#123; private String name; private List&lt;String&gt; list; @Autowired private AutowiredAction(String name) &#123; this.name=name; &#125; public String getName() &#123; return name; &#125; @Autowired public void setName(String name) &#123; this.name = name; &#125; @Autowired(required = true) private void initName(String name,List&lt;String&gt; list) &#123; this.name = name; this.list = list; &#125; &#125; 接口 12345public interface AutowiredIn &#123; @Autowired void initName(String name,Integer age);&#125; ​ @Resource 默认按照名称装配 可以标注在字段或属性的setter方法上。默认按照字段的名称去Spring容器中找依赖对象，如果没有找到，退回到按照类型查找 如果配置了属性name 那么只能按照名称找依赖对象 12345678910111213141516171819202122232425public class ResourceAction &#123; @Resource(name=\"name\") private String name; @Resource private List&lt;String&gt; list; public String getName() &#123; return name; &#125; @Resource public void setName(String name) &#123; this.name = name; &#125; public List&lt;String&gt; getList() &#123; return list; &#125; public void setList(List&lt;String&gt; list) &#123; this.list = list; &#125; &#125;","categories":[{"name":"JAVA","slug":"JAVA","permalink":"https://chengtong.me/categories/JAVA/"}],"tags":[]},{"title":"Jenkins2插件Pipeline+BlueOcean实现持续交付的初次演练","slug":"Jenkins2插件Pipeline+BlueOcean实现持续交付的初次演练","date":"2017-04-28T08:27:01.000Z","updated":"2020-12-11T08:54:50.088Z","comments":true,"path":"posts/238477f1.html","link":"","permalink":"https://chengtong.me/posts/238477f1.html","excerpt":"","text":"需要完成的目标 使用Pipeline完成项目的checkout，package、deploy、restart 提取出公有部分封装为公有JOB 实现pipeline对其他JOB的调用和逻辑的判断 实现任务的指定调用 实现多节点同时并发build 结合插件Open Blue Ocean Pipeline的基础代码 收集了一些代码案例，可以自行查阅，不在啰嗦。 jenkins2 pipeline入门：http://www.cnblogs.com/itech/p/5633948.html jenkins2 pipeline高级：http://www.cnblogs.com/itech/p/5646219.html jenkins2 pipeline插件的10个最佳实践：http://www.cnblogs.com/itech/p/5678643.html 提取出公有部分封装为公有JOB,在另一个JOB中引用 JOB初始化、容器、分发分成了三个部分作为共有JOB进行管理。 场景描述：同一项目组有若干个模块，其有较高的耦合性，而且步骤均一致。只有SVN、补丁内容，等参数，所以采用提取这部分作为一个参数化job，每个模块构建步骤采用pipeline传递自身特有参数的方式触发构建。 实现pipeline对任务逻辑的判断 注意：jenkins中的boolean值似乎只是值的指定，通过shell可以直接if判断，但在goory里面我这里用的判断等于 1`//更新bus容器``if` `(XD_Env_BUS_Update_Start == ``&apos;true&apos;``) &#123;`` ``println ``&quot;XD_Env_BUS_Update_Start - 更新&quot;`` ``build job: ``&apos;XD_Env_BUS_Update_Start&apos;``, parameters: [``string``(name: ``&apos;Env&apos;``, value: BD_Env), ``string``(name: ``&apos;BD_Dir&apos;``, value: BD_Dir)]``&#125; ``else` `&#123;`` ``println ``&quot;XD_Env_BUS_Update_Start - 不更新&quot;``&#125;` 实现多节点同时并发build 实现多节点，主要是为了加快时间 JOB的演示切换进入BlueOcean 点击进行执行 运行后，可以对具体的查看状态。","categories":[{"name":"DevOps","slug":"DevOps","permalink":"https://chengtong.me/categories/DevOps/"}],"tags":[{"name":"Jenkins","slug":"Jenkins","permalink":"https://chengtong.me/tags/Jenkins/"}]},{"title":"Jenkins2实现持续交付初次演练(MultiJob，Pipeline，Blue Ocean)","slug":"Jenkins2实现持续交付初次演练(MultiJob，Pipeline，Blue Ocean)","date":"2017-04-28T07:58:01.000Z","updated":"2021-04-09T15:49:04.178Z","comments":true,"path":"posts/4f466ef0.html","link":"","permalink":"https://chengtong.me/posts/4f466ef0.html","excerpt":"","text":"背景 项目需要用到自动部署，但可获取外网的节点机器只有一台，那只能同过主节点机器进行构建完成然后分发至对应服务器进行启动更新。 目前已尝试过三种方式： 1.Pipeline-Trigger parameterized build on other projects 2.MultiJob 3.PipelineJob +Blue Ocean 三种方式最后的实现结果如下： Pipeline-Trigger parameterized build on other projects MultiJob PipelineJob+Blue Ocean 三种方式的对比： 1.Pipeline-Trigger parameterized build on other projects 1.优点: 能实现参数的界面化，过程中使用参数都能展示出来 能单独进行触发构建 能实现串行 2.缺点 无法解决上游指定中游执行任务，下游等待中游全部完成后执行 2.MultiJob 1.优点： 能将不同阶段的执行步骤展示出来 能进行任务的并行和串行判断 能实现下游等待上游完成后进行执行 2.缺点： 无法解决上游指定中游执行指定任务 过程变量没法展示出来 3.PipelineJob +Blue Ocean 1.优点 能将不同阶段的执行步骤展示出来 能进行任务的并行和串行判断 能实现下游等待上游完成后进行执行 能上游指定中游执行指定任务 过程变量可直接在上游全部配置（较为繁琐）","categories":[{"name":"DevOps","slug":"DevOps","permalink":"https://chengtong.me/categories/DevOps/"}],"tags":[{"name":"Jenkins","slug":"Jenkins","permalink":"https://chengtong.me/tags/Jenkins/"}]},{"title":"Git问题Everything up-to-date解决","slug":"Git问题Everything up-to-date解决","date":"2017-03-13T16:00:00.000Z","updated":"2020-05-22T02:03:24.797Z","comments":true,"path":"posts/65bb19af.html","link":"","permalink":"https://chengtong.me/posts/65bb19af.html","excerpt":"","text":"先说说出现这个问题的原因：git提交改动到缓存，要push的时候不会将本地所有的分支都push掉，所以出现这个问题。那么我们就需要新建分支提交改动然后合并分支。 1.先创建一个新的分支提交改动 $ git branch newbranch 2.检查这条命令是否创建成功 $ git branch 这时终端会输出： newbranch *master 这样就创建成功了，前面的*代表的是当前你所在的工作分支，接下来就要切换工作分支。 3.git checkout newbranch 4.然后将你的改动提交到新的分支上 $ git add 网页换肤 $ git commit -m”skin” 此时可以$ git status 检查下提交情况。如果提交成功，我们接下来就要回主分支了，$ git checkout master 5.我们将新分支提交的改动合并到主分支上 $ git merge newbranch 合并分支可能产生冲突这是正常的，虽然我们这是新建的分支不会产生冲突，但还是在这里记录下。可以用 $ git diff 来查看产生冲突的文件，然后做对应的修改再提交一次就可以了。 6.我们的问题解决了，接下来就可以push代码了 $ git push -u origin master 7.最后，新建分支的朋友别忘了删除分支 $ git branch -D newbranch 如果想保留分支只是想删除已经合并的部分只要把大写的D改成小写的d就行了。","categories":[{"name":"源代码版本管理工具","slug":"源代码版本管理工具","permalink":"https://chengtong.me/categories/源代码版本管理工具/"}],"tags":[{"name":"Git","slug":"Git","permalink":"https://chengtong.me/tags/Git/"}]},{"title":"解除360doc网页防复制","slug":"解除360doc网页防复制","date":"2016-10-14T07:32:48.000Z","updated":"2020-05-22T02:03:25.150Z","comments":true,"path":"posts/2fc0e0a3.html","link":"","permalink":"https://chengtong.me/posts/2fc0e0a3.html","excerpt":"","text":"方法1chrome浏览器按F12（打开谷歌浏览器的开发者工具） 然后按F5 刷新下网页，（根据测试必须刷新下网页等下插入代码才能生效）下面空白插入代码：1document.oncontextmenu=document.onselectstart=document.body.onselectstart=document.oncopy=document.body.oncopy=&quot;&quot; 然后按回车键，ok！不会弹出那令人蛋疼的提示了，可以复制了。 方法2先打开一个Word文件，然后直接选中要复制的内容，可以把复制的内容直接拖动到Word中就OK了。 发现这种方法也适合其他被保护内容的复制。 方法3把下面的代码保存成浏览器书签，遇到右键不允许复制的网站，点一下这个书签就可以去除保护，随意复制。1javascript:(function() &#123; function R(a)&#123;ona =&quot;on&quot;+a; if(window.addEventListener) window.addEventListener(a, function (e) &#123; for(var n=e.originalTarget; n; n=n.parentNode) n[ona]=null; &#125;, true); window[ona]=null; document[ona]=null; document.onkeydown=null; if(document.body) document.body[ona]=null; document.body.oncopy=null; &#125; R(&quot;contextmenu&quot;); R(&quot;click&quot;); R(&quot;mousedown&quot;); R(&quot;mouseup&quot;); R(&quot;selectstart&quot;);&#125;)() 方法4右上角菜单按钮→设置→显示高级设置→隐私设置下的 内容设置按钮→javascript下的管理例外情况→添加 [*.]360doc.com 设置为禁止 →完成 重新刷新页面即可。","categories":[],"tags":[]},{"title":"git add -A 和 git add . 的区别","slug":"git-add-A-和-git-add-的区别","date":"2016-09-10T05:30:21.000Z","updated":"2020-05-22T02:03:24.925Z","comments":true,"path":"posts/1c334725.html","link":"","permalink":"https://chengtong.me/posts/1c334725.html","excerpt":"","text":"介绍git add -A和 git add . git add -u在功能上看似很相近，但还是存在一点差别 git add . ：他会监控工作区的状态树，使用它会把工作时的所有变化提交到暂存区，包括文件内容修改(modified)以及新文件(new)，但不包括被删除的文件。 git add -u ：他仅监控已经被add的文件（即tracked file），他会将被修改的文件提交到暂存区。add -u 不会提交新文件（untracked file）。（git add –update的缩写） git add -A ：是上面两个功能的合集（git add –all的缩写） 示例下面是具体操作例子，方便更好的理解（Git version 1.x）：12345678910111213141516171819202122232425262728293031323334353637383940414243444546git initecho Change me &gt; change-meecho Delete me &gt; delete-megit add change-me delete-megit commit -m initialecho OK &gt;&gt; change-merm delete-meecho Add me &gt; add-megit status# Changed but not updated:# modified: change-me# deleted: delete-me# Untracked files:# add-megit add .git status# Changes to be committed:# new file: add-me# modified: change-me# Changed but not updated:# deleted: delete-megit resetgit add -ugit status# Changes to be committed:# modified: change-me# deleted: delete-me# Untracked files:# add-megit resetgit add -Agit status# Changes to be committed:# new file: add-me# modified: change-me# deleted: delete-me 总结· git add -A 提交所有变化 · git add -u 提交被修改(modified)和被删除(deleted)文件，不包括新文件(new) · git add . 提交新文件(new)和被修改(modified)文件，不包括被删除(deleted)文件 git不同版本区别Git Version 1.x:Git Version 2.x:","categories":[{"name":"源代码版本管理工具","slug":"源代码版本管理工具","permalink":"https://chengtong.me/categories/源代码版本管理工具/"}],"tags":[{"name":"Git","slug":"Git","permalink":"https://chengtong.me/tags/Git/"}]},{"title":"IntelliJ使用pipeline文件","slug":"IntelliJ使用pipeline文件","date":"2016-08-12T08:21:53.000Z","updated":"2020-05-23T12:43:23.980Z","comments":true,"path":"posts/b12943d1.html","link":"","permalink":"https://chengtong.me/posts/b12943d1.html","excerpt":"","text":"使用idea格式化pipeline文件 新建项目Groovy项目新建.gdsl 文件 在当前项目中/src/main/groovy新建.gdsl 文件","categories":[],"tags":[]},{"title":"数据库存时间戳的好处","slug":"数据库存时间戳的好处","date":"2016-05-31T00:49:27.000Z","updated":"2020-05-23T12:43:24.058Z","comments":true,"path":"posts/3d12f64a.html","link":"","permalink":"https://chengtong.me/posts/3d12f64a.html","excerpt":"","text":"不管做什么项目，必须都得接触的东西就是时间类型。现在用时间戳存储日期数据（整型存储）已经是业界很平常的的事情，网上各大游戏公司，各大开源都是采取整型时间戳存储。整数存日期好处很多，程序判断直读，扩展性好，随意可转换xml,json等格式。不过有一个最大的缺点就是查数据库不直观，也就是说我们用管理工具打开数据库的时候，看到的是一堆数字，维护数据不方便。为了解决这一缺陷，我找到一方法，先上代码： 1SELECT *,FROM_UNIXTIME(created_time, &apos;%Y-%m-%d %H:%i:%s&apos;) as created_time_ref FROM `user` 时间戳不含时区，绝对时间，存的是标准时不受服务器所在时区的影响 好处如下： 0、无时区干扰1、存储空间小一个数字比一个字符串占用空间小得多2、检索效率高3、计算方便(计算出需要检索的时间戳，然后比较。如果存的是字符串，根本无法比较) 以 mysql 来说，用 bigint 来存较好对应java中的类型为Long 优点 1. 存储值与时区无关 2. 不用考虑各台机器时区以及 mysql 所用时区不一致问题 缺点: 查询结果需做转换才能可读(mysql-cli/gui) DATETIME: 存储的可以理解为就是你给它的值(yyyy-MM-dd HH:mm:ss)，但是不会带上时区信息，所以如果各台机器时区不一致，那库里存的就不知道它的时区了TIMESTAMP: 存储的可以理解为把你给它的值(yyyy-MM-dd HH:mm:ss)以 mysql 所用时区来理解，转成 UTC 时间来存储，所以如果程序所用时区与 mysql 所用时区不一致，那 mysql 就存错值了 那如果程序所用时区与 mysql 所用时区都全部一致，DATETIME 和 TIMESTAMP 有什么区别呢？ 各台机器 0 时区，mysqlA 0 时区，数据都在 mysqlA 上，mysqlB 用的是 1 时区，把 mysqlA 导出导入到 mysqlB 中DATETIME: A,B 查询结果一致，时区信息自己记得是 0 时区TIMESTAMP: A,B 查询结果不同，分别是各自 mysql 所用时区ps: 把 mysqlB 时区改一致不就完了……额，就以它不能改吧 其它区别: 如取值范围。。（自己上网看至于闰秒问题。不考虑[有看到建议取消闰秒])TIMESTAMP 范围问题，程序能活到那个时候再说~（等 mysql 加大 TIMESTAMP 字节？ 如果还有人觉得这样麻烦，我无话可说，毕竟有些做小项目的人不需要考虑扩展，也用不上对象格式转换。后台的操作基本用不上Date，都是把Date转成整型再计算，干嘛浪费时间精力存一个不方便转格式的Date型。众多大型开源都使用时间戳，允分证明了时间戳存储的优势。为了一个快一步的直观而放弃扩展，这值吗?","categories":[{"name":"数据库","slug":"数据库","permalink":"https://chengtong.me/categories/数据库/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://chengtong.me/tags/MySQL/"}]},{"title":"让putty支持标签tabs功能","slug":"让putty支持标签tabs功能","date":"2016-04-18T08:19:01.000Z","updated":"2020-05-23T12:43:24.085Z","comments":true,"path":"posts/f62f0412.html","link":"","permalink":"https://chengtong.me/posts/f62f0412.html","excerpt":"","text":"putty一个我们常用的管理和连接linux的工具，小而功能够用，使用下来不足的就是不支持像类似chrome浏览器一样的tabs标签。 google了一把，找到了方法，下载一个ttyplus的工具安装后再启动就会让putty支持多标签方式浏览。 官网下载地址：http://www.ttyplus.com/downloads.html其他下载地址：http://wangpant.cn/resource/view/hat9slegj0pa.html 运行后如图：","categories":[],"tags":[]},{"title":"Java生成随机数(n位长度，字母+数字)","slug":"Java生成随机数(n位长度，字母+数字)","date":"2016-02-03T02:20:00.000Z","updated":"2020-08-20T07:43:11.295Z","comments":true,"path":"posts/ba9f4885.html","link":"","permalink":"https://chengtong.me/posts/ba9f4885.html","excerpt":"","text":"1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071import java.util.Random;/** * 随机数 */public class Demo &#123; public static void main(String[] args) &#123; System.out.println(getStringRandom(6)); System.out.println(getStringRandomZm(6)); System.out.println(getRandomNumber(6)); &#125; /** * 生成字母+数字的随机数 * * @param length * @return */ public static String getStringRandom(int length) &#123; String val = \"\"; Random random = new Random(); //参数length，表示生成几位随机数 for (int i = 0; i &lt; length; i++) &#123; String charOrNum = random.nextInt(2) % 2 == 0 ? \"char\" : \"num\"; //输出字母还是数字 if (\"char\".equalsIgnoreCase(charOrNum)) &#123; //输出是大写字母还是小写字母 int temp = random.nextInt(2) % 2 == 0 ? 65 : 97; val += (char) (random.nextInt(26) + temp); &#125; else if (\"num\".equalsIgnoreCase(charOrNum)) &#123; val += String.valueOf(random.nextInt(10)); &#125; &#125; return val; &#125; /** * 生成字母(大写+小写) * * @param length * @return */ private static String getStringRandomZm(int length) &#123; String base = \"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\"; Random random = new Random(); StringBuffer sb = new StringBuffer(); for (int i = 0; i &lt; length; i++) &#123; int number = random.nextInt(base.length()); sb.append(base.charAt(number)); &#125; return sb.toString(); &#125; /** * 生成0-9的随机数 * * @param length * @return */ public static String getRandomNumber(int length) &#123; Random random = new Random(); StringBuffer buffer = new StringBuffer(); for (int i = 0; i &lt; length; i++) &#123; buffer.append(random.nextInt(10)); &#125; return buffer.toString(); &#125;&#125;","categories":[],"tags":[]},{"title":"5W,5W1H,5W2H,5W2H1E","slug":"5W-5W1H-5W2H-5W2H1E","date":"2015-10-14T07:53:22.000Z","updated":"2020-05-22T02:03:24.772Z","comments":true,"path":"posts/87d9b46d.html","link":"","permalink":"https://chengtong.me/posts/87d9b46d.html","excerpt":"","text":"5W理论&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;美国学者H·拉斯维尔于1948年在《传播在社会中的结构与功能》一篇论文中，首次提出了构成传播过程的五种基本要素，并按照一定结构顺序将它们排列，形成了后来人们称之“五W模式”或“拉斯维尔程式”的过程模式。这五个W分别是英语中五个疑问代词的第一个字母，即： Who （谁） Says What （说了什么） In Which Channal （通过什么渠道） To Whom （向谁说） With What Effect （有什么效果） 5W1H分析法也称六何分析法&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;5W1H分析法也称六何分析法，是一种思考方法，也可以说是一种创造技法。是对选定的项目、工序或操作，都要从原因（WHY）、对象（WHAT）、地点（WHERE）、时间（WHEN）、人员（WHO）、方法（HOW）等六个方面提出问题进行思考。这种看似很可笑、很天真的问话和思考办法，可使思考的内容深化、科学化。具体见下表： 对象（WHAT） 公司生产什么产品？车间生产什么零配件？为什么要生产这个产品？能不能生产别的？我到底应该生产什么？例如如果现在这个产品不挣钱，换个利润高 场所（WHERE） 生产是在哪里干的？为什么偏偏要在这个地方干？换个地方行不行？到底应该在什么地方干？这是选择工作场所应该考虑的。 时间和程序（WHEN） 例如现在这个工序或者零部件是在什么时候干的？为什么要在这个时候干？能不能在其他时候干？把后工序提到前面行不行？到底应该在什么时间干？ 人员（WHO） 现在这个事情是谁在干？为什么要让他干？如果他既不负责任，脾气又很大，是不是可以换个人？有时候换一个人，整个生产就有起色了。 手段（HOW） 手段也就是工艺方法，例如，现在我们是怎样干的？为什么用这种方法来干？有没有别的方法可以干？到底应该怎么干？有时候方法一改，全局就会改变。 5W2H分析法又称七何分析法&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;5W2H法是第二世界大战中美国陆军兵器修理部首创。简单、方便，易于理解、使用，富有启发意义，广泛用于企业管理和技术活动，对于决策和执行性的活动措施也非常有帮助，也有助于弥补考虑问题的疏漏。为什么（Why）为什么采用这个技术参数？为什么不能有响声？为什么停用？为什么变成红色：为什么要做成这个形状？为什么采用机器代替人力？为什么产品的制造要经过这么多环节？为什么非做不可？ 做什么（What）条件是什么？哪一部分工作要做？目的是什么？重点是什么？与什么有关系？功能是什么？规范是什么？工作对象是什么？ 谁（Who）谁来办最方便？谁会生产？谁可以办？谁是顾客？谁被忽略了？谁是决策人？谁会受益？ 何时（When）何时要完成？何时安装？何时销售？何时是最佳营业时间？何时工作人员容易疲劳？何时产量最高？何时完成最为时宜？需要几天才算合理？ 何地（Where）何地最适宜某物生长？何处生产最经济？从何处买？还有什么地方可以作销售点？安装在什么地方最合适？何地有资源？ 怎样（How）怎样做省力？怎样做最快？怎样做效率最高？怎样改进？怎样得到？怎样避免失败？ 怎样求发展？怎样增加销路？怎样达到效率？怎样才能使产品更加美观大方？怎样使产品用起来方便？ 多少（How much）功能指标达到多少？销售多少？成本多少？输出功率多少？效率多高？尺寸多少？重量多少？ 5W2H1E任何一种企划书的构成都必须有5W2H1E，共8个基本要素。所谓的5W2H1E即： What(什么)–企划的目的、内容。 Who( 谁)–企划相关人员。 Where( 何处)–企划实施场所。 When(何时)–企划的时间。 Why(为什么)–企划缘由、前景。 How(如何)–企划的方法和运转实施。 How much(多少)–企划预算。 Effect(效果)–预测企划结果、效果。 尤其值得一提的是，要注意How much和Effect对整个企划案的重要意义。如果忽视企划的成本投入，不注意企划书实施效果的预测，那么，这种企划就不是一种成功的企划。只有5W1H的企划书不能称之为企划书，只能算是计划书。","categories":[],"tags":[]},{"title":"mysql启动时，提示/etc/my.cnf 被忽略的问题处理","slug":"mysql启动时，提示etc my.cnf 被忽略的问题处理","date":"2015-10-14T06:24:30.000Z","updated":"2020-05-23T12:43:24.019Z","comments":true,"path":"posts/aa7c6b3f.html","link":"","permalink":"https://chengtong.me/posts/aa7c6b3f.html","excerpt":"","text":"今天在处理测试开发人员的问题是，发现一个MySQL实例启动故障，处理过程如下：发现mysql实例是关闭的，执行命令启动mysql实例时有警告： 1service mysql.server start Warning: World-writable config file ‘/etc/my.cnf’ is ignoredStarting MySQL SUCCESS! 观察mysql的启动日志，在日志中显示： 12151014 11:39:24 mysqld_safe Starting mysqld daemon with databases from /data/mysql/dataWarning: World-writable config file '/etc/my.cnf' is ignored 大概意思是权限全局可写，任何一个用户都可以写。mysql担心这种文件被其他用户恶意修改，所以忽略掉这个配置文件。这样mysql无法关闭。 此时查询MySQL数据库中的配置，发现一些my.cnf配置的参数，在mysql实例中并没有生效。 这个是因为 /etc/my.cnf 也被修改为 777权限了：1ls -la /etc/my.cnf -rwxrwxrwx 1 root root 1120 Jul 31 10:28 /etc/my.cnf /etc/my.cnf 权限过大，会影响实例不能启动，或者不能关闭，需要修改为 644.操作如下： 1ls -la /etc/my.cnf -rwxrwxrwx 1 root root 1120 Jul 31 10:28 /etc/my.cnf 1chmod 644 /etc/my.cnf 1ls -la /etc/my.cnf -rw-r–r– 1 root root 1120 Jul 31 10:28 /etc/my.cnf 确认一下 /etc/my.cnf ,重启实例： 12345678910111213141516151014 14:05:54 mysqld_safe mysqld from pid file /data/mysql/data/yq-xg-dev122.pid ended151014 14:06:08 mysqld_safe Starting mysqld daemon with databases from /data/mysql/data151014 14:06:08 [Note] Plugin 'FEDERATED' is disabled.151014 14:06:08 InnoDB: The InnoDB memory heap is disabled151014 14:06:08 InnoDB: Mutexes and rw_locks use GCC atomic builtins151014 14:06:08 InnoDB: Compressed tables use zlib 1.2.3151014 14:06:08 InnoDB: Using Linux native AIO151014 14:06:08 InnoDB: Initializing buffer pool, size = 128.0M151014 14:06:08 InnoDB: Completed initialization of buffer pool151014 14:06:08 InnoDB: highest supported file format is Barracuda.151014 14:06:08 InnoDB: Waiting for the background threads to start151014 14:06:09 InnoDB: 1.1.8 started; log sequence number 18872844901151014 14:06:09 [Warning] 'proxies_priv' entry '@ root@xinge122' ignored in --skip-name-resolve mode.151014 14:06:09 [Note] Event Scheduler: Loaded 0 events151014 14:06:09 [Note] /usr/local/mysql/bin/mysqld: ready for connections.Version: '5.5.19-log' socket: '/tmp/mysql.sock' port: 3306 MySQL Community Server (GPL) 可以看到将 /etc/my.cnf 权限修改正常后，MySQL实例就可以正常启动了。 通过这个案例可以得到如下启发：修改Linux操作系统根目录下目录和文件的权限是非常危险的；比如修改了 /etc/ssh 目录的权限，ssh就无法使用了；如果是 /etc/security 或者 /etc/init.d/sshd 文件被修改了，则root用户就无法登录到系统了；所以必须注意系统权限，尤其是 /etc/ 目录下的文件权限，不能随便修改。不论是开发，还是运维都是需要规范化，尽量避免都以root用户直接操作；对于软件和应用程序的存放位置，也放在单独规定的目录中，使用各个应用单独的用户进行操作；对于系统文件轻易不要修改，尤其不要随便修改/etc/相关的系统文件，如果要修改，可以先测试，确认没有问题后再进行修改。","categories":[{"name":"数据库","slug":"数据库","permalink":"https://chengtong.me/categories/数据库/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://chengtong.me/tags/MySQL/"}]},{"title":"Hello World","slug":"hello-world","date":"2013-12-24T15:00:00.000Z","updated":"2020-05-22T02:03:24.927Z","comments":true,"path":"posts/4a17b156.html","link":"","permalink":"https://chengtong.me/posts/4a17b156.html","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[]},{"title":"shell脚本中的“请按任意键继续”","slug":"shell脚本中的“请按任意键继续”","date":"2013-03-22T01:16:01.000Z","updated":"2020-05-23T12:43:24.029Z","comments":true,"path":"posts/2379f3d9.html","link":"","permalink":"https://chengtong.me/posts/2379f3d9.html","excerpt":"","text":"在Windows的bat脚本中，我们插入pause关键字就可以实现“请按任意键继续”的功能，下面我们来看看Linux下Shell脚本中怎么实现。 脚本代码：any.sh 1234567891011121314151617#!/bin/bashget_char()&#123; SAVEDSTTY=`stty -g` stty -echo stty cbreak dd if=/dev/tty bs=1 count=1 2&gt; /dev/null stty -raw stty echo stty $SAVEDSTTY&#125;echo \"Press any key to continue 。。。\"echo \" CTRL+C break command bash ...\" #CTRL+C EXITchar=`get_char`echo \"Done....\"","categories":[{"name":"Linux","slug":"Linux","permalink":"https://chengtong.me/categories/Linux/"}],"tags":[{"name":"Shell","slug":"Shell","permalink":"https://chengtong.me/tags/Shell/"}]},{"title":"SOA、ERP、SAP和SaaS四者的区别","slug":"SOA、ERP、SAP和SaaS四者的区别","date":"2011-03-25T08:19:32.000Z","updated":"2020-05-22T02:03:24.884Z","comments":true,"path":"posts/44771869.html","link":"","permalink":"https://chengtong.me/posts/44771869.html","excerpt":"","text":"SOA、ERP、SAP和SaaS大家熟悉吗？秘奥收集相关资料整理如下： SOA 面向服务架构SOA（Service-Oriented Architecture）是一种架构模型和一套设计方法学，其目的是最大限度地重用应用程序中立型的服务以提高IT适应性和效率。它可以根据需求通过网络对松散耦合的粗粒度应用组件进行分布式部署、组合和使用。服务层是SOA的基础，可以直接被应用调用，从而有效控制系统中与软件代理交互的人为依赖性。SOA的关键是“服务”的概念，W3C将服务定义为：“服务提供者完成一组工作，为服务使用者交付所需的最终结果。最终结果通常会使使用者的状态发生变化，但也可能使提供者的状态改变，或者双方都产生变化”。 ERPERP是英文Enterprise Resource Planning(企业资源计划)的简写。指建立在信息技术基础上，以系统化的管理思想为企业决策层及员工提供决策运行手段的管理平台。 ERP系统集中信息技术与先进的管理思想於一身，成为现代企业的运行模式，反映时代对企业合理调配资源，最大化地创造社会财富的要求，成为企业在信息时代生存、发展的基石。 SAP是一个领先的ERP软件.Systems ,Application,and Products in Data processingSAP R/3软件具备以下功能和主要特点:功能性：R/3以模块化的形式提供了一整套业务措施,其中的模块囊括了全部所需要的业务功能并把用户与技术性应用软件相联而形成一个总括的系统，用于公司或企业战略上和运用上的管理。集成化: R/3把逻辑上相关联的部分连接在一起。重复工作和多余数据被完全取消，规程被优化，集成化的业务处理取代了传统的人工操作。 SaaS SaaS是Software-as-a-service（软件即服务）的简称，它是一种通过Internet提供软件的模式，用户不用再购买软件，而改用向提供商租用基于Web的软件，来管理企业经营活动，且无需对软件进行维护，服务提供商会全权管理和维护软件，对于许多小型企业来说，SaaS是采用先进技术的最好途径，它消除了企业购买、构建和维护基础设施和应用程序的需要，近年来，SaaS的兴起已经给传统套装软件厂商带来真实的压力。秘奥软件坚持的发展战略就是：软件即是一种服务！ SaaS服务提供模式 SaaS服务提供商为中小企业搭建信息化所需要的所有网络基础设施及软件、硬件运作平台，并负责所有前期的实施、后期的维护等一系列服务，企业无需购买软硬件、建设机房、招聘IT人员，只需前期支付一次性的项目实施费和定期的软件租赁服务费，即可通过互联网享用信息系统。服务提供商通过有效的技术措施，可以保证每家企业数据的安全性和保密性。企业采用SaaS服务模式在效果上与企业自建信息系统基本没有区别，但节省了大量用于购买IT产品、技术和维护运行的资金，且像打开自来水龙头就能用水一样，方便地利用信息化系统，从而大幅度降低了中小企业信息化的门槛与风险。 SaaS服务的优势 对企业来说，SaaS的优点在于： ⒈ 从技术方面来看：企业无需再配备IT方面的专业技术人员，同时又能得到最新的技术应用，满足企业对信息管理的需求。⒉ 从投资方面来看：企业只以相对低廉的“月费”方式投资，不用一次性投资到位，不占用过多的营运资金，从而缓解企业资金不足的压力；不用考虑成本折旧问题，并能及时获得最新硬件平台及最佳解决方案。⒊ 从维护和管理方面来看：由于企业采取租用的方式来进行物流业务管理，不需要专门的维护和管理人员，也不需要为维护和管理人员支付额外费用。很大程度上缓解企业在人力、财力上的压力，使其能够集中资金对核心业务进行有效的运营。 以上是对SOA、ERP、SAP和SaaS四者的分析。","categories":[],"tags":[]},{"title":"MySQL连接&备份&导入数据库","slug":"MySQL连接&备份&导入数据库","date":"2010-06-01T00:49:27.000Z","updated":"2020-05-23T12:43:23.987Z","comments":true,"path":"posts/727549f.html","link":"","permalink":"https://chengtong.me/posts/727549f.html","excerpt":"","text":"连接本地数据库语法：mysql -h 目标服务器(可选的，默认为localhost) -P 端口(可选) -u 用户名 -p密码 1mysql -u root -p123456; 注：-u与root可以不用加空格，其它也一样，除-p和123456不能有空格； 连接远程数据库例如：MySQL 连接远程数据库（192.168.1.100），端口“3306”(默认3306可以忽略)，用户名为“demo”，密码“12345678” 1mysql -h 192.168.1.100 -P 3306 -u demo -p12345678; 备份本地数据库语法：mysqldump -h 目标服务器(可选的，默认为localhost) -P 端口(可选) -u 用户名 -p密码 数据库名 &gt; 导出的文件名 1mysqldump -u root -p123456 demo &gt; ~/demo_&quot;$(date +%Y%m%d%H%M%S)&quot;.sql; 备份远程数据库1mysqldump -h 192.168.1.100 -u demo -p12345678 demo &gt; ~/demo_&quot;$(date +%Y%m%d%H%M%S)&quot;.sql; 导入123mysql -u root -p123456;USE demo;source ~/demo.sql;","categories":[{"name":"数据库","slug":"数据库","permalink":"https://chengtong.me/categories/数据库/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://chengtong.me/tags/MySQL/"}]},{"title":"MySQL循环批量插入数据","slug":"mysql循环批量插入数据","date":"2010-05-31T06:37:03.000Z","updated":"2020-05-22T02:03:24.973Z","comments":true,"path":"posts/f02121e8.html","link":"","permalink":"https://chengtong.me/posts/f02121e8.html","excerpt":"","text":"123456789101112TRUNCATE TABLE a; #清空表数据DROP PROCEDURE IF EXISTS proc_init_data; #如果存在此存储过程则删掉DELIMITER $ -- 使用delimiter后，将不把分号当做语句结束，会将该段整个提交CREATE PROCEDURE proc_init_data()BEGIN DECLARE i INT DEFAULT 1; WHILE i&lt;=10000 DO INSERT INTO a (`name`) VALUES (i); SET i = i+1; END WHILE;END $CALL proc_init_data();","categories":[{"name":"数据库","slug":"数据库","permalink":"https://chengtong.me/categories/数据库/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://chengtong.me/tags/MySQL/"}]},{"title":"MySQL删除表数据DROP、TRUNCATE和DELETE的用法和区别","slug":"mysql删除表数据drop、truncate和delete的用法和区别","date":"2010-05-30T06:21:46.000Z","updated":"2020-05-22T02:03:24.972Z","comments":true,"path":"posts/fd4a1da4.html","link":"","permalink":"https://chengtong.me/posts/fd4a1da4.html","excerpt":"","text":"程度从强到弱drop table tbdrop将表格直接删除，没有办法找回 truncate (table) tb删除表中的所有数据，不能与where一起使用 delete from tb (where)删除表中的数据(可制定某一行) 区别：truncate和delete的区别1、事务：truncate是不可以rollback的，但是delete是可以rollback的； 原因：truncate删除整表数据(ddl语句,隐式提交)，delete是一行一行的删除，可以rollback，效率上truncate比delete快，但truncate删除后不记录mysql日志，不可以恢复数据。 2、效果：truncate删除后将重新水平线和索引(id从零开始) ,delete不会删除索引，truncate相当于保留mysql表的结构，重新创建了这个表，所有的状态都相当于新表。 3、truncate 不能触发任何Delete触发器。 4、delete 删除可以返回行数","categories":[{"name":"数据库","slug":"数据库","permalink":"https://chengtong.me/categories/数据库/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://chengtong.me/tags/MySQL/"}]}]}